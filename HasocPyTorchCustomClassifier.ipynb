{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HasocPyTorchCustomClassifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "414513c0d32243dd95bbd79933db8e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a840d86003a347a4a0fd9f09504a7f38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0dd137441e6a453f9b8f204c9ebc8cd2",
              "IPY_MODEL_a6b5edfb7b8a470fbfdb9d9b20670661"
            ]
          }
        },
        "a840d86003a347a4a0fd9f09504a7f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dd137441e6a453f9b8f204c9ebc8cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_433bd7fbd44044798b5e1d37b07851a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 541,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 541,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81d232a1401740f684fb1cdcb6d9ec7c"
          }
        },
        "a6b5edfb7b8a470fbfdb9d9b20670661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_931d9211d9a142ab9c9db3b03f2fdd27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 541/541 [00:00&lt;00:00, 631B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f67567a7d8f447209b2cbe455b71cb71"
          }
        },
        "433bd7fbd44044798b5e1d37b07851a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81d232a1401740f684fb1cdcb6d9ec7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "931d9211d9a142ab9c9db3b03f2fdd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f67567a7d8f447209b2cbe455b71cb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f995289201034471b8cc490e7f2bb533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00c91013dbe04cf481a46f72c0baeefe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bc1b1704f18454d9e9e39885f92adf2",
              "IPY_MODEL_3646fc9b07d4404c9a36674d2b87d175"
            ]
          }
        },
        "00c91013dbe04cf481a46f72c0baeefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bc1b1704f18454d9e9e39885f92adf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_996d580f8b2c4dfb95cc0e7587f5e107",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_269ba5a19c9f4aa295bab0cf490d69bb"
          }
        },
        "3646fc9b07d4404c9a36674d2b87d175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f63f442657494d73a1aaa15e6085884a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:03&lt;00:00, 1.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b122ea4fc0a47508c079b47bf16c438"
          }
        },
        "996d580f8b2c4dfb95cc0e7587f5e107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "269ba5a19c9f4aa295bab0cf490d69bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f63f442657494d73a1aaa15e6085884a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b122ea4fc0a47508c079b47bf16c438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4174e06604f34c5bb746124660b51863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a867a410675b4230ab77ec937eee7e05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af3ad716ebe840c68472aa88a340329d",
              "IPY_MODEL_63625811ea804f97b3025456e1482977"
            ]
          }
        },
        "a867a410675b4230ab77ec937eee7e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af3ad716ebe840c68472aa88a340329d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_019dc76545d24ce6929d27bcbf3c3b45",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7c18001eb8a4bb0b0fb722e82851b1b"
          }
        },
        "63625811ea804f97b3025456e1482977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_075e46b52b0a49939fd6c3df9a332448",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [00:01&lt;00:00, 86.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae1c0b578a51439980fe8ffd42befb7f"
          }
        },
        "019dc76545d24ce6929d27bcbf3c3b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7c18001eb8a4bb0b0fb722e82851b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "075e46b52b0a49939fd6c3df9a332448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae1c0b578a51439980fe8ffd42befb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09b5d98e7c7a4b4abfc9e049b0fa513b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcc3b0314c4c4b478008fc96bb3b39dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c959357078964d658615f5aedcdbc8e7",
              "IPY_MODEL_d1320477ddf44fe794623b35a11932c7"
            ]
          }
        },
        "dcc3b0314c4c4b478008fc96bb3b39dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c959357078964d658615f5aedcdbc8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_415b903300b9447cb6ee848e4dea8384",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 147,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 147,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22be5619430543838d0b9d61956c9e67"
          }
        },
        "d1320477ddf44fe794623b35a11932c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e25a07d0d4e4f56ace5b3764255fa20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 147/147 [00:00&lt;00:00, 158B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_543fe739838b489dbf2fd45d207108a2"
          }
        },
        "415b903300b9447cb6ee848e4dea8384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22be5619430543838d0b9d61956c9e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e25a07d0d4e4f56ace5b3764255fa20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "543fe739838b489dbf2fd45d207108a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "621baa310c6d495e8d40f021a6368ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_317ab94de77d4c6fa70eaeceecdc534d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca5df6aa293e4d3988e251931fbc3a61",
              "IPY_MODEL_e4f0630fafb24ba3ab01c636a69c1cf3"
            ]
          }
        },
        "317ab94de77d4c6fa70eaeceecdc534d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca5df6aa293e4d3988e251931fbc3a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba94275cb89c4ec49406c130f9d71b1a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1112256686,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1112256686,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e1790e620384535a8444597558b5223"
          }
        },
        "e4f0630fafb24ba3ab01c636a69c1cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5ee644ddd804deb8a458e2ffe12a944",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.11G/1.11G [00:50&lt;00:00, 21.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73312ca0a848424e94d7d88777f53d94"
          }
        },
        "ba94275cb89c4ec49406c130f9d71b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e1790e620384535a8444597558b5223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5ee644ddd804deb8a458e2ffe12a944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73312ca0a848424e94d7d88777f53d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/HasocPyTorchCustomClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusydJSf1JWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca2922e-9915-49ea-b53c-abbe7b910829"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5k6sJxMId20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb7d6a7c-799f-49f0-a166-9528aa49026d"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers\n",
        "!pip install seaborn\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U sentence-transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 9.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5fd20f5bdc10d10dbc9f8703cc6477cf00bc8936ef00bafac069eeae397741b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 12.7MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/74/49848e9bb64482a7e5f475cc66da5de759077817ede36f8812060ebcaba6/sentence-transformers-0.3.6.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.6-cp36-none-any.whl size=101182 sha256=e2f2451446b3a20c2ab9831d39d75ee3842f9bbe65150e0ccd9c13bfe48dc286\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/3f/75/c0c4b3ef5dfbf8806d37b8dc661861772aba2f7aa419c85a9b\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-0.3.6\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0yrIDfJZaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "17b66809-0b07-4884-a529-642e2e6f823e"
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
        "import gensim.models as gsm\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "from tqdm import tqdm \n",
        "import gc\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gcXgxjBfAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4677e5b6-db91-4f2e-aa79-78385d326df5"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtF92-5O1kHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loc = '/content/drive/My Drive/2020_processed_data/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXhZ-jlRdzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "050989c5-5572-4793-e7b9-e981b74e227a"
      },
      "source": [
        "e2v = gsm.KeyedVectors.load_word2vec_format('./emoji2vec.bin', binary=True)\n",
        "\n",
        "def getEmojiEmbeddings(emojiList,dim=300,verbose = False):\n",
        "  # Generates an emoji vector by averaging the emoji representation for each emoji\n",
        "  # If no emoji returns an empty list of dimension dim\n",
        "  if dim < 300:\n",
        "    raise IndexError(\"Dim has to be greater than 300\")\n",
        "  result = np.zeros(dim)\n",
        "  if (len(emojiList) == 0):\n",
        "    return result\n",
        "  else:\n",
        "    embs = None\n",
        "    for i in emojiList:\n",
        "      if verbose:\n",
        "        if i not in e2v.vocab:\n",
        "          print(i)\n",
        "    embs = np.mean([e2v[i] for i in emojiList if i in e2v.vocab], axis=0)\n",
        "  if np.any(np.isnan(embs)):\n",
        "    return result\n",
        "  result[:300] = embs\n",
        "  return result "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-FXMlpJstB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def loadData(lang):\n",
        "  \"\"\" Function to load data for one language from the preprocessed pickle file\"\"\"\n",
        "  if lang[:2] not in ['hi','en','ge']:\n",
        "      raise NameError(\"Language not found\")\n",
        "  fileName = lang + '.pickle'\n",
        "  with open(DATASET_ROOT+fileName, 'rb') as f:\n",
        "    ged = pickle.load(f)\n",
        "  df = pd.DataFrame.from_dict(ged)\n",
        "  train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)\n",
        "  return train_df, test_df, df\n",
        "\n",
        "def loadDataAllLangs():\n",
        "  \"\"\" Function to load data for all languages from the preprocessed pickle file\"\"\"\n",
        "\n",
        "  hi_train,hi_test,hi_df = loadData('hi')\n",
        "  en_train,en_test,en_df = loadData('en')\n",
        "  ge_train,ge_test,ge_df = loadData('ge')\n",
        "  train_df = pd.concat([hi_train,en_train,ge_train],ignore_index=True)\n",
        "  test_df =  pd.concat([hi_test,en_test,ge_test],ignore_index=True)\n",
        "  df = pd.concat([hi_df,en_df,ge_df],ignore_index=True)\n",
        "  train_df = train_df.sample(frac = 1, random_state=42)\n",
        "  test_df = test_df.sample(frac = 1, random_state=42)\n",
        "  df = df.sample(frac = 1, random_state=42)\n",
        "  return train_df,test_df,df\n",
        "\n",
        "class HASOCDataset(Dataset):\n",
        "  \"\"\" Data loader to load the data for the Torch \"\"\"\n",
        "  def __init__(self, dataPath, isDF = False):\n",
        "    if isDF:\n",
        "      self.df = pd.DataFrame.from_dict(dataPath)\n",
        "    else:\n",
        "      data = pickle.load(open(dataPath,'rb'))\n",
        "      self.df = pd.DataFrame.from_dict(data)\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  def __getitem__(self,index):\n",
        "    return self.df.iloc[index]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcJgq6lAAB--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "     # \"\"\" Sets all seed to the given value, so we can reproduce (:3) \"\"\"\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "set_seed(42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kcl1jVZAbyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullExample(object):\n",
        "  \"\"\" Not necessary any more, mainly here in case we might need to use the entire thing. \"\"\"\n",
        "  def __init__(self, id, task_1, task_2, hasoc_id, full_tweet, tweet_raw_text, hashtags, smiley, emoji, url, mentions, numerals, reserved_word, segmented_hash):\n",
        "    self.id  = id\n",
        "    self.task_1 = task_1\n",
        "    self.task_2 = task_2\n",
        "    self.hasoc_id = hasoc_id\n",
        "    self.full_tweet = full_tweet\n",
        "    self.tweet_raw_text = tweet_raw_text\n",
        "    self.hashtags = hashtags\n",
        "    self.smiley = smiley\n",
        "    self.emoji = emoji\n",
        "    self.url = url \n",
        "    self. mentions = mentions \n",
        "    self.numerals = numerals\n",
        "    self.reserved_word = reserved_word\n",
        "    self.segmented_hash = segmented_hash\n",
        "  \n",
        "class Example(object):\n",
        "  \"\"\" Contains the data for one example from the dataset \"\"\"\n",
        "  def __init__(self, id, task_1, task_2, hasoc_id, full_tweet, tweet_raw_text,  emoji,  segmented_hash):\n",
        "    self.id  = id\n",
        "    self.task_1 = task_1\n",
        "    self.task_2 = task_2\n",
        "    self.hasoc_id = hasoc_id\n",
        "    self.full_tweet = full_tweet\n",
        "    self.tweet_raw_text = tweet_raw_text\n",
        "    self.emoji = emoji\n",
        "    self.segmented_hash = segmented_hash\n",
        "\n",
        "class ExampleFeautres(object):\n",
        "    \"\"\" Contains the dataset in a batch friendly feaute set \"\"\"\n",
        "    def __init__(self, id, task_1, task_2, input_ids, input_mask,input_length,  emoji,  hash):\n",
        "      self.id  = id\n",
        "      self.task_1 = task_1\n",
        "      self.task_2 = task_2\n",
        "      self.emoji = torch.tensor(emoji)\n",
        "      self.input_ids = input_ids\n",
        "      self.input_mask = input_mask\n",
        "      self.input_length = input_length \n",
        "      self.hash = torch.tensor(hash)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4itxWcjlAqY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287,
          "referenced_widgets": [
            "414513c0d32243dd95bbd79933db8e91",
            "a840d86003a347a4a0fd9f09504a7f38",
            "0dd137441e6a453f9b8f204c9ebc8cd2",
            "a6b5edfb7b8a470fbfdb9d9b20670661",
            "433bd7fbd44044798b5e1d37b07851a1",
            "81d232a1401740f684fb1cdcb6d9ec7c",
            "931d9211d9a142ab9c9db3b03f2fdd27",
            "f67567a7d8f447209b2cbe455b71cb71",
            "f995289201034471b8cc490e7f2bb533",
            "00c91013dbe04cf481a46f72c0baeefe",
            "9bc1b1704f18454d9e9e39885f92adf2",
            "3646fc9b07d4404c9a36674d2b87d175",
            "996d580f8b2c4dfb95cc0e7587f5e107",
            "269ba5a19c9f4aa295bab0cf490d69bb",
            "f63f442657494d73a1aaa15e6085884a",
            "8b122ea4fc0a47508c079b47bf16c438",
            "4174e06604f34c5bb746124660b51863",
            "a867a410675b4230ab77ec937eee7e05",
            "af3ad716ebe840c68472aa88a340329d",
            "63625811ea804f97b3025456e1482977",
            "019dc76545d24ce6929d27bcbf3c3b45",
            "a7c18001eb8a4bb0b0fb722e82851b1b",
            "075e46b52b0a49939fd6c3df9a332448",
            "ae1c0b578a51439980fe8ffd42befb7f",
            "09b5d98e7c7a4b4abfc9e049b0fa513b",
            "dcc3b0314c4c4b478008fc96bb3b39dd",
            "c959357078964d658615f5aedcdbc8e7",
            "d1320477ddf44fe794623b35a11932c7",
            "415b903300b9447cb6ee848e4dea8384",
            "22be5619430543838d0b9d61956c9e67",
            "3e25a07d0d4e4f56ace5b3764255fa20",
            "543fe739838b489dbf2fd45d207108a2"
          ]
        },
        "outputId": "96a40887-9ae1-47be-c1ce-0a61bea6f1dd"
      },
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens\")\n",
        "max_seq_length = 74\n",
        "e2v = gsm.KeyedVectors.load_word2vec_format('./emoji2vec.bin', binary=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "414513c0d32243dd95bbd79933db8e91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f995289201034471b8cc490e7f2bb533",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4174e06604f34c5bb746124660b51863",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09b5d98e7c7a4b4abfc9e049b0fa513b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=147.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "100%|██████████| 1.01G/1.01G [00:14<00:00, 70.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHi9Z9TyA16V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_task1 ={'NOT':0, 'HOF':1}\n",
        "labels_task2 ={'NONE':0,'PRFN':1,'OFFN':2,'HATE':3}\n",
        "\n",
        "def convertExamplesToFeature(example):\n",
        "  \"\"\" Given a data row convert it to feautres so it's batch friendly \"\"\"\n",
        "  raw_text = example.tweet_raw_text\n",
        "  tokens = tokenizer.tokenize(raw_text)\n",
        "  if (len(tokens) > (max_seq_length-2)):\n",
        "    tokens = tokens[: (max_seq_length-2)]\n",
        "  tokens = [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n",
        "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  input_mask = [1] * len(input_ids)\n",
        "  input_length = len(input_ids)\n",
        "  padding = [0] * (max_seq_length - len(input_ids))\n",
        "  input_ids += padding\n",
        "  input_mask += padding\n",
        "  hashtags = ' '.join(example.segmented_hash)\n",
        "  hashembs = sent_encoder.encode(hashtags)\n",
        "  # Do we want to propage the values across hashtags? ~ Prolly not\n",
        "  # but the following code keeps that provision in case we need it. \n",
        "  # hashtags = []\n",
        "  # hashtokens = tokenizer.tokenize(hashtags)\n",
        "  # if (len(hashtokens) > (max_hash_length-2)):\n",
        "  #   hashtokens = tokens[: (max_hash_length-2)]\n",
        "  # tokens = [tokenizer.cls_token] + hashtokens + [tokenizer.sep_token]\n",
        "  # hashinput_ids = tokenizer.convert_tokens_to_ids(hashtokens)\n",
        "  # hashinput_mask = [1] * len(hashinput_ids)\n",
        "  # input_length = len(hashinput_ids)\n",
        "  # padding = [0] * (max_hash_length - len(hashinput_ids))\n",
        "  # input_ids += padding\n",
        "  # input_mask += padding\n",
        "  emojiVec = getEmojiEmbeddings(example.emoji)\n",
        "  task1 = labels_task1[example.task_1]\n",
        "  task2 = labels_task2[example.task_2]\n",
        "  id = example.id\n",
        "  return ExampleFeautres(id,task1,task2, input_ids, input_mask,input_length, emojiVec,hashembs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8agjm46BCJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDataset(input_features):\n",
        "    \"\"\"\n",
        "    Mappings for index-> features \n",
        "    0 -> ID\n",
        "    1 -> input ids\n",
        "    2 -> input masks\n",
        "    3 -> input lengths \n",
        "    4 -> hash embs \n",
        "    5 -> emoji embs \n",
        "    6 -> task1\n",
        "    7 -> task2\n",
        "    \"\"\"\n",
        "    all_input_page_ids = torch.tensor([f.id for f in input_features], dtype=torch.long)\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in input_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in input_features], dtype=torch.long)\n",
        "    all_input_lengths = torch.tensor([f.input_length for f in input_features], dtype=torch.long)\n",
        "    all_hash_embs = torch.stack([f.hash for f in input_features])\n",
        "    all_emoji_embs = torch.stack([f.emoji for f in input_features])\n",
        "    all_task_1 = torch.tensor([f.task_1 for f in input_features], dtype=torch.long)\n",
        "    all_task_2 = torch.tensor([f.task_2 for f in input_features], dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(all_input_page_ids, all_input_ids, all_input_mask,all_input_lengths, all_hash_embs, all_emoji_embs, all_task_1,  all_task_2)\n",
        "    return dataset "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzg3OZcGBF8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['valid'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "\n",
        "def getDataloader(path_to_pickle,val_split = 0.2, batch_size = 16, multiLing = False):\n",
        "  if multiLing:\n",
        "    tr,tt,df = loadDataAllLangs()\n",
        "    tempDataset = HASOCDataset(df, isDF=True)\n",
        "  else:\n",
        "    tempDataset = HASOCDataset(path_to_pickle)\n",
        "  input_features = []\n",
        "  for i in tqdm(range(len(tempDataset))):\n",
        "    example = Example(i,tempDataset[i]['task_1'],tempDataset[i]['task_2'],tempDataset[i]['hasoc_id'], tempDataset[i]['full_tweet'],tempDataset[i]['tweet_raw_text'], tempDataset[i]['emoji'],tempDataset[i]['segmented_hash'])\n",
        "    input_feature = convertExamplesToFeature(example)\n",
        "    input_features.append(input_feature)\n",
        "  dataset = getDataset(input_features)\n",
        "  # print(len(dataset))\n",
        "  set_seed(42)\n",
        "  data_sampler = RandomSampler(dataset)\n",
        "  dd = train_val_dataset(dataset, val_split)\n",
        "  train_dataloader = DataLoader(dd['train'], sampler = RandomSampler(dd['train']), batch_size=batch_size, drop_last=True)\n",
        "  valid_dataloader = DataLoader(dd['valid'] , batch_size=batch_size, drop_last=True)\n",
        "  dataloader = DataLoader(dataset , batch_size=batch_size, drop_last=True)\n",
        "  dataloaders = {x:DataLoader(dd[x],16, shuffle=True, num_workers=4) for x in ['train','valid']} \n",
        "\n",
        "  return train_dataloader,valid_dataloader,dataloader,dataloaders"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWxiWkEZBHbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "76ae4316-b715-4ba4-e9a0-fefef5bb58ff"
      },
      "source": [
        "DATASET_ROOT = data_loc\n",
        "train_dataloader, valid_dataloader,dataloader, dataloaders = getDataloader(data_loc + 'en.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 62/3708 [00:00<00:49, 73.76it/s]/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            " 73%|███████▎  | 2702/3708 [00:36<00:13, 73.95it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLtxJQYfRfHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here cause restarting the code sometimes causes Colab to crash, so don't wanna waste\n",
        "# time waiting for the entire thing to run again. \n",
        "\n",
        "# import pickle\n",
        "# with open('train.pikcle','wb') as handle:\n",
        "#   pickle.dump(train_dataloader, handle)\n",
        "# with open('valid.pickle','wb') as handle:\n",
        "#   pickle.dump(valid_dataloader, handle)\n",
        "# with open('train.pikcle','rb') as handle:\n",
        "#   train_dataloader = pickle.load(handle)\n",
        "# with open('valid.pickle','rb') as handle:\n",
        "#   valid_dataloader = pickle.load( handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09HIcuPKXBUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "  \"\"\" Classification head for the Roberta Model \"\"\" \n",
        "  def __init__(self, numberOfClasses, hidden_size_bert, hidden_size_post_feats, dropout_val = 0.2):\n",
        "    super().__init__()\n",
        "    self.denseInit = nn.Linear(hidden_size_post_feats, hidden_size_bert)\n",
        "    self.dense = nn.Linear(hidden_size_bert, hidden_size_bert)\n",
        "    self.dropout = nn.Dropout(dropout_val)\n",
        "    self.output = nn.Linear(hidden_size_bert, numberOfClasses)\n",
        "  def forward(self, x):\n",
        "    # print(x.shape)\n",
        "    x = self.dropout(x)\n",
        "    x = self.denseInit(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.dense(x)\n",
        "    x  = torch.tanh(x)\n",
        "    x = self.dropout(x)\n",
        "    x  = self.output(x)\n",
        "    return x\n",
        "\n",
        "class TextClassification(nn.Module):\n",
        "  \"\"\" Classifier with feature injection \"\"\"\n",
        "  def __init__(self, numberOfClasses,dropout_val = 0.1, batch_size = 16):\n",
        "     super(TextClassification, self).__init__()\n",
        "     self.bert = XLMRobertaModel.from_pretrained(\"sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens\")\n",
        "     self.classifier = ClassificationHead(numberOfClasses, self.bert.config.hidden_size , (self.bert.config.hidden_size * 2 + 300) , dropout_val)\n",
        "  def forward(self, input_seq, attention_mask, emoji, hashTag):\n",
        "    bert_pooled_output = self.bert(input_seq, attention_mask=attention_mask)[0]\n",
        "    bert_pooled_output = bert_pooled_output[:,0,:]\n",
        "    bert_pooled_out_feat = torch.cat([bert_pooled_output, emoji,hashTag],axis = 1)\n",
        "    # print(\"Shape\",bert_pooled_out_feat.shape)\n",
        "    output = self.classifier(bert_pooled_out_feat)\n",
        "    return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeV2EukDtH1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_dataloader, valid_dataloader,numberOfEpochs , task = 1):\n",
        "  \"\"\" Train Loop for the model \"\"\"\n",
        "  if task == 2:\n",
        "    classNum = 4\n",
        "    taskIndex = 7\n",
        "  elif task == 1:\n",
        "    classNum = 2\n",
        "    taskIndex = 6\n",
        "  else:\n",
        "    raise NameError(\"Task not defined\")\n",
        "  total_steps = len(train_dataloader) * numberOfEpochs\n",
        "  print(\"Start\")\n",
        "  model = TextClassification(classNum)# task 1 \n",
        "  if device == \"gpu\":\n",
        "    model.cuda()\n",
        "  \n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "            )\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "  \n",
        "  loss_function = nn.CrossEntropyLoss().to(device)\n",
        "  epoch_loss = 0\n",
        "  batch_accuracy_scores = []\n",
        "  global_pred = []\n",
        "  global_label = []\n",
        "  for epoch in (range(numberOfEpochs)):\n",
        "    print(\"Epoch:\",epoch)\n",
        "    gc.collect()\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    batch_accuracy_scores = []\n",
        "    train_data_count = float(len(train_dataloader))\n",
        "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
        "      # print(len(batch))\n",
        "      b_input_ids = batch[1]\n",
        "      b_input_mask = batch[2]\n",
        "      b_labels = batch[taskIndex]\n",
        "      b_emoji = batch[5]\n",
        "      b_hashtag = batch[4]\n",
        "      pred = model(b_input_ids,b_input_mask ,b_emoji.float(), b_hashtag.float())\n",
        "      loss = loss_function(pred.view(-1,classNum ), b_labels.view(-1))\n",
        "      with torch.no_grad():\n",
        "        epoch_loss += (loss.item()*len(b_labels))\n",
        "        global_pred.append(pred)\n",
        "        global_label.append(b_labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9CoPXK0tHbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "model = train_model(train_dataloader, valid_dataloader, 3, task = 2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jzInSOrVnuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model \n",
        "torch.save(model.state_dict(),  'customTorchMultiLing_2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sRfRRBlYHu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modelEvaluate(model, valid_dataloader, task = 1):\n",
        "  gc.collect()\n",
        "  if task == 1:\n",
        "    taskIndex = 6\n",
        "  elif task == 2:\n",
        "    taskIndex = 7\n",
        "  model.eval()\n",
        "  predictions , true_labels = [], []\n",
        "  logits = []\n",
        "  # Predict \n",
        "  for batch in valid_dataloader:\n",
        "    # Add batch to GPU\n",
        "    b_input_ids = batch[1]\n",
        "    b_input_mask = batch[2]\n",
        "    b_labels = batch[taskIndex]\n",
        "    b_emoji = batch[5]\n",
        "    b_hashtag = batch[4]\n",
        "    with torch.no_grad():\n",
        "      pred = model(b_input_ids,b_input_mask ,b_emoji.float(), b_hashtag.float())\n",
        "    logits.append(pred.detach().cpu().numpy())\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "    predictions = []\n",
        "    for i in logits:\n",
        "      for j in i:\n",
        "        predictions.append(j)\n",
        "    flat_predictions = [np.argmax(i) for i in predictions]\n",
        "    assert(len(flat_predictions) == len(flat_true_labels))\n",
        "    return flat_predictions, flat_true_labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fkmas1FijYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, true_labels = modelEvaluate(model, valid_dataloader, 2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TIpVVDkRW5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "272d2dfb-f938-4f4f-d8b6-92260c27e454"
      },
      "source": [
        "f1_score(true_labels, predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8117647058823529"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZhjBCvxAnvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(model_path, task = 1):\n",
        "  \"\"\" Code to load a model based on the saved points \"\"\"\n",
        "  if task == 1:\n",
        "    classNum = 2\n",
        "  elif task == 2:\n",
        "    classNum = 4\n",
        "  else:\n",
        "    raise NameError(\"No such task\")\n",
        "  model = TextClassification(classNum)\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  return model "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoo3FyAML13x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "621baa310c6d495e8d40f021a6368ac5",
            "317ab94de77d4c6fa70eaeceecdc534d",
            "ca5df6aa293e4d3988e251931fbc3a61",
            "e4f0630fafb24ba3ab01c636a69c1cf3",
            "ba94275cb89c4ec49406c130f9d71b1a",
            "4e1790e620384535a8444597558b5223",
            "d5ee644ddd804deb8a458e2ffe12a944",
            "73312ca0a848424e94d7d88777f53d94"
          ]
        },
        "outputId": "969f1a71-95c3-4077-e4a0-7f291d747b5c"
      },
      "source": [
        "model1 = loadModel('/content/drive/My Drive/2020_processed_data/customTorchMultiLing_2.pt',2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "621baa310c6d495e8d40f021a6368ac5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1112256686.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmTCENnyMEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions, true_labels = modelEvaluate(model1, valid_dataloader, 2)\n",
        "f1_score(true_labels, predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJgzt_J6h84P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Have the data in data_loc \n",
        "# data_loc will have it as hi_test.pickle\n",
        "\n",
        "def loadTestDataAllLangs():\n",
        "  \"\"\" Function to load data for all languages from the preprocessed pickle file\"\"\"\n",
        "  hi_train,hi_test,hi_df = loadData('hi_test')\n",
        "  en_train,en_test,en_df = loadData('en_test')\n",
        "  ge_train,ge_test,ge_df = loadData('ge_test')\n",
        "  train_df = pd.concat([hi_train,en_train,ge_train],ignore_index=True)\n",
        "  test_df =  pd.concat([hi_test,en_test,ge_test],ignore_index=True)\n",
        "  df = pd.concat([hi_df,en_df,ge_df],ignore_index=True)\n",
        "  train_df = train_df.sample(frac = 1, random_state=42)\n",
        "  test_df = test_df.sample(frac = 1, random_state=42)\n",
        "  df = df.sample(frac = 1, random_state=42)\n",
        "  return train_df,test_df,df\n",
        "\n",
        "def getTestDataLoader(path_to_pickle, batch_size = 16,  multiLing = False):\n",
        "  if multiLing:\n",
        "    tr,tt,df = loadTestDataAllLangs()\n",
        "    tempDataset = HASOCDataset(df, isDF=True)\n",
        "  else:\n",
        "    tempDataset = HASOCDataset(path_to_pickle)\n",
        "  input_features = []\n",
        "  for i in tqdm(range(len(tempDataset))):\n",
        "    example = Example(i,tempDataset[i]['task_1'],tempDataset[i]['task_2'],tempDataset[i]['hasoc_id'], tempDataset[i]['full_tweet'],tempDataset[i]['tweet_raw_text'], tempDataset[i]['emoji'],tempDataset[i]['segmented_hash'])\n",
        "    input_feature = convertExamplesToFeature(example)\n",
        "    input_features.append(input_feature)\n",
        "  dataset = getDataset(input_features)\n",
        "  # print(len(dataset))\n",
        "  set_seed(42)\n",
        "  dataloader = DataLoader(dataset , batch_size=batch_size, drop_last=True)\n",
        "  return dataloader"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay1kxqgjkGUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "369d1057-6666-4e1a-9c1d-3089f3460edd"
      },
      "source": [
        "DATASET_ROOT = data_loc\n",
        "\n",
        "test_dataloader = getTestDataLoader(data_loc + 'en_test', multiLing = True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/2003 [00:14<7:59:13, 14.36s/it]/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "100%|██████████| 2003/2003 [00:46<00:00, 43.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LDcQG4XkGNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88a574a5-4377-4fe0-df78-9dacd0d85a2d"
      },
      "source": [
        "predictions, true_labels = modelEvaluate(model1, test_dataloader, 2)\n",
        "f1_score(true_labels, predictions, average='macro')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44047619047619047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjpw_D2Oh3jy",
        "colab_type": "text"
      },
      "source": [
        "# Things left to do \n",
        "\n",
        "- [X] use the test data and check @Ujwal\n",
        "- [ ] Write the scripts to convert this to the submission format @ TR\n",
        "- [ ]  Add perspective data\n",
        "- [ ] Explore hyperparameters for Learning rate \n",
        "  - [ ] Adaptive learning rate @Sayar \n",
        "  - [ ]  Look at different non linearities \n",
        "  - [ ] explore dropout\n",
        "- [ ] Currently using 2 Linear layers, can 1 do better? \n",
        "- [ ] Explore different massive multiling models\n",
        "  - [ ] Make a list of models to experiment with @TR, @Zubair\n",
        "- [ ] Carry out per language analysis and find the stats. @TR\n",
        "- [ ] Currently using CrossEntropy as the Loss function, but BCE should do better in a multi task setting.Explore that. @ Ujwal \n",
        "- [ ] Explore multi-task setting \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvYLSJMiY9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}