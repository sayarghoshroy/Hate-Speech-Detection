{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC BE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da30a7ed1c48490b8d4b384d5aedc10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4593f37c98004814b85a0ba2973cea27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69aabecf7dd54a8abb7bb70ae0da61dc",
              "IPY_MODEL_e7b5871fae724049b390deda05651c85"
            ]
          }
        },
        "4593f37c98004814b85a0ba2973cea27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69aabecf7dd54a8abb7bb70ae0da61dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8087729def5b45ff8fab5bbeacf580b0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 247333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 247333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6805d549f414ff3b5116e3edd11e7c1"
          }
        },
        "e7b5871fae724049b390deda05651c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba9a8fb6607e464390830d621189cf39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 247k/247k [00:00&lt;00:00, 679kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_158c4558e9e84fadaa95d7bc05540725"
          }
        },
        "8087729def5b45ff8fab5bbeacf580b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6805d549f414ff3b5116e3edd11e7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba9a8fb6607e464390830d621189cf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "158c4558e9e84fadaa95d7bc05540725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4484b2c31e6646fc894d790a8f7b688a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4335cf6820249c0bc8e3df0907d58e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_117bf75c67e14c8595cb00504dfdd812",
              "IPY_MODEL_53e15abf7046466fb80eeb4fde6c424d"
            ]
          }
        },
        "f4335cf6820249c0bc8e3df0907d58e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "117bf75c67e14c8595cb00504dfdd812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f63f39fab894e4792039d09edd86bc3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45db729fec594935ab050e86a912f6bd"
          }
        },
        "53e15abf7046466fb80eeb4fde6c424d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03ff75fcef184e5cbdcc68b2f6b6cd90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 614B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c48935c27204118a1b6a4fd9ec94f6d"
          }
        },
        "4f63f39fab894e4792039d09edd86bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45db729fec594935ab050e86a912f6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ff75fcef184e5cbdcc68b2f6b6cd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c48935c27204118a1b6a4fd9ec94f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abe888e535884729a3fff8618596f280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53e827c668f64831bc7076bcee1b06cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fae58794193246dea13954ae63962d10",
              "IPY_MODEL_36d5c11e8a944aae86a2ac3f3dd2b5fe"
            ]
          }
        },
        "53e827c668f64831bc7076bcee1b06cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fae58794193246dea13954ae63962d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ebbbe6bba04418d9dee94cdb3350c6e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442256365,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442256365,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b009534db3a40b7b2f6302c4373787b"
          }
        },
        "36d5c11e8a944aae86a2ac3f3dd2b5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_575e4a62665a4c3a9d36a32920e04284",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:13&lt;00:00, 33.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9252bba2c1374ed395bbfb07fa36eabd"
          }
        },
        "3ebbbe6bba04418d9dee94cdb3350c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b009534db3a40b7b2f6302c4373787b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "575e4a62665a4c3a9d36a32920e04284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9252bba2c1374ed395bbfb07fa36eabd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymx75g3TKBPu",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusydJSf1JWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "139b53cf-9111-4023-927f-d5966377e87d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkgSSbTKFnl",
        "colab_type": "text"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5k6sJxMId20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fcabb620-fcf9-4361-8d1a-2d2927bf2356"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers\n",
        "!pip install seaborn\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U sentence-transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1fe9de6443eafe4ff32499488848e533edecf63fbad8a32f336a6141be4524f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.15.0)\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/74/49848e9bb64482a7e5f475cc66da5de759077817ede36f8812060ebcaba6/sentence-transformers-0.3.6.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.6-cp36-none-any.whl size=101182 sha256=e7754e00a7098ca96beb5e28e65066cb19347bf4d43d5208e72ec677aa658e24\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/3f/75/c0c4b3ef5dfbf8806d37b8dc661861772aba2f7aa419c85a9b\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-0.3.6\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mJWYRNKH7l",
        "colab_type": "text"
      },
      "source": [
        "# Get imports\n",
        "\n",
        "- **General:** random, pickle, re, time, datetime\n",
        "- **General DS:** pandas, numpy, sklearn, matplotlib, seaborn, nltk\n",
        "- **Deep Learning:** torch, transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0yrIDfJZaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk36oE5Lrg9W",
        "colab_type": "text"
      },
      "source": [
        "# GPU device Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gcXgxjBfAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "51d0a3ff-a6e1-4cdc-8bf5-d5ce32b7757c"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKl5AjVg2GGu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtF92-5O1kHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = '/content/drive/My Drive/HASOC/Data/2020_processed_data/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnNe1bM1vaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(DATASET_ROOT+'ge.pickle', 'rb') as f:\n",
        "  ged = pickle.load(f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MXmbq82tfXr",
        "colab_type": "text"
      },
      "source": [
        "Checking it once for content description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLKtbO3yBD-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0718e041-e1f4-40b3-da70-86fe03241202"
      },
      "source": [
        "ged.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_id', 'task_1', 'task_2', 'hasoc_id', 'full_tweet', 'tweet_raw_text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlOlcu0QWM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae9d2bb-c45c-4f05-fce9-d4f06d69febc"
      },
      "source": [
        "ged['task_1'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOT', 'NOT', 'NOT', 'NOT', 'HOF', 'HOF', 'NOT', 'NOT', 'HOF', 'NOT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSohluLctjzO",
        "colab_type": "text"
      },
      "source": [
        "## Split data into train-test-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXL1bHONOQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1_hash = ged['segmented_hash'][:2000]\n",
        "test1_hash = ged['segmented_hash'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYE1Uvx2O35x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_hash = []\n",
        "for lis in train1_hash:\n",
        "  train_hash.append(' '.join(lis))\n",
        "test_hash = []\n",
        "for lis in test1_hash:\n",
        "  test_hash.append(' '.join(lis))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyLubZmQuGzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text, test_text, train_t1s, test_t1s = model_selection.train_test_split(\n",
        "    ged['tweet_raw_text'],\n",
        "    ged['task_1'],\n",
        "    test_size = 0.2,\n",
        "    # random_state = 42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoKUgiqgtag5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = ged['tweet_raw_text'][:2000]\n",
        "train_t1s = ged['task_1'][:2000]\n",
        "\n",
        "test_text = ged['tweet_raw_text'][2000:]\n",
        "test_t1s = ged['task_1'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_XcLvgGqafu",
        "colab_type": "text"
      },
      "source": [
        "# get Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8BMAterqu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(embeddings):\n",
        "  # emb = []\n",
        "  # for e in embeddings:\n",
        "  #   emb.append({'feat': e})\n",
        "  emb = embeddings\n",
        "  return emb"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jmwjber44S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_task(tasklist):\n",
        "  newtasks = []\n",
        "  for x in tasklist:\n",
        "    if x == 'NOT':\n",
        "      # newtasks.append(['0'])\n",
        "      newtasks.append(0)\n",
        "    else:\n",
        "      # newtasks.append(['1'])\n",
        "      newtasks.append(1)\n",
        "  return newtasks"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QUstRzc2yHm",
        "colab_type": "text"
      },
      "source": [
        "# Experiment: Sentence Embeddings, xlm-r-100langs-bert-base-nli-mean-tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCG1N1pQK5zb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "da30a7ed1c48490b8d4b384d5aedc10c",
            "4593f37c98004814b85a0ba2973cea27",
            "69aabecf7dd54a8abb7bb70ae0da61dc",
            "e7b5871fae724049b390deda05651c85",
            "8087729def5b45ff8fab5bbeacf580b0",
            "f6805d549f414ff3b5116e3edd11e7c1",
            "ba9a8fb6607e464390830d621189cf39",
            "158c4558e9e84fadaa95d7bc05540725"
          ]
        },
        "outputId": "91e1ccda-3502-4fc8-846f-abc01273a445"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da30a7ed1c48490b8d4b384d5aedc10c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=247333.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.01G/1.01G [00:20<00:00, 48.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k5DmChXWorL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Qu6WBrQPJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embeddings = sent_encoder.encode(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M1GFtsEtpNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_embeddings = sent_encoder.encode(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXVvvbUnsIn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_t1 = get_task(train_t1s)\n",
        "test_t1 = get_task(test_t1s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVVLRVXTsh0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_emb = get_features(train_embeddings)\n",
        "test_emb = get_features(test_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwifzww5w9Dk",
        "colab_type": "text"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apmHIpdlwPqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4BvjxQ5wPoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f9af65d5-427b-4011-e29d-c9469df123a0"
      },
      "source": [
        "%%time\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18.1 s, sys: 8.89 s, total: 27 s\n",
            "Wall time: 13.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqCSYEjewPl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test_t1 = clf.predict(test_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1hmWFB_y7I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv2BlDfWqini",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9d698b8d-bc0c-4a36-a51b-41a2aeeda0dd"
      },
      "source": [
        "print(classification_report(test_t1, pred_test_t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.84       335\n",
            "           1       0.65      0.45      0.53       140\n",
            "\n",
            "    accuracy                           0.77       475\n",
            "   macro avg       0.72      0.67      0.69       475\n",
            "weighted avg       0.75      0.77      0.75       475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "430Tls8fNfxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TkflGXZGRRGe"
      },
      "source": [
        "# Experiment: Sentence Embeddings, xlm-r-100langs-bert-base-nli-mean-tokens: fulltext\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXFKtMcLRRGl",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-d_KiGIRRRG5",
        "colab": {}
      },
      "source": [
        "train_text = ged['full_tweet'][:2000]\n",
        "train_t1s = ged['task_1'][:2000]\n",
        "\n",
        "test_text = ged['full_tweet'][2000:]\n",
        "test_t1s = ged['task_1'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cdwD81bZRRHH",
        "colab": {}
      },
      "source": [
        "train_embeddings = sent_encoder.encode(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GuyGd4SoRRHR",
        "colab": {}
      },
      "source": [
        "test_embeddings = sent_encoder.encode(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2LFKvOsxRRHc",
        "colab": {}
      },
      "source": [
        "train_t1 = get_task(train_t1s)\n",
        "test_t1 = get_task(test_t1s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8KcnHGWkRRHk",
        "colab": {}
      },
      "source": [
        "train_emb = get_features(train_embeddings)\n",
        "test_emb = get_features(test_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wv0Wt5BBRRHq"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kaX1cFGoRRHs",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0_tH9W1RRHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a381a304-ff07-46e5-ceb6-9dc02e036bab"
      },
      "source": [
        "%%time\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.1 s, sys: 10 s, total: 31.2 s\n",
            "Wall time: 16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PebUhJBjRRH8",
        "colab": {}
      },
      "source": [
        "pred_test_t1 = clf.predict(test_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z1ivLI_ZRRID",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0NNWiSI4RRIL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "bdc90ac8-bb76-405e-b2f4-f188abdd6170"
      },
      "source": [
        "print(classification_report(test_t1, pred_test_t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       269\n",
            "           1       0.67      0.62      0.64       104\n",
            "\n",
            "    accuracy                           0.81       373\n",
            "   macro avg       0.76      0.75      0.76       373\n",
            "weighted avg       0.81      0.81      0.81       373\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xeUKpSrhNgLW"
      },
      "source": [
        "# Experiment: Sentence Embeddings, xlm-r-100langs-bert-base-nli-mean-tokens, + hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MKqZtUTmNgLZ",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWFHZmgrNgLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "20f8c0ef-d42d-4654-b5b5-a3fe759a4e1e"
      },
      "source": [
        "train_hash[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'esc 2019 iceland',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'merkel kundgebug wuppertal repression ',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N2IsFBVWNgL0",
        "colab": {}
      },
      "source": [
        "train_embeddings = sent_encoder.encode(train_text)\n",
        "train_hashembeddings = sent_encoder.encode(train_hash)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLd93dPoNgL8",
        "colab": {}
      },
      "source": [
        "test_embeddings = sent_encoder.encode(test_text)\n",
        "test_hashembeddings = sent_encoder.encode(test_hash)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4h8_c3cfNgME",
        "colab": {}
      },
      "source": [
        "train_t1 = get_task(train_t1s)\n",
        "test_t1 = get_task(test_t1s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZMn3SwnUNgMM",
        "colab": {}
      },
      "source": [
        "train_emb = get_features(train_embeddings)\n",
        "test_emb = get_features(test_embeddings)\n",
        "train_hashemb = get_features(train_hashembeddings)\n",
        "test_hashemb = get_features(test_hashembeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsgfMOGQOBIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1839733c-8a20-44e4-ea14-9a9b28af4505"
      },
      "source": [
        "(train_hashemb[0]+train_emb[0]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RtXV2pg2NgMT"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "64dJMR0fNgMW",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eArnZjlNNgMc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b0073847-d719-482a-98f2-877dc1797f84"
      },
      "source": [
        "%%time\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_hashemb+train_emb, train_t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.1 s, sys: 10.8 s, total: 33 s\n",
            "Wall time: 17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tS21V1jNgMj",
        "colab": {}
      },
      "source": [
        "pred_test_t1 = clf.predict(test_emb+test_hashemb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rDTMKWHRNgMr",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w44xzq_HNgM0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "843ba647-f7f4-49ca-b6f5-7ab9814e9bc9"
      },
      "source": [
        "print(classification_report(test_t1, pred_test_t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85       269\n",
            "           1       0.62      0.61      0.61       104\n",
            "\n",
            "    accuracy                           0.79       373\n",
            "   macro avg       0.73      0.73      0.73       373\n",
            "weighted avg       0.78      0.79      0.78       373\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s550acIXrW3j",
        "colab_type": "text"
      },
      "source": [
        "# Experiment: Sentence Embeddings, xlm-r-100langs-bert-base-nli-stsb-mean-tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kswZzT_1wPiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3a596e3-8df5-43b5-8601-c81c795a09a0"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-stsb-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.01G/1.01G [00:49<00:00, 20.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vgIEqeZryYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embeddings = sent_encoder.encode(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY45PYeKryV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_embeddings = sent_encoder.encode(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4KDCegBryS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_t1 = get_task(train_t1s)\n",
        "test_t1 = get_task(test_t1s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae1LURr8ryPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_emb = get_features(train_embeddings)\n",
        "test_emb = get_features(test_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkAkM613r9no",
        "colab_type": "text"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjuBGSSXsD-p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3d31cc03-46fc-4455-d4ef-b84c04458509"
      },
      "source": [
        "%%time\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18.4 s, sys: 8.91 s, total: 27.3 s\n",
            "Wall time: 14 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2idcLbutsD-_",
        "colab": {}
      },
      "source": [
        "pred_test_t1 = clf.predict(test_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7QEK7RwhsD_u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7b19e389-6174-4dbb-82d2-fa942cc28d6c"
      },
      "source": [
        "print(classification_report(test_t1, pred_test_t1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86       269\n",
            "           1       0.66      0.59      0.62       104\n",
            "\n",
            "    accuracy                           0.80       373\n",
            "   macro avg       0.75      0.73      0.74       373\n",
            "weighted avg       0.79      0.80      0.80       373\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgjZDwSryB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr78Lk7-08Hc",
        "colab_type": "text"
      },
      "source": [
        "# BERT Sequence Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzI760g1lQd",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "Loading the dataset into a dataframe, then transforming the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAcmEjoxrx4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = '/content/drive/My Drive/HASOC/Data/2020_train_sets/hasoc_2020_de_train.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxX_2glrxqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "223167b6-b31f-4064-9be4-1b2c40a619ec"
      },
      "source": [
        "df = pd.read_csv(DATASET_PATH)\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,452\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1631</th>\n",
              "      <td>1133418909816766467</td>\n",
              "      <td>...nicht nur dass sie mit dem Kopf gegen die W...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_de_820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>1131662981215997955</td>\n",
              "      <td>@Fred_ahoi Nur blöd, wenn man's vor lauter Dum...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>1124354788186099713</td>\n",
              "      <td>RT @BauerGeorg6: ⁦@AndreaNahlesSPD⁩, ihr seit ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_de_2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1131979881854713858</td>\n",
              "      <td>RT @Iunahri: Ja blabla jeder Herd ist untersch...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_de_2865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2273</th>\n",
              "      <td>1131642005501685761</td>\n",
              "      <td>@saschakam @hannoderbus mal rt wie viel geiler...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>1130840578860748800</td>\n",
              "      <td>RT @deutsch365: ‼️‼️ Donald Trump Das deutsche...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>1124533499082551296</td>\n",
              "      <td>RT @Textvergessen: Ich bin auch Organspender. ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>1132712970692255745</td>\n",
              "      <td>@MzudemOffiziell Willkommen zurück??</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1771</th>\n",
              "      <td>1131281295366131712</td>\n",
              "      <td>@dieserbutzi Ich Neonlicht einfach Christine u...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1311</th>\n",
              "      <td>1124383762433884161</td>\n",
              "      <td>@BenKTallmadge Scheisse!</td>\n",
              "      <td>NOT</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                  ID\n",
              "1631  1133418909816766467  ...   hasoc_2020_de_820\n",
              "820   1131662981215997955  ...  hasoc_2020_de_2389\n",
              "1227  1124354788186099713  ...  hasoc_2020_de_2833\n",
              "1407  1131979881854713858  ...  hasoc_2020_de_2865\n",
              "2273  1131642005501685761  ...  hasoc_2020_de_1580\n",
              "2402  1130840578860748800  ...  hasoc_2020_de_2046\n",
              "396   1124533499082551296  ...   hasoc_2020_de_325\n",
              "593   1132712970692255745  ...   hasoc_2020_de_365\n",
              "1771  1131281295366131712  ...   hasoc_2020_de_454\n",
              "1311  1124383762433884161  ...   hasoc_2020_de_600\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo60AHM91IeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ad765af9-57fb-4ec8-cf10-e627d887219f"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "df['task1'] = LE.fit_transform(df['task1'])\n",
        "df['task2'] = LE.fit_transform(df['task2'])\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1133388798925189122</td>\n",
              "      <td>Deutsche rothaarige porno reife deutsche fraue...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1131117000279961600</td>\n",
              "      <td>Lehrstück auch, wie in der linken Jammerfemini...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1127134592517980161</td>\n",
              "      <td>RT @NDRinfo: Die deutsche Klimaaktivistin Luis...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_1042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1128897106171842560</td>\n",
              "      <td>@ruhrbahn jeden Morgen eine neue „Fahrzeugstör...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1123576753199484928</td>\n",
              "      <td>@Junge_Freiheit Die Inkas hatten sich schon dä...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...                  ID\n",
              "0  1133388798925189122  ...  hasoc_2020_de_2684\n",
              "1  1131117000279961600  ...  hasoc_2020_de_2440\n",
              "2  1127134592517980161  ...  hasoc_2020_de_1042\n",
              "3  1128897106171842560  ...   hasoc_2020_de_774\n",
              "4  1123576753199484928  ...   hasoc_2020_de_559\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrWazNo1LoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d0b0504-638e-4291-bd1c-2de8d09768d0"
      },
      "source": [
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "df.text.apply(count_words).max()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ULzJBy1Paa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 74"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCg277B18qw",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the Dataset\n",
        "\n",
        "And then extracting the posts and tasks from that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y3XmMr3ZidE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = []\n",
        "for i in range(len(ged['tweet_raw_text'])):\n",
        "  tw = ged['tweet_raw_text'][i]\n",
        "  seg = ' '.join(ged['segmented_hash'][i])\n",
        "  tmp.append(tw+seg)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tEuNZX1NuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(tmp, get_task(ged['task_1']), test_size=0.2)\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['task1'], test_size=0.2, stratify=df['task1'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmPE59dv1QvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = train_x.values\n",
        "# categories = train_y.values\n",
        "posts = train_x\n",
        "categories = train_y"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu-_UGz81Szr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b110260-dc53-4662-f0dd-f5acc8c89947"
      },
      "source": [
        "ged['segmented_hash']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['esc 2019', 'iceland'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel', 'kundgebug', 'wuppertal', 'repression', ''],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['nwbrb 58'],\n",
              " [],\n",
              " ['nazis', 'linke', 'sozialisten', 'antifanten', 'krim in ellen', 'antifa'],\n",
              " ['benziner', 'diesel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['do they know its europe'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['europawahl 2019', 'weber', 'wahlarena'],\n",
              " [],\n",
              " [],\n",
              " ['esco rf'],\n",
              " [],\n",
              " [],\n",
              " ['scheisse', 'fusion bleibt'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['unser wir'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['hofheim'],\n",
              " [],\n",
              " ['educa aun fifi'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['europawahl 2019'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['grünen'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['sound cloud', 'np'],\n",
              " [],\n",
              " ['akk', 'merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['club 28'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['nihl'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['rezo', 'fake new'],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['hc smuss weg'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['aufstehen'],\n",
              " ['home for whovians'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['erstwähler'],\n",
              " [],\n",
              " [],\n",
              " ['eu wahl', 'massen', 'verbrecherinvasion', 'afd'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['grillen', 'grillkohle'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['identifikationmitdem aggressor'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['austauschschüler'],\n",
              " ['deutschland', 'pkk'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['aufschrei', 'link en'],\n",
              " ['nwbre 14'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['gay', 'ass', 'ass play', 'ff', 'fisting time', 'fisting', 'xyz'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['eu wahl 19'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['naziaufmärsche'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['birth strike'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['s bahn stgt'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['kandidatencheck', 'europawahl 2019'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['akk', 'merkel', 'merkel'],\n",
              " [],\n",
              " ['haltung'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['amthor'],\n",
              " [],\n",
              " ['grautöne'],\n",
              " [],\n",
              " ['grüne', 'grünen'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['anwalt', 'merkel', 'voelkermord'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['gabriel'],\n",
              " ['betze'],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " ['free speech friday', 'fight the censors', 'pjnet', 'tcot'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['migrations'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['linear'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['unternehmensgeschichte'],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['direktflug', 'fachkräfte', 'dauerrentner'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['özil', 'erdogan'],\n",
              " [],\n",
              " ['linke', 'grüne'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['england'],\n",
              " [],\n",
              " ['grünen', 'grün'],\n",
              " ['europawahl 2019', 'plauen0105', 'plau'],\n",
              " [],\n",
              " ['zdf', 'me in erstes mal', 'e kel haft'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['buntland'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['product design', 'design thinking', 'design inspiration', 'graphic'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['sound cloud', 'np'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['gz sz'],\n",
              " ['ajax o 19'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['terror', 'lyon'],\n",
              " [],\n",
              " [],\n",
              " ['piraten'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['flüchtlinge'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['geht waehlen'],\n",
              " ['linken', 'geht waehlen', 'brandenburg'],\n",
              " [],\n",
              " [],\n",
              " ['grünen', 'europawahl 2019', 'no grüne', 'no eu'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['wir sind mehr'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['beweis', 'grünen', 'spd', 'lüge'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['milchkühe'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['maschinia 2024', 'fcn', 'mathenia'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['nazis raus'],\n",
              " ['grundgesetz', 'juhuu'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['fridays for future'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['direktflug', 'fachkräfte', 'dauerrentner'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['relotiuspresse', 'relotiuspresse', 'relotiuspresse', 're'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['pflegesystem'],\n",
              " [],\n",
              " ['du0105'],\n",
              " [],\n",
              " ['merkel', 'harvard', 'trump'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['fresnillo', 'silberproduzent'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['kippa'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['af d', 'no af d', 'nazis raus', 'fckafd'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['nsfw', 'rt'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['honecker'],\n",
              " [],\n",
              " ['abi2019'],\n",
              " [],\n",
              " [],\n",
              " ['trades feed'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['das perfekt e dinner'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel', 'g 5 sahel', 'burkina faso'],\n",
              " [],\n",
              " [],\n",
              " ['front al21'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['europawahl 2019'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['eu wahl 2019'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['co 2'],\n",
              " ['türkei', 'imamoglu'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['rootserver'],\n",
              " [],\n",
              " ['erziehung', 'zofe', 'nylonkittel', 'wunder', 'brav'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['berlin', 'linken', 'grünen', 'starke schulden'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['dasperfekte dinner'],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['strache', 'merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['fdj', 'merkel', 'harvard'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['reconquista internet'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['fck afd'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['ehrenkirchen'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['leipzig', 'srwle19'],\n",
              " [],\n",
              " [],\n",
              " ['niewieder cducsuspd grüne fdp linke'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['t'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['fani', 'indien'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['grüne', 'kolumbien'],\n",
              " ['zdf', 'europawahl 2019'],\n",
              " [],\n",
              " [],\n",
              " ['amthor video'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['strache', 'oesterreich'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['gnt m finale', 'gntm'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['team quintus'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['freierfeiertag',\n",
              "  'after work',\n",
              "  'cheers',\n",
              "  'it s aperol o clock',\n",
              "  'our hood',\n",
              "  'lieblings nach bar'],\n",
              " ['anti rauch er', 'black and white photography'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['pack', 'chico desnudo', 'destroys boys'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['kühnert', 'grünen'],\n",
              " [],\n",
              " [],\n",
              " ['malaysia', 'müll', 'abfa'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['wissenschaftler', 'ergebnissen'],\n",
              " [],\n",
              " [],\n",
              " ['gersvk', 'eishockey wm'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel', 'harvard', 'trump', 'akk'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['vatertag'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['ableism us'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['google alerts'],\n",
              " ['elektro f lie ger'],\n",
              " ['antifa', 'hitler'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['now playing'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['frau'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['votes trac he'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['n 26', 'ba fin'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['dennsiewissennichtwaspassiert'],\n",
              " [],\n",
              " ['epp el heim', 'frisör'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['rezo', 'amthor video', 'nie mehr cdu', 'co 2 steu'],\n",
              " ['nazis', 'nazis raus'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['af d', 'ard', 'zdf'],\n",
              " [],\n",
              " ['merkel'],\n",
              " [],\n",
              " [],\n",
              " ['porsche', 'porsches'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['kahrs'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['merkel', 'harvard', 'trump', 'cnn', 'trum'],\n",
              " ['europa', 'deutschland'],\n",
              " [],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2VP_v-3D9r",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Data\n",
        "\n",
        "Into BERT-type preprocessed things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6GFCCa1Tse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "89d775cf-7c94-4b77-a103-1ee7dcd2c17a"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNv-M4V3NhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f8bd71e6-f7c7-405c-8eb3-b5e24f850673"
      },
      "source": [
        "print('Original: ', posts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Es ist halt ziemlich sinnfrei, l in einen l-Tank fllen zu wollen, wenn man gar nicht wegfahren mchte...\n",
            "Token IDs: tensor([ 102,  233,  207, 5392, 6016, 3896, 2256,  806,  155,  142,  366,  155,\n",
            "         223, 9242,  525, 3693,  167, 1670,  806,  509,  420, 1186,  237, 1261,\n",
            "        1088, 6707, 4061,  552,  552,  552,  103,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Wc-M043Nrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6d88e383-843a-447b-8f45-02646c11eded"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.875 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,660 training samples\n",
            "  238 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrb2Ypi3NpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcBb8t383Nnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4484b2c31e6646fc894d790a8f7b688a",
            "f4335cf6820249c0bc8e3df0907d58e1",
            "117bf75c67e14c8595cb00504dfdd812",
            "53e15abf7046466fb80eeb4fde6c424d",
            "4f63f39fab894e4792039d09edd86bc3",
            "45db729fec594935ab050e86a912f6bd",
            "03ff75fcef184e5cbdcc68b2f6b6cd90",
            "9c48935c27204118a1b6a4fd9ec94f6d",
            "abe888e535884729a3fff8618596f280",
            "53e827c668f64831bc7076bcee1b06cc",
            "fae58794193246dea13954ae63962d10",
            "36d5c11e8a944aae86a2ac3f3dd2b5fe",
            "3ebbbe6bba04418d9dee94cdb3350c6e",
            "7b009534db3a40b7b2f6302c4373787b",
            "575e4a62665a4c3a9d36a32920e04284",
            "9252bba2c1374ed395bbfb07fa36eabd"
          ]
        },
        "outputId": "b690a70a-4fa7-47f5-d498-e2408a49935a"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-german-dbmdz-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4484b2c31e6646fc894d790a8f7b688a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abe888e535884729a3fff8618596f280",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442256365.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-dbmdz-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DC_gcsJ3NlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "1ca1408d-1ebe-46ae-bc6c-5700cb90056d"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (31102, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (4, 768)\n",
            "classifier.bias                                                 (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiLVh19n9JFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "            )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DD-3nVZ9JDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVGWrc19JBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HovaG5-9I-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdSKj6Jo9I5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "b6193d6b-4380-45d7-ebfe-70b7d09272c4"
      },
      "source": [
        "seed_val = 42\n",
        "torch.cuda.empty_cache()\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:34.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epoch took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:34.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:00:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:35.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 0:00:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:02:20 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmNsEOq9Unz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "698cfb98-3060-4b1b-9d67-1ec491b7b5c2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:44</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:00:44</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:45</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.59         0.38           0.86       0:00:44         0:00:02\n",
              "2               0.38         0.37           0.87       0:00:44         0:00:02\n",
              "3               0.27         0.38           0.86       0:00:45         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzoDddQ9Uj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "6449e5d1-5c84-465f-bcb9-7a9e1d982379"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQPpBsf9Ug_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = valid_x.values\n",
        "# categories = valid_y.values\n",
        "posts = valid_x\n",
        "categories = valid_y"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UmpeSGX9Udu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "51019125-0ee9-466c-b5b4-7afbe59c82eb"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbqr33a9UZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2368c320-dbf9-4819-ede6-73f940a3cf12"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 475 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H6pRi5K9fag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "55b1d1a4-1a2c-4fea-aefc-13d530436bc1"
      },
      "source": [
        "print(predictions[0],true_labels[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4.071025    0.6455151  -2.5438023  -2.3961136 ]\n",
            " [ 4.4020004   0.3040659  -2.4348478  -2.342598  ]\n",
            " [ 4.4975443   0.46557128 -2.4041107  -2.4024696 ]\n",
            " [ 3.6756544   1.2394006  -2.58248    -2.589711  ]\n",
            " [ 3.1920457   2.4315987  -2.6532192  -2.999734  ]\n",
            " [ 3.864484    1.1618338  -2.5666502  -2.835919  ]\n",
            " [ 4.289539    1.1265717  -2.5175567  -2.6631355 ]\n",
            " [ 4.3015327   0.6329232  -2.3247786  -2.5645065 ]\n",
            " [ 1.2594702   3.3216412  -2.40835    -2.1632197 ]\n",
            " [ 4.167192   -0.39152682 -1.7839669  -1.9591285 ]\n",
            " [ 4.370276    0.8659677  -2.7009006  -2.5919697 ]\n",
            " [ 3.8940725   0.9836284  -2.72088    -2.5111277 ]\n",
            " [ 3.2045863   1.6445718  -2.8445334  -2.6958463 ]\n",
            " [ 3.6955254   1.5767964  -2.7940385  -2.7577724 ]\n",
            " [ 3.4214916   2.1309576  -2.9816935  -2.8397632 ]\n",
            " [-0.41699484  3.7179573  -1.7409167  -1.6039004 ]] [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-g-1py9g2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "24dcd737-82b6-4b21-bc76-2ea8e0ee060a"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "predicts = []\n",
        "accurate = 0\n",
        "total_len = 0\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "    # in to a list of 0s and 1s.\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    predicts.append(pred_labels_i)\n",
        "    # Calculate and store the coef for this batch.  \n",
        "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "\n",
        "    matthews_set.append(matthews)\n",
        "    for j in range(len(true_labels[i])):\n",
        "        if true_labels[i][j] == pred_labels_i[j]:\n",
        "            accurate+=1\n",
        "        total_len+=1\n",
        "print(\"Accuracy:\",accurate/total_len)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Accuracy: 0.848421052631579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6oFj1N9h_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e16b9516-9f31-49f5-beea-b0ca51505d3b"
      },
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fh7Aa1n9jUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1577df87-6e87-49f5-9fff-f52c283703a9"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBWPnpv9kgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8369ebff-9ab1-415c-8efb-bee166b92527"
      },
      "source": [
        "accurate = 0\n",
        "for (i,j) in zip(flat_predictions, flat_true_labels):\n",
        "    if i==j:\n",
        "        accurate += 1\n",
        "accurate/len(flat_predictions)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.848421052631579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHaUWhL9lpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2e4c82e-dfa3-4a4c-a216-d473855fa731"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8137254901960784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXrjmeWh9q7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    }
  ]
}