{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC BE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7f2ccb199a54586a519b36dc7c858ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f09dc444315e46e5b3cb2a80ea9937ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0201d3e829749f393dd88d0b2a41591",
              "IPY_MODEL_6958a94a459b434a92c2491659cdbc41"
            ]
          }
        },
        "f09dc444315e46e5b3cb2a80ea9937ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0201d3e829749f393dd88d0b2a41591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_168954e6f8a4463aadc21830a93257d6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 541,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 541,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60fa0dec0ce5411ab2f8028c70fe113f"
          }
        },
        "6958a94a459b434a92c2491659cdbc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aea53bd325f3431a87be7e45ee7dfe6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 541/541 [00:52&lt;00:00, 10.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97b6b0dfe66348e8b13b5ba38c9a80a6"
          }
        },
        "168954e6f8a4463aadc21830a93257d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60fa0dec0ce5411ab2f8028c70fe113f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aea53bd325f3431a87be7e45ee7dfe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97b6b0dfe66348e8b13b5ba38c9a80a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "833efcc550414ad8b054e93d44c52d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16c8c0cbdcc541ea8f2d28948cc4f9b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7287c0a842224fe4bea3465ff5327187",
              "IPY_MODEL_afc98f72310a421c98e098e618b12977"
            ]
          }
        },
        "16c8c0cbdcc541ea8f2d28948cc4f9b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7287c0a842224fe4bea3465ff5327187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca282cc210954e9e8db76b8cd673f2e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b3c39bae66c473186b7a4e78bff5105"
          }
        },
        "afc98f72310a421c98e098e618b12977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf4c6f141bff4eb2b40e6fc62969fb49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:06&lt;00:00, 749kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d095ff77ca14f1abc447d7127c812da"
          }
        },
        "ca282cc210954e9e8db76b8cd673f2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b3c39bae66c473186b7a4e78bff5105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf4c6f141bff4eb2b40e6fc62969fb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d095ff77ca14f1abc447d7127c812da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ead82938d194cbc9cf2cd74744c61d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce6fb22e841f42388f0014595c610a02",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df6253ad45b64061a1d87f30284e8c7c",
              "IPY_MODEL_210aeb94211a4fa6abc23c8ebb2a8596"
            ]
          }
        },
        "ce6fb22e841f42388f0014595c610a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df6253ad45b64061a1d87f30284e8c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b7e88dd1fb546909eb46c4484e06976",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f2c752eba75442380d36d33eb7a9af9"
          }
        },
        "210aeb94211a4fa6abc23c8ebb2a8596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cfe84beb36849a7a07fee0997d7ad9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [00:01&lt;00:00, 78.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea4a8a2bf03143fd95bbc3ee91c875f4"
          }
        },
        "4b7e88dd1fb546909eb46c4484e06976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f2c752eba75442380d36d33eb7a9af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cfe84beb36849a7a07fee0997d7ad9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea4a8a2bf03143fd95bbc3ee91c875f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "145bddf270d34ad084fd792914ecca57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_caf774ebee7948c7ad13a5e403169ab6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e4b9f48795b4e3a87e26dd641a70b58",
              "IPY_MODEL_be276de284b34bc8b7ad944b70dc67dc"
            ]
          }
        },
        "caf774ebee7948c7ad13a5e403169ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e4b9f48795b4e3a87e26dd641a70b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_711d6cd306c548b8b4c51abf8e56088c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 147,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 147,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b571b44254834bdf8d04ef20f3e5ae06"
          }
        },
        "be276de284b34bc8b7ad944b70dc67dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac696f01d9da4e68936f3d89f67de05c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 147/147 [00:43&lt;00:00, 3.40B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5688d8ce909247aeb373c5c720a5d0d3"
          }
        },
        "711d6cd306c548b8b4c51abf8e56088c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b571b44254834bdf8d04ef20f3e5ae06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac696f01d9da4e68936f3d89f67de05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5688d8ce909247aeb373c5c720a5d0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/HASOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymx75g3TKBPu",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusydJSf1JWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0d619c5-a1ec-4aed-e8d2-6b84bdfc2df3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkgSSbTKFnl",
        "colab_type": "text"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5k6sJxMId20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d401d772-cbc9-4753-d2c8-de5ed9f5f835"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers\n",
        "!pip install seaborn\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U sentence-transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.9.7)\n",
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mJWYRNKH7l",
        "colab_type": "text"
      },
      "source": [
        "# Get imports\n",
        "\n",
        "- **General:** random, pickle, re, time, datetime\n",
        "- **General DS:** pandas, numpy, sklearn, matplotlib, seaborn, nltk\n",
        "- **Deep Learning:** torch, transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0yrIDfJZaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk36oE5Lrg9W",
        "colab_type": "text"
      },
      "source": [
        "# GPU device Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gcXgxjBfAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0b2a3c86-2c85-4e20-c582-a07d589840ff"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKl5AjVg2GGu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtF92-5O1kHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = '/content/drive/My Drive/2020_processed_data/'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnNe1bM1vaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(DATASET_ROOT+'hi.pickle', 'rb') as f:\n",
        "  ged = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MXmbq82tfXr",
        "colab_type": "text"
      },
      "source": [
        "Checking it once for content description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLKtbO3yBD-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ddd2ec9-2fcc-4a9f-f2b6-5d914b986921"
      },
      "source": [
        "ged.keys()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_id', 'task_1', 'task_2', 'hasoc_id', 'full_tweet', 'tweet_raw_text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlOlcu0QWM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9723a8a0-2e1f-4cdf-d925-284184baaabe"
      },
      "source": [
        "ged['task_1'][:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HOF', 'NOT', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'HOF', 'NOT', 'NOT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSohluLctjzO",
        "colab_type": "text"
      },
      "source": [
        "## Split data into train-test-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXL1bHONOQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train1_hash = ged['segmented_hash'][:2000]\n",
        "# test1_hash = ged['segmented_hash'][2000:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYE1Uvx2O35x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_hash = []\n",
        "# for lis in train1_hash:\n",
        "#   train_hash.append(' '.join(lis))\n",
        "# test_hash = []\n",
        "# for lis in test1_hash:\n",
        "#   test_hash.append(' '.join(lis))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyLubZmQuGzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text, test_text, train_t1s, test_t1s = model_selection.train_test_split(\n",
        "#     ged['tweet_raw_text'],\n",
        "#     ged['task_1'],\n",
        "#     test_size = 0.2,\n",
        "#     # random_state = 42\n",
        "# )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoKUgiqgtag5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text = ged['tweet_raw_text'][:2000]\n",
        "# train_t1s = ged['task_1'][:2000]\n",
        "\n",
        "# test_text = ged['tweet_raw_text'][2000:]\n",
        "# test_t1s = ged['task_1'][2000:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwhRamhzzZRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame.from_dict(ged)\n",
        "# df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub6jEswMzlcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNTWBGA0tnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1_hash = list(train_df['segmented_hash'])\n",
        "test1_hash = list(test_df['segmented_hash'])\n",
        "train_hash = []\n",
        "for lis in train1_hash:\n",
        "  train_hash.append(' '.join(lis))\n",
        "test_hash = []\n",
        "for lis in test1_hash:\n",
        "  test_hash.append(' '.join(lis))\n",
        "train_text = list(train_df['tweet_raw_text'])\n",
        "train_t1s = list(train_df['task_1'])\n",
        "\n",
        "test_text = list(test_df['tweet_raw_text'])\n",
        "test_t1s = list(test_df['task_1'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_XcLvgGqafu",
        "colab_type": "text"
      },
      "source": [
        "# get Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8BMAterqu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(embeddings):\n",
        "  # emb = []\n",
        "  # for e in embeddings:\n",
        "  #   emb.append({'feat': e})\n",
        "  emb = embeddings\n",
        "  return emb"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jmwjber44S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_task(tasklist, taskType = 1):\n",
        "  newtasks = []\n",
        "  if taskType == 2:\n",
        "    for x in tasklist:\n",
        "      if x == \"NONE\":\n",
        "        newtasks.append(0)\n",
        "      elif x == \"HATE\":\n",
        "        newtasks.append(1)\n",
        "      elif x == \"PRFN\":\n",
        "        newtasks.append(2)\n",
        "      elif x == \"OFFN\":\n",
        "        newtasks.append(3)\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "  else:\n",
        "    for x in tasklist:\n",
        "      if x == 'NOT':\n",
        "        # newtasks.append(['0'])\n",
        "        newtasks.append(0)\n",
        "      elif x ==\"HOF\":\n",
        "        # newtasks.append(['1'])\n",
        "        newtasks.append(1)\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "\n",
        "  return newtasks"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXhZ-jlRdzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "869883fe-4820-465b-9110-cb5f4ae45716"
      },
      "source": [
        "import gensim.models as gsm\n",
        "e2v = gsm.KeyedVectors.load_word2vec_format('emoji2vec.bin', binary=True)\n",
        "# happy_vector = e2v['😂']    # Produces an embedding vector of length 300\n",
        "\n",
        "# Download the bin file from here https://github.com/uclnlp/emoji2vec/blob/master/pre-trained/emoji2vec.bin\n",
        "\n",
        "def getEmojiEmbeddings(emojiList,dim=300,verbose = False):\n",
        "  \"\"\" Generates an emoji vector by averaging the emoji representation for each emoji. If no emoji returns an empty list of dimension dim\"\"\"\n",
        "  if dim < 300:\n",
        "    raise IndexError(\"Dim has to be greater than 300\")\n",
        "  result = np.zeros(dim)\n",
        "  if (len(emojiList) == 0):\n",
        "    return result\n",
        "  else:\n",
        "    embs = None\n",
        "    for i in emojiList:\n",
        "      if verbose:\n",
        "        if i not in e2v.vocab:\n",
        "          print(i)\n",
        "    embs = np.mean([e2v[i] for i in emojiList if i in e2v.vocab], axis=0)\n",
        "  if np.any(np.isnan(embs)):\n",
        "    return result\n",
        "  result[:300] = embs\n",
        "  return result \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K9SOt3i1ihL",
        "colab_type": "text"
      },
      "source": [
        "# Ablation Studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXrjmeWh9q7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "e7f2ccb199a54586a519b36dc7c858ce",
            "f09dc444315e46e5b3cb2a80ea9937ba",
            "d0201d3e829749f393dd88d0b2a41591",
            "6958a94a459b434a92c2491659cdbc41",
            "168954e6f8a4463aadc21830a93257d6",
            "60fa0dec0ce5411ab2f8028c70fe113f",
            "aea53bd325f3431a87be7e45ee7dfe6a",
            "97b6b0dfe66348e8b13b5ba38c9a80a6",
            "833efcc550414ad8b054e93d44c52d05",
            "16c8c0cbdcc541ea8f2d28948cc4f9b4",
            "7287c0a842224fe4bea3465ff5327187",
            "afc98f72310a421c98e098e618b12977",
            "ca282cc210954e9e8db76b8cd673f2e5",
            "2b3c39bae66c473186b7a4e78bff5105",
            "bf4c6f141bff4eb2b40e6fc62969fb49",
            "5d095ff77ca14f1abc447d7127c812da",
            "4ead82938d194cbc9cf2cd74744c61d9",
            "ce6fb22e841f42388f0014595c610a02",
            "df6253ad45b64061a1d87f30284e8c7c",
            "210aeb94211a4fa6abc23c8ebb2a8596",
            "4b7e88dd1fb546909eb46c4484e06976",
            "6f2c752eba75442380d36d33eb7a9af9",
            "5cfe84beb36849a7a07fee0997d7ad9a",
            "ea4a8a2bf03143fd95bbc3ee91c875f4",
            "145bddf270d34ad084fd792914ecca57",
            "caf774ebee7948c7ad13a5e403169ab6",
            "5e4b9f48795b4e3a87e26dd641a70b58",
            "be276de284b34bc8b7ad944b70dc67dc",
            "711d6cd306c548b8b4c51abf8e56088c",
            "b571b44254834bdf8d04ef20f3e5ae06",
            "ac696f01d9da4e68936f3d89f67de05c",
            "5688d8ce909247aeb373c5c720a5d0d3"
          ]
        },
        "outputId": "98cab9b1-a752-424c-a6b6-8ed53d36bf7a"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens\")\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f2ccb199a54586a519b36dc7c858ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "833efcc550414ad8b054e93d44c52d05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ead82938d194cbc9cf2cd74744c61d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "145bddf270d34ad084fd792914ecca57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=147.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CYez461hZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "a = []\n",
        "b = []\n",
        "def trainModelWithFeatures(train_df,test_df, hashtags=True, emojis=True, verbose = False):\n",
        "  \"\"\" Function to train a model on a specific configuration of features \"\"\"\n",
        "  global a\n",
        "  global b\n",
        "  train1_hash = list(train_df['segmented_hash'])\n",
        "  test1_hash = list(test_df['segmented_hash'])\n",
        "  train_hash = []\n",
        "  for lis in train1_hash:\n",
        "    train_hash.append(' '.join(lis))\n",
        "  test_hash = []\n",
        "  for lis in test1_hash:\n",
        "    test_hash.append(' '.join(lis))\n",
        "  train_text = list(train_df['tweet_raw_text'])\n",
        "  train_t1s = list(train_df['task_1'])\n",
        "  train_t2s =  list(train_df['task_2'])\n",
        "\n",
        "  test_text = list(test_df['tweet_raw_text'])\n",
        "  test_t1s = list(test_df['task_1'])\n",
        "  test_t2s = list(test_df['task_2'])\n",
        "\n",
        "  if verbose:\n",
        "    print(\"Started getting text embeddings\")\n",
        "  train_embeddings = sent_encoder.encode(train_text)\n",
        "  test_embeddings = sent_encoder.encode(test_text)\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the text embeddings\")\n",
        "  train_t1 = get_task(train_t1s)\n",
        "  train_t2 = get_task(train_t2s, 2)\n",
        "  \n",
        "  test_t1 = get_task(test_t1s)\n",
        "  test_t2 = get_task(test_t2s,2)\n",
        "\n",
        "  train_emb = get_features(train_embeddings)\n",
        "  test_emb = get_features(test_embeddings)\n",
        "  if hashtags:\n",
        "    if verbose:\n",
        "      print(\"Started getting hash embeddings\")\n",
        "    train_hashembeddings = sent_encoder.encode(train_hash)\n",
        "    test_hashembeddings = sent_encoder.encode(test_hash)\n",
        "    train_emb = np.concatenate((train_emb , train_hashembeddings), axis = 1)\n",
        "    test_emb =  np.concatenate((test_emb , test_hashembeddings), axis = 1)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the hash embeddings\")\n",
        "  if emojis:\n",
        "    if verbose:\n",
        "      print(\"Started getting emoji embeddings\")\n",
        "    train_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(train_df['emoji']))])\n",
        "    test_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(test_df['emoji']))])\n",
        "    train_emb = np.concatenate((train_emb , train_emojiEmbs), axis = 1)\n",
        "    test_emb = np.concatenate((test_emb , test_emojiEmbs), axis = 1)\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the emoji embeddings\")\n",
        "  a = train_emb\n",
        "  b = test_emb\n",
        "  assert (train_t2 != test_t2)\n",
        "  clf1 = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)\n",
        "  clf2 =  MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t2)\n",
        "  if verbose:\n",
        "    print(\"Finsihed training classifier\")\n",
        "  pred_test_t1 = clf1.predict(test_emb)\n",
        "  pred_test_t2 = clf2.predict(test_emb)\n",
        "\n",
        "  print(\"Task 1\")\n",
        "  print(classification_report(test_t1, pred_test_t1))\n",
        "  print(\"Task 2\")\n",
        "  print(classification_report(test_t2, pred_test_t2))\n",
        "\n",
        "  return clf1,clf2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqkF55RX303E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(lang):\n",
        "  \"\"\" Function to load data for one language from the preprocessed pickle file\"\"\"\n",
        "  if lang not in ['hi','en','ge']:\n",
        "      raise NameError(\"Language not found\")\n",
        "  fileName = lang + '.pickle'\n",
        "  with open(DATASET_ROOT+fileName, 'rb') as f:\n",
        "    ged = pickle.load(f)\n",
        "  df = pd.DataFrame.from_dict(ged)\n",
        "  train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)\n",
        "  return train_df, test_df, df\n",
        "\n",
        "def loadDataAllLangs():\n",
        "  \"\"\" Function to load data for all languages from the preprocessed pickle file\"\"\"\n",
        "\n",
        "  hi_train,hi_test,hi_df = loadData('hi')\n",
        "  en_train,en_test,en_df = loadData('en')\n",
        "  ge_train,ge_test,ge_df = loadData('ge')\n",
        "  train_df = pd.concat([hi_train,en_train,ge_train],ignore_index=True)\n",
        "  test_df =  pd.concat([hi_test,en_test,ge_test],ignore_index=True)\n",
        "  df = pd.concat([hi_df,en_df,ge_df],ignore_index=True)\n",
        "  train_df = train_df.sample(frac = 1, random_state=42)\n",
        "  test_df = test_df.sample(frac = 1, random_state=42)\n",
        "  df = df.sample(frac = 1, random_state=42)\n",
        "  return train_df,test_df,df\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdtrgDk18sNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df, df = loadDataAllLangs()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQ1qlfM9CdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "6bb6e016-7118-4a52-f0c8-88302d76b73f"
      },
      "source": [
        "clf1,clf2 = trainModelWithFeatures(train_df,test_df,  verbose = False)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Task 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82      1386\n",
            "           1       0.73      0.64      0.68       876\n",
            "\n",
            "    accuracy                           0.77      2262\n",
            "   macro avg       0.76      0.75      0.75      2262\n",
            "weighted avg       0.77      0.77      0.77      2262\n",
            "\n",
            "Task 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.81      1386\n",
            "           1       0.25      0.25      0.25       130\n",
            "           2       0.62      0.65      0.63       508\n",
            "           3       0.34      0.23      0.27       238\n",
            "\n",
            "    accuracy                           0.69      2262\n",
            "   macro avg       0.50      0.49      0.49      2262\n",
            "weighted avg       0.68      0.69      0.68      2262\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AEBfX0BHk7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performAblations(train_df, test_df,features = [\"hashtags\", \"emojis\"], verbose = False):\n",
        "  \"\"\" Perform Ablation studies on the given set of features \"\"\"\n",
        "  for i in features:\n",
        "    if i not in [\"hashtags\", \"emojis\"]:\n",
        "      raise NameError(\"Wrong set of features. \")\n",
        " # TODO Make it more extensible \n",
        "  results = {}\n",
        "  print(\"all\")\n",
        "  results[\"hash+emoji\"] = trainModelWithFeatures(train_df,test_df,  verbose = verbose)\n",
        "  print(\"hash\")\n",
        "  results[\"hash\"] = trainModelWithFeatures(train_df,test_df,emojis=False, verbose = verbose)\n",
        "  print(\"emoji\")\n",
        "  results[\"emoji\"] = trainModelWithFeatures(train_df,test_df,hashtags=False, verbose = verbose)\n",
        "  print(\"vanilla\")\n",
        "  results[\"vanilla\"] = trainModelWithFeatures(train_df,test_df,hashtags=False,emojis=False, verbose = verbose)\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47VtJ99RI2l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "0eae4ef3-7ed9-4bf5-aaf3-03139254053a"
      },
      "source": [
        "r = performAblations(train_df, test_df,features = [\"hashtags\", \"emojis\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       523\n",
            "           1       0.56      0.51      0.53       218\n",
            "\n",
            "    accuracy                           0.74       741\n",
            "   macro avg       0.68      0.67      0.68       741\n",
            "weighted avg       0.73      0.74      0.73       741\n",
            "\n",
            "hash\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       523\n",
            "           1       0.55      0.52      0.53       218\n",
            "\n",
            "    accuracy                           0.73       741\n",
            "   macro avg       0.68      0.67      0.67       741\n",
            "weighted avg       0.73      0.73      0.73       741\n",
            "\n",
            "emoji\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       523\n",
            "           1       0.56      0.56      0.56       218\n",
            "\n",
            "    accuracy                           0.74       741\n",
            "   macro avg       0.69      0.69      0.69       741\n",
            "weighted avg       0.74      0.74      0.74       741\n",
            "\n",
            "vanilla\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.83       523\n",
            "           1       0.61      0.42      0.50       218\n",
            "\n",
            "    accuracy                           0.75       741\n",
            "   macro avg       0.70      0.66      0.67       741\n",
            "weighted avg       0.74      0.75      0.74       741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mDtiufnI7Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42694126-1c5d-428b-cfa6-ed54bd0f6dfd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSK-ZMaGI8lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvBW4-cJYjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVs6Hx7Jcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr78Lk7-08Hc",
        "colab_type": "text"
      },
      "source": [
        "# Pure BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzI760g1lQd",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "Loading the dataset into a dataframe, then transforming the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAcmEjoxrx4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = '/content/drive/My Drive/HASOC/Data/2020_train_sets/hasoc_2020_de_train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxX_2glrxqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "bbb41d5a-2855-49ab-973a-7608702146b0"
      },
      "source": [
        "df = pd.read_csv(DATASET_PATH)\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,452\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2114</th>\n",
              "      <td>1124994968999858176</td>\n",
              "      <td>@dabiggapicta @twitpatli @operationlibero Stim...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>1133100503418703874</td>\n",
              "      <td>@iParaadox Das ist einfach anders</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1165</th>\n",
              "      <td>1131791712786030592</td>\n",
              "      <td>RT @DerZeroy: ich hab schon tweets gemacht da ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_de_114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>1125436117518626822</td>\n",
              "      <td>@tagesschau Dankeschön❤️🌙😽</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1626</th>\n",
              "      <td>1134494044162277377</td>\n",
              "      <td>RT @ohnenahme: @MalteKaufmann @Nobby1949Z Ich ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_1105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1134169870571098112</td>\n",
              "      <td>RT @hl_h2o: Komm,mein Herz,geh und leg dich wi...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>1125967141575057410</td>\n",
              "      <td>So ist es, und war es schon immer. Die Menschh...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1124469888272216065</td>\n",
              "      <td>@bineuerboss @shoutoutxobella Würde Arsch geben</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>1131202803140124672</td>\n",
              "      <td>in 🇱🇻 ballern jetzt einfach alle alle pointen ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>1128626259007660032</td>\n",
              "      <td>Daniel+Kermit &amp;gt; Red+Andy</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                  ID\n",
              "2114  1124994968999858176  ...  hasoc_2020_de_1027\n",
              "700   1133100503418703874  ...  hasoc_2020_de_1592\n",
              "1165  1131791712786030592  ...   hasoc_2020_de_114\n",
              "2416  1125436117518626822  ...  hasoc_2020_de_2238\n",
              "1626  1134494044162277377  ...  hasoc_2020_de_1105\n",
              "321   1134169870571098112  ...  hasoc_2020_de_1212\n",
              "1258  1125967141575057410  ...   hasoc_2020_de_200\n",
              "495   1124469888272216065  ...   hasoc_2020_de_996\n",
              "507   1131202803140124672  ...   hasoc_2020_de_758\n",
              "610   1128626259007660032  ...   hasoc_2020_de_381\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo60AHM91IeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cd153475-9f25-4bc7-b057-5815f04aea0d"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "df['task1'] = LE.fit_transform(df['task1'])\n",
        "df['task2'] = LE.fit_transform(df['task2'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1133388798925189122</td>\n",
              "      <td>Deutsche rothaarige porno reife deutsche fraue...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1131117000279961600</td>\n",
              "      <td>Lehrstück auch, wie in der linken Jammerfemini...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1127134592517980161</td>\n",
              "      <td>RT @NDRinfo: Die deutsche Klimaaktivistin Luis...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_1042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1128897106171842560</td>\n",
              "      <td>@ruhrbahn jeden Morgen eine neue „Fahrzeugstör...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1123576753199484928</td>\n",
              "      <td>@Junge_Freiheit Die Inkas hatten sich schon dä...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...                  ID\n",
              "0  1133388798925189122  ...  hasoc_2020_de_2684\n",
              "1  1131117000279961600  ...  hasoc_2020_de_2440\n",
              "2  1127134592517980161  ...  hasoc_2020_de_1042\n",
              "3  1128897106171842560  ...   hasoc_2020_de_774\n",
              "4  1123576753199484928  ...   hasoc_2020_de_559\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrWazNo1LoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52fc5127-6ec5-4fd7-e545-c029e27df164"
      },
      "source": [
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "df.text.apply(count_words).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ULzJBy1Paa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCg277B18qw",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the Dataset\n",
        "\n",
        "And then extracting the posts and tasks from that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tEuNZX1NuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(ged['tweet_raw_text'], get_task(ged['task_1']), test_size=0.2)\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['task1'], test_size=0.2, stratify=df['task1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmPE59dv1QvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = train_x.values\n",
        "# categories = train_y.values\n",
        "posts = train_x\n",
        "categories = train_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu-_UGz81Szr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2VP_v-3D9r",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Data\n",
        "\n",
        "Into BERT-type preprocessed things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6GFCCa1Tse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e07c910a-31c2-4d91-f3d8-fbdbb402af93"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNv-M4V3NhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "90ed3f31-e861-4175-b602-6bdee15eca69"
      },
      "source": [
        "# print('Original: ', posts[0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  : Die hat die Bekleidung der Schler im linken Bild als Uniformierung gewertet. Die Bekleidung der Nazis rechts h\n",
            "Token IDs: tensor([  102,   847,   125,   292,   125, 23474,   127,  2673, 30940,   197,\n",
            "         5782,  1282,   250, 22326,   603, 26678,   552,   125, 23474,   127,\n",
            "        22900,  1557,   134,   103,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Wc-M043Nrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "326626af-eb32-4104-f1fd-d9912ff35c9b"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.875 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# print('{:>5,} training samples'.format(train_size))\n",
        "# print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,660 training samples\n",
            "  238 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrb2Ypi3NpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcBb8t383Nnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99e82e6f-bc7b-42e5-ec7b-7fe2f126a321"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-german-dbmdz-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-dbmdz-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DC_gcsJ3NlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# params = list(model.named_parameters())\n",
        "\n",
        "# print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "# print('==== Embedding Layer ====\\n')\n",
        "\n",
        "# for p in params[0:5]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "# print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "# for p in params[5:21]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "# print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "# for p in params[-4:]:\n",
        "#     print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiLVh19n9JFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DD-3nVZ9JDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVGWrc19JBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HovaG5-9I-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdSKj6Jo9I5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "8f09bdaf-f642-4239-a01a-b1c51fe66bfa"
      },
      "source": [
        "seed_val = 42\n",
        "torch.cuda.empty_cache()\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epoch took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epoch took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:23 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmNsEOq9Unz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# pd.set_option('precision', 2)\n",
        "\n",
        "# df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# df_stats"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzoDddQ9Uj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "92549eb5-7d30-49eb-a26f-e8b0b1a3446b"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQPpBsf9Ug_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = valid_x.values\n",
        "# categories = valid_y.values\n",
        "posts = valid_x\n",
        "categories = valid_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UmpeSGX9Udu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9ba02b0c-edfa-4a1a-8dfa-8c382c50827e"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbqr33a9UZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7ae78fb0-67dd-44b0-ea2a-54003b567a4f"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 475 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H6pRi5K9fag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b6cc7328-de91-4cd9-a263-8efa4dcd6381"
      },
      "source": [
        "print(predictions[0],true_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.815918    0.67652035 -2.2650628  -2.2906172 ]\n",
            " [ 3.8203065   0.5583332  -2.6725311  -2.4873564 ]\n",
            " [ 3.9499502   0.24259631 -2.4285192  -2.5219963 ]\n",
            " [ 3.8023715   0.8992263  -2.5455017  -2.6608763 ]\n",
            " [ 3.5275538   0.95858186 -2.3949318  -2.4766378 ]\n",
            " [ 3.887617    0.8140077  -2.6724727  -2.5248737 ]\n",
            " [ 0.16910587  3.6695373  -2.1501563  -1.9946499 ]\n",
            " [ 3.9468524   0.59644496 -2.5063562  -2.649984  ]\n",
            " [ 3.4229798   1.6607033  -2.573406   -2.9573843 ]\n",
            " [ 3.6360824   0.6973718  -2.5745804  -2.4552243 ]\n",
            " [ 3.3757284   1.1719614  -2.5285096  -2.8608246 ]\n",
            " [ 2.4881876   2.7517326  -2.7661166  -2.5374627 ]\n",
            " [ 3.873526    1.1388052  -2.6257365  -2.922611  ]\n",
            " [ 1.1770823   3.7499785  -2.6348324  -2.4921196 ]\n",
            " [ 3.671365    0.7367661  -2.4249887  -2.6031053 ]\n",
            " [ 3.5447338   1.9936495  -2.782876   -2.8870366 ]] [0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-g-1py9g2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# matthews_set = []\n",
        "# predicts = []\n",
        "# accurate = 0\n",
        "# total_len = 0\n",
        "# # Evaluate each test batch using Matthew's correlation coefficient\n",
        "# print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# # For each input batch...\n",
        "# for i in range(len(true_labels)):\n",
        "#     # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "#     # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "#     # in to a list of 0s and 1s.\n",
        "#     pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "#     predicts.append(pred_labels_i)\n",
        "#     # Calculate and store the coef for this batch.  \n",
        "#     matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "\n",
        "#     matthews_set.append(matthews)\n",
        "#     for j in range(len(true_labels[i])):\n",
        "#         if true_labels[i][j] == pred_labels_i[j]:\n",
        "#             accurate+=1\n",
        "#         total_len+=1\n",
        "# print(\"Accuracy:\",accurate/total_len)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6oFj1N9h_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "# plt.title('MCC Score per Batch')\n",
        "# plt.ylabel('MCC Score (-1 to +1)')\n",
        "# plt.xlabel('Batch #')\n",
        "\n",
        "# plt.show()\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fh7Aa1n9jUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd6dbb7d-5b21-4d60-9157-be161ba58689"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBWPnpv9kgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d8e71b5-2556-4fa4-e327-5d8eee8ca3a2"
      },
      "source": [
        "accurate = 0\n",
        "for (i,j) in zip(flat_predictions, flat_true_labels):\n",
        "    if i==j:\n",
        "        accurate += 1\n",
        "accurate/len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8273684210526315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHaUWhL9lpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5ea681-9c14-4857-f434-b070142f2bfb"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.775094696969697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    }
  ]
}