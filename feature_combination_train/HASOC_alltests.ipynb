{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC_alltests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f4844a265fb46b2ac7bc3495203ed4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f7dfb4629c240b69132e4d5aa7c332d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09abbce550634a45ae3b891e030a12f8",
              "IPY_MODEL_d9bcd80d126d4ac2a031324d79b8a1fb"
            ]
          }
        },
        "6f7dfb4629c240b69132e4d5aa7c332d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09abbce550634a45ae3b891e030a12f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27edd6a1538c46f0aef7c69899acbfbe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 247333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 247333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af9f8a23eeee4f6cb9e9cbee8081a627"
          }
        },
        "d9bcd80d126d4ac2a031324d79b8a1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f50cda79879470a834193c725c928e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 247k/247k [00:00&lt;00:00, 1.59MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c22825422fd4fa8acf4a8f3ddae1e0a"
          }
        },
        "27edd6a1538c46f0aef7c69899acbfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af9f8a23eeee4f6cb9e9cbee8081a627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f50cda79879470a834193c725c928e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c22825422fd4fa8acf4a8f3ddae1e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36b8eeea93fa4d74ace74bf9eb501cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f39e5acab674eb191a1ad690312c6bb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_110e6e1655e941b28c92de002ea7a947",
              "IPY_MODEL_41c181fc244543f29affc0e1611b9f15"
            ]
          }
        },
        "9f39e5acab674eb191a1ad690312c6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "110e6e1655e941b28c92de002ea7a947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80bc1b33433f4472b34e917c1cf00c47",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76d0acb3ba3647a081a6915c51f1204b"
          }
        },
        "41c181fc244543f29affc0e1611b9f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5cc684216fcc4265ae0d62b4a9e94b51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 785B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea55906d911f473d9b27f1dac6f46ac3"
          }
        },
        "80bc1b33433f4472b34e917c1cf00c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76d0acb3ba3647a081a6915c51f1204b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cc684216fcc4265ae0d62b4a9e94b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea55906d911f473d9b27f1dac6f46ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b6eece69dfc44d78b830223fd4f1fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94b44bdb8dd342b0bc2b15d112c368f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bd978faf6604530b16f52ac1386cc96",
              "IPY_MODEL_ad755932caec4926b6d7623eca8ba814"
            ]
          }
        },
        "94b44bdb8dd342b0bc2b15d112c368f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bd978faf6604530b16f52ac1386cc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29a19cbabb0c4e8e86ee941e327104cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442256365,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442256365,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6efc8f6cbd084b7b8267c33131b14818"
          }
        },
        "ad755932caec4926b6d7623eca8ba814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0eb60a3ff694e46910544ed880512f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:28&lt;00:00, 15.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adcf12e5ffc149bea974f804368f8d7d"
          }
        },
        "29a19cbabb0c4e8e86ee941e327104cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6efc8f6cbd084b7b8267c33131b14818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0eb60a3ff694e46910544ed880512f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adcf12e5ffc149bea974f804368f8d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/HASOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymx75g3TKBPu",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusydJSf1JWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d1be08c-9cfd-4de0-e48b-bb36253295d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkgSSbTKFnl",
        "colab_type": "text"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5k6sJxMId20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81c7957d-403b-4a39-858a-7176259eeaae"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers\n",
        "!pip install seaborn\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U sentence-transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.15.0)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied, skipping upgrade: transformers<3.2.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.2.0,>=3.1.0->sentence-transformers) (0.8.1rc2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.2.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.2.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.2.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mJWYRNKH7l",
        "colab_type": "text"
      },
      "source": [
        "# Get imports\n",
        "\n",
        "- **General:** random, pickle, re, time, datetime\n",
        "- **General DS:** pandas, numpy, sklearn, matplotlib, seaborn, nltk\n",
        "- **Deep Learning:** torch, transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0yrIDfJZaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk36oE5Lrg9W",
        "colab_type": "text"
      },
      "source": [
        "# GPU device Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gcXgxjBfAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f243e0f1-3e76-43d6-d486-5ef802af722a"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKl5AjVg2GGu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset load setup and exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtF92-5O1kHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = '/content/drive/My Drive/HASOC/Data/2020_processed_data/'\n",
        "TEST_ROOT = '/content/drive/My Drive/HASOC/Data/2020_processed_test/'\n",
        "OUTPUT_ROOT = '/content/drive/My Drive/HASOC/Out/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34eBicH3p-Mc",
        "colab_type": "text"
      },
      "source": [
        "## Exploration with the German dataset\n",
        "\n",
        "This is not be used in the actual pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnNe1bM1vaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open(DATASET_ROOT+'ge.pickle', 'rb') as f:\n",
        "#   ged = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MXmbq82tfXr",
        "colab_type": "text"
      },
      "source": [
        "Checking it once for content description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLKtbO3yBD-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ged.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlOlcu0QWM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ged['task_1'][:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSohluLctjzO",
        "colab_type": "text"
      },
      "source": [
        "## Exploration: Split data into train-test-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXL1bHONOQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train1_hash = ged['segmented_hash'][:2000]\n",
        "# test1_hash = ged['segmented_hash'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYE1Uvx2O35x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_hash = []\n",
        "# for lis in train1_hash:\n",
        "#   train_hash.append(' '.join(lis))\n",
        "# test_hash = []\n",
        "# for lis in test1_hash:\n",
        "#   test_hash.append(' '.join(lis))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyLubZmQuGzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text, test_text, train_t1s, test_t1s = model_selection.train_test_split(\n",
        "#     ged['tweet_raw_text'],\n",
        "#     ged['task_1'],\n",
        "#     test_size = 0.2,\n",
        "#     # random_state = 42\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoKUgiqgtag5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text = ged['tweet_raw_text'][:2000]\n",
        "# train_t1s = ged['task_1'][:2000]\n",
        "\n",
        "# test_text = ged['tweet_raw_text'][2000:]\n",
        "# test_t1s = ged['task_1'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwhRamhzzZRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.DataFrame.from_dict(ged)\n",
        "# df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub6jEswMzlcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNTWBGA0tnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train1_hash = list(train_df['segmented_hash'])\n",
        "# test1_hash = list(test_df['segmented_hash'])\n",
        "# train_hash = []\n",
        "# for lis in train1_hash:\n",
        "#   train_hash.append(' '.join(lis))\n",
        "# test_hash = []\n",
        "# for lis in test1_hash:\n",
        "#   test_hash.append(' '.join(lis))\n",
        "# train_text = list(train_df['tweet_raw_text'])\n",
        "# train_t1s = list(train_df['task_1'])\n",
        "\n",
        "# test_text = list(test_df['tweet_raw_text'])\n",
        "# test_t1s = list(test_df['task_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsekPggYytDy",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_XcLvgGqafu",
        "colab_type": "text"
      },
      "source": [
        "## get Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8BMAterqu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(embeddings):\n",
        "  # emb = []\n",
        "  # for e in embeddings:\n",
        "  #   emb.append({'feat': e})\n",
        "  emb = embeddings\n",
        "  return emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jmwjber44S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_task(tasklist, taskType = 1):\n",
        "  newtasks = []\n",
        "  if taskType == 2:\n",
        "    for x in tasklist:\n",
        "      if x == \"NONE\":\n",
        "        newtasks.append(0)\n",
        "      elif x == \"HATE\":\n",
        "        newtasks.append(1)\n",
        "      elif x == \"PRFN\":\n",
        "        newtasks.append(2)\n",
        "      elif x == \"OFFN\":\n",
        "        newtasks.append(3)\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "  else:\n",
        "    for x in tasklist:\n",
        "      if x == 'NOT':\n",
        "        # newtasks.append(['0'])\n",
        "        newtasks.append(0)\n",
        "      elif x ==\"HOF\":\n",
        "        # newtasks.append(['1'])\n",
        "        newtasks.append(1)\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "\n",
        "  return newtasks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP8JO5dt8FVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tasks_reverse(tasklist, taskType = 1):\n",
        "  newtasks = []\n",
        "  if taskType == 2:\n",
        "    for x in tasklist:\n",
        "      # print(x)\n",
        "      if x == 0:\n",
        "        newtasks.append(\"NONE\")\n",
        "      elif x == 1:\n",
        "        newtasks.append(\"HATE\")\n",
        "      elif x == 2:\n",
        "        newtasks.append(\"PRFN\")\n",
        "      elif x == 3:\n",
        "        newtasks.append(\"OFFN\")\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "  else:\n",
        "    for x in tasklist:\n",
        "      # print(x)\n",
        "      if x == 0:\n",
        "        # newtasks.append(['0'])\n",
        "        newtasks.append(\"NOT\")\n",
        "      elif x == 1:\n",
        "        # newtasks.append(['1'])\n",
        "        newtasks.append(\"HOF\")\n",
        "      else:\n",
        "        raise NameError(\"Class not defined\")\n",
        "\n",
        "  return newtasks\n",
        "  # return tasklist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXhZ-jlRdzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "103f37f3-9a32-4514-f701-f946c49a43b8"
      },
      "source": [
        "import gensim.models as gsm\n",
        "e2v = gsm.KeyedVectors.load_word2vec_format('/content/drive/My Drive/HASOC/emoji2vec.bin', binary=True)\n",
        "# happy_vector = e2v['😂']    # Produces an embedding vector of length 300\n",
        "\n",
        "# Download the bin file from here https://github.com/uclnlp/emoji2vec/blob/master/pre-trained/emoji2vec.bin\n",
        "\n",
        "def getEmojiEmbeddings(emojiList,dim=300,verbose = False):\n",
        "  \"\"\" Generates an emoji vector by averaging the emoji representation for each emoji. If no emoji returns an empty list of dimension dim\"\"\"\n",
        "  if dim < 300:\n",
        "    raise IndexError(\"Dim has to be greater than 300\")\n",
        "  result = np.zeros(dim)\n",
        "  if (len(emojiList) == 0):\n",
        "    return result\n",
        "  else:\n",
        "    embs = None\n",
        "    for i in emojiList:\n",
        "      if verbose:\n",
        "        if i not in e2v.vocab:\n",
        "          print(i)\n",
        "    embs = np.mean([e2v[i] for i in emojiList if i in e2v.vocab], axis=0)\n",
        "  if np.any(np.isnan(embs)):\n",
        "    return result\n",
        "  result[:300] = embs\n",
        "  return result \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmwE8SQpw6oJ",
        "colab_type": "text"
      },
      "source": [
        "## Output formatter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHLT2XuZ57PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def writeOutput(test_df, language, test_pred_1, test_pred_2 = None, path=OUTPUT_ROOT):\n",
        "\n",
        "  if language == 'ge':\n",
        "    language = 'de'\n",
        "  lang = language.upper()\n",
        "  fprefix = 'submission_' + lang + '_'\n",
        "\n",
        "  # Get tweet ID and system (HASOC) id for tests:\n",
        "  test_tweet_ids = list(test_df['tweet_id'])\n",
        "  test_hasoc_ids = list(test_df['hasoc_id'])\n",
        "\n",
        "  print('Writing Task A')\n",
        "  fname = fprefix + 'A.csv'\n",
        "  fpath = path + fname\n",
        "\n",
        "  test_pred_1 = get_tasks_reverse(test_pred_1)\n",
        "  pred = []\n",
        "  for i in range(len(test_tweet_ids)):\n",
        "    pred.append([test_tweet_ids[i], test_pred_1[i], test_hasoc_ids[i]])\n",
        "  # pred = [[test_tweet_ids, i, test_hasoc_ids] for i in test_pred_1]\n",
        "\n",
        "  with open(fpath, 'w+', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
        "    csvwriter.writerows(pred)\n",
        "\n",
        "  print('Finished writing Task A')\n",
        "\n",
        "  if not test_pred_2 is None:\n",
        "    print('Writing Task B')\n",
        "    fname = fprefix + 'B.csv'\n",
        "    fpath = path + fname\n",
        "\n",
        "    test_pred_2 = get_tasks_reverse(test_pred_2, taskType=2)\n",
        "    pred = []\n",
        "    for i in range(len(test_tweet_ids)):\n",
        "      pred.append([test_tweet_ids[i], test_pred_2[i], test_hasoc_ids[i]])\n",
        "\n",
        "    with open(fpath, 'w+', newline='') as csvfile:\n",
        "      csvwriter = csv.writer(csvfile, delimiter=',')\n",
        "      csvwriter.writerows(pred)\n",
        "  \n",
        "    print('Finished writing Task B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ik8FdCVzyGA",
        "colab_type": "text"
      },
      "source": [
        "## Model saver\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg8cKr3lz2kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def savemodel(models, path=OUTPUT_ROOT):\n",
        "  with open(path+'models.pkl', 'wb') as f:\n",
        "    pickle.dump(models, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ8PBCX-ql4x",
        "colab_type": "text"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqkF55RX303E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData(lang, seed=42, test=False):\n",
        "  if lang not in ['hi','en','ge']:\n",
        "      raise NameError(\"Language not found\")\n",
        "  fileName = lang\n",
        "  if test:\n",
        "    fileName += '_test.pickle'\n",
        "    with open(TEST_ROOT+fileName, 'rb') as f:\n",
        "      ged= pickle.load(f)\n",
        "  else:\n",
        "    fileName += '.pickle'\n",
        "    with open(DATASET_ROOT+fileName, 'rb') as f:\n",
        "      ged = pickle.load(f)\n",
        "  df = pd.DataFrame.from_dict(ged)\n",
        "  train_df, test_df = model_selection.train_test_split(df, random_state = seed, test_size = 0.25)\n",
        "  return train_df, test_df, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tshEk6NF1aIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadAllLangs(seed=42):\n",
        "  train_en, test_en, en = loadData('en', seed)\n",
        "  train_ge, test_ge, ge = loadData('ge', seed)\n",
        "  train_hi, test_hi, hi = loadData('hi', seed)\n",
        "\n",
        "  # Combine the languages\n",
        "  train_all = pd.concat([train_en, train_ge, train_hi], ignore_index=True)\n",
        "  test_all = pd.concat([test_en, test_ge, test_hi], ignore_index=True)\n",
        "  all = pd.concat([en, ge, hi], ignore_index=True)\n",
        "\n",
        "  # Randomize\n",
        "  train_all = train_all.sample(frac=1, random_state=seed)\n",
        "  test_all = test_all.sample(frac=1, random_state=seed)\n",
        "  all = all.sample(frac=1, random_state=seed)\n",
        "\n",
        "  return train_all, test_all, all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K9SOt3i1ihL",
        "colab_type": "text"
      },
      "source": [
        "# Ablation Studies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcKXXDc8qii5",
        "colab_type": "text"
      },
      "source": [
        "## Encoder setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXrjmeWh9q7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir8sgHd9uWmo",
        "colab_type": "text"
      },
      "source": [
        "## Ablation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtV-SXAZzC4n",
        "colab_type": "text"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CYez461hZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "b = []\n",
        "def trainModelWithFeatures(train_df,test_df, lang, mlp=None, hashtags=True, emojis=True, verbose = False):\n",
        "  \"\"\" \n",
        "  Function to train a model on a specific configuration of features \n",
        "  Returns the classifier(s)\n",
        "  \"\"\"\n",
        "  global a\n",
        "  global b\n",
        "\n",
        "  if mlp is None:\n",
        "    mlp = MLPClassifier(\n",
        "        random_state=1,\n",
        "        max_iter=300,\n",
        "        hidden_layer_sizes=(200,),\n",
        "        activation='tanh',\n",
        "    )\n",
        "\n",
        "  # Get Segmented Hashtags from dataset\n",
        "  train1_hash = list(train_df['segmented_hash'])\n",
        "  test1_hash = list(test_df['segmented_hash'])\n",
        "  \n",
        "  # Segmented hashtags: List of strings --> Space-separated string\n",
        "  train_hash = []\n",
        "  for lis in train1_hash:\n",
        "    train_hash.append(' '.join(lis))\n",
        "  test_hash = []\n",
        "  for lis in test1_hash:\n",
        "    test_hash.append(' '.join(lis))\n",
        "\n",
        "  # Get raw train data from dataset\n",
        "  train_text = list(train_df['tweet_raw_text'])\n",
        "  train_t1s = list(train_df['task_1'])\n",
        "  train_t2s = list(train_df['task_2'])\n",
        "\n",
        "  # Get raw test data from the dataset\n",
        "  test_text = list(test_df['tweet_raw_text'])\n",
        "  test_t1s = list(test_df['task_1'])\n",
        "  test_t2s = list(test_df['task_2'])\n",
        "\n",
        "  # Get embeddings for the text\n",
        "  if verbose:\n",
        "    print(\"Started getting text embeddings\")\n",
        "  train_embeddings = sent_encoder.encode(train_text)\n",
        "  test_embeddings = sent_encoder.encode(test_text)\n",
        "  \n",
        "  # Get usable feature representations\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the text embeddings\")\n",
        "  train_t1 = get_task(train_t1s)\n",
        "  train_t2 = get_task(train_t2s, 2)\n",
        "  \n",
        "  test_t1 = get_task(test_t1s)\n",
        "  test_t2 = get_task(test_t2s, 2)\n",
        "\n",
        "  train_emb = get_features(train_embeddings)\n",
        "  test_emb = get_features(test_embeddings)\n",
        "\n",
        "  # Ablation: If hashtag\n",
        "  if hashtags:\n",
        "    if verbose:\n",
        "      print(\"Started getting hash embeddings\")\n",
        "    train_hashembeddings = sent_encoder.encode(train_hash)\n",
        "    test_hashembeddings = sent_encoder.encode(test_hash)\n",
        "    train_emb = np.concatenate((train_emb , train_hashembeddings), axis = 1)\n",
        "    test_emb =  np.concatenate((test_emb , test_hashembeddings), axis = 1)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the hash embeddings\")\n",
        "  \n",
        "  # Ablation: if emoji\n",
        "  if emojis:\n",
        "    if verbose:\n",
        "      print(\"Started getting emoji embeddings\")\n",
        "    train_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(train_df['emoji']))])\n",
        "    test_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(test_df['emoji']))])\n",
        "    train_emb = np.concatenate((train_emb , train_emojiEmbs), axis = 1)\n",
        "    test_emb = np.concatenate((test_emb , test_emojiEmbs), axis = 1)\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the emoji embeddings\")\n",
        "\n",
        "  # Fit and run classifier\n",
        "  a = train_emb\n",
        "  b = test_emb\n",
        "  \n",
        "  assert (train_t2 != test_t2)\n",
        "  # clf1 = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)\n",
        "  # clf2 =  MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t2)\n",
        "  clf1 = MLPClassifier(\n",
        "        random_state=1,\n",
        "        max_iter=300,\n",
        "        hidden_layer_sizes=(200,),\n",
        "        activation='tanh',\n",
        "    ).fit(train_emb, train_t1)\n",
        "  clf2 =  MLPClassifier(\n",
        "        random_state=1,\n",
        "        max_iter=300,\n",
        "        hidden_layer_sizes=(200,),\n",
        "        activation='tanh',\n",
        "    ).fit(train_emb, train_t2)\n",
        "\n",
        "  if verbose:\n",
        "    print(\"Finished training classifier\")\n",
        "  pred_test_t1 = clf1.predict(test_emb)\n",
        "  pred_test_t2 = clf2.predict(test_emb)\n",
        "\n",
        "  # print(pred_test_t1[:10])\n",
        "\n",
        "  # writeOutput(test_df, lang, pred_test_t1, pred_test_t2)\n",
        "\n",
        "  print(\"-\"*20, \"Task 1\", \"-\"*20)\n",
        "  print(classification_report(test_t1, pred_test_t1))\n",
        "  print(\"-\"*20, \"Task 2\", \"-\"*20)\n",
        "  print(classification_report(test_t2, pred_test_t2))\n",
        "\n",
        "  # print(pred_test_t1[:10])\n",
        "  return clf1, clf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX66QqSyzFnu",
        "colab_type": "text"
      },
      "source": [
        "### Ablation runner function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AEBfX0BHk7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performAblations(train_df, test_df, lang, features = [\"hashtags\", \"emojis\"], verbose = False):\n",
        "  '''\n",
        "  Given the train and test DF and the featureset, print results for the \n",
        "  classifier on all combinations\n",
        "  '''\n",
        "  for i in features:\n",
        "    if i not in [\"hashtags\", \"emojis\"]:\n",
        "      raise NameError(\"Wrong set of features.\")\n",
        " # TODO Make it more extensible \n",
        "  results = {}\n",
        "  print(\"*\"*20, \"ALL:\", \"*\"*20)\n",
        "  results[\"hash+emoji\"] = trainModelWithFeatures(train_df,test_df, lang, verbose = verbose)\n",
        "  print(\"*\"*20, \"HASH:\", \"*\"*20)\n",
        "  results[\"hash\"] = trainModelWithFeatures(train_df,test_df,lang,emojis=False, verbose = verbose)\n",
        "  print(\"*\"*20, \"EMOJI:\", \"*\"*20)\n",
        "  results[\"emoji\"] = trainModelWithFeatures(train_df,test_df,lang,hashtags=False, verbose = verbose)\n",
        "  print(\"*\"*20, \"VANILLA:\", \"*\"*20)\n",
        "  results[\"vanilla\"] = trainModelWithFeatures(train_df,test_df,lang,hashtags=False,emojis=False, verbose = verbose)\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fxqArg1xXJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def selectTokenizer(lang='en'):\n",
        "#   if lang not in ['en', 'ge', 'hi']:\n",
        "#     raise NameError(\"Wrong language\")\n",
        "#   tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "#   if lang == 'en':\n",
        "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "#   elif lang == 'hi':\n",
        "#     tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "#   return tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_swX7AF24I1",
        "colab_type": "text"
      },
      "source": [
        "## Experiment with combined languages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szL9VEuO3ASf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runCombinedLangs(seed=42):\n",
        "  train_df, test_df, df = loadAllLangs(seed=seed)\n",
        "  performAblations(train_df, test_df, features=['hashtags', 'emojis'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rczVDdN93NsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# runCombinedLangs(seed=69)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nocImXKTvS-r",
        "colab_type": "text"
      },
      "source": [
        "## Experiment with all languages and all ablations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FetxHw78cXdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpwQ2uB0vbs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "def trainAllLangs(langs=['en', 'ge', 'hi'], seed=42):\n",
        "  for i in langs:\n",
        "    if i not in ['en', 'ge', 'hi']:\n",
        "      raise NameError(\"Wrong set of languages\")\n",
        "  \n",
        "  for lang in langs:\n",
        "    print(\"\\n\\nFor the language:\", lang, '\\n', '#'*69)\n",
        "    train_df, test_df, df = loadData(lang, seed=seed)\n",
        "    results = performAblations(train_df, test_df, lang, features=['hashtags', 'emojis'])\n",
        "    models[lang] = results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvghASGcwOaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainAndSave(path=OUTPUT_ROOT, seed=42):\n",
        "  global models\n",
        "  trainAllLangs(seed=seed)\n",
        "  savemodel(models, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_JOh1jF0oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# savemodel(models, path=OUTPUT_ROOT+'/base/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99MQAmcu0Tep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17ffbea4-de78-4738-ad76-7df5cc8eb744"
      },
      "source": [
        "trainAndSave(path=OUTPUT_ROOT+'/base/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "For the language: en \n",
            " #####################################################################\n",
            "******************** ALL: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       442\n",
            "           1       0.86      0.83      0.84       485\n",
            "\n",
            "    accuracy                           0.84       927\n",
            "   macro avg       0.84      0.84      0.84       927\n",
            "weighted avg       0.84      0.84      0.84       927\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.87      0.82       442\n",
            "           1       0.32      0.15      0.20        40\n",
            "           2       0.75      0.73      0.74       364\n",
            "           3       0.45      0.27      0.34        81\n",
            "\n",
            "    accuracy                           0.73       927\n",
            "   macro avg       0.57      0.51      0.52       927\n",
            "weighted avg       0.71      0.73      0.72       927\n",
            "\n",
            "******************** HASH: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83       442\n",
            "           1       0.86      0.81      0.83       485\n",
            "\n",
            "    accuracy                           0.83       927\n",
            "   macro avg       0.83      0.83      0.83       927\n",
            "weighted avg       0.83      0.83      0.83       927\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       442\n",
            "           1       0.40      0.15      0.22        40\n",
            "           2       0.76      0.77      0.76       364\n",
            "           3       0.46      0.26      0.33        81\n",
            "\n",
            "    accuracy                           0.75       927\n",
            "   macro avg       0.60      0.52      0.54       927\n",
            "weighted avg       0.73      0.75      0.73       927\n",
            "\n",
            "******************** EMOJI: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.84       442\n",
            "           1       0.87      0.80      0.84       485\n",
            "\n",
            "    accuracy                           0.84       927\n",
            "   macro avg       0.84      0.84      0.84       927\n",
            "weighted avg       0.84      0.84      0.84       927\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82       442\n",
            "           1       0.17      0.07      0.10        40\n",
            "           2       0.75      0.75      0.75       364\n",
            "           3       0.39      0.27      0.32        81\n",
            "\n",
            "    accuracy                           0.73       927\n",
            "   macro avg       0.52      0.49      0.50       927\n",
            "weighted avg       0.71      0.73      0.72       927\n",
            "\n",
            "******************** VANILLA: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       442\n",
            "           1       0.86      0.82      0.84       485\n",
            "\n",
            "    accuracy                           0.83       927\n",
            "   macro avg       0.83      0.83      0.83       927\n",
            "weighted avg       0.83      0.83      0.83       927\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.90      0.83       442\n",
            "           1       0.21      0.07      0.11        40\n",
            "           2       0.76      0.74      0.75       364\n",
            "           3       0.39      0.21      0.27        81\n",
            "\n",
            "    accuracy                           0.74       927\n",
            "   macro avg       0.53      0.48      0.49       927\n",
            "weighted avg       0.71      0.74      0.72       927\n",
            "\n",
            "\n",
            "\n",
            "For the language: ge \n",
            " #####################################################################\n",
            "******************** ALL: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       421\n",
            "           1       0.59      0.45      0.51       173\n",
            "\n",
            "    accuracy                           0.75       594\n",
            "   macro avg       0.69      0.66      0.67       594\n",
            "weighted avg       0.73      0.75      0.74       594\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84       421\n",
            "           1       0.25      0.14      0.18        36\n",
            "           2       0.55      0.51      0.53        99\n",
            "           3       0.21      0.08      0.12        38\n",
            "\n",
            "    accuracy                           0.73       594\n",
            "   macro avg       0.45      0.40      0.42       594\n",
            "weighted avg       0.69      0.73      0.70       594\n",
            "\n",
            "******************** HASH: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       421\n",
            "           1       0.56      0.46      0.50       173\n",
            "\n",
            "    accuracy                           0.74       594\n",
            "   macro avg       0.68      0.65      0.66       594\n",
            "weighted avg       0.72      0.74      0.73       594\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       421\n",
            "           1       0.16      0.11      0.13        36\n",
            "           2       0.55      0.54      0.54        99\n",
            "           3       0.33      0.11      0.16        38\n",
            "\n",
            "    accuracy                           0.73       594\n",
            "   macro avg       0.46      0.41      0.42       594\n",
            "weighted avg       0.70      0.73      0.71       594\n",
            "\n",
            "******************** EMOJI: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       421\n",
            "           1       0.58      0.50      0.53       173\n",
            "\n",
            "    accuracy                           0.75       594\n",
            "   macro avg       0.69      0.67      0.68       594\n",
            "weighted avg       0.74      0.75      0.74       594\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       421\n",
            "           1       0.19      0.14      0.16        36\n",
            "           2       0.54      0.49      0.52        99\n",
            "           3       0.20      0.08      0.11        38\n",
            "\n",
            "    accuracy                           0.71       594\n",
            "   macro avg       0.43      0.40      0.41       594\n",
            "weighted avg       0.68      0.71      0.69       594\n",
            "\n",
            "******************** VANILLA: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84       421\n",
            "           1       0.64      0.47      0.54       173\n",
            "\n",
            "    accuracy                           0.77       594\n",
            "   macro avg       0.72      0.68      0.69       594\n",
            "weighted avg       0.75      0.77      0.76       594\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83       421\n",
            "           1       0.08      0.06      0.06        36\n",
            "           2       0.58      0.54      0.56        99\n",
            "           3       0.18      0.08      0.11        38\n",
            "\n",
            "    accuracy                           0.72       594\n",
            "   macro avg       0.41      0.39      0.39       594\n",
            "weighted avg       0.68      0.72      0.69       594\n",
            "\n",
            "\n",
            "\n",
            "For the language: hi \n",
            " #####################################################################\n",
            "******************** ALL: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.95      0.82       523\n",
            "           1       0.50      0.11      0.19       218\n",
            "\n",
            "    accuracy                           0.71       741\n",
            "   macro avg       0.61      0.53      0.50       741\n",
            "weighted avg       0.66      0.71      0.63       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.29      0.04      0.08        45\n",
            "           3       0.41      0.08      0.13       119\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.35      0.27      0.26       741\n",
            "weighted avg       0.59      0.70      0.61       741\n",
            "\n",
            "******************** HASH: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       523\n",
            "           1       0.47      0.09      0.15       218\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.59      0.52      0.49       741\n",
            "weighted avg       0.64      0.70      0.62       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.97      0.82       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.25      0.02      0.04        45\n",
            "           3       0.36      0.07      0.11       119\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.33      0.27      0.24       741\n",
            "weighted avg       0.58      0.70      0.60       741\n",
            "\n",
            "******************** EMOJI: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.93      0.81       523\n",
            "           1       0.42      0.12      0.19       218\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.57      0.53      0.50       741\n",
            "weighted avg       0.63      0.69      0.63       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.25      0.04      0.08        45\n",
            "           3       0.33      0.04      0.07       119\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.33      0.27      0.24       741\n",
            "weighted avg       0.58      0.70      0.60       741\n",
            "\n",
            "******************** VANILLA: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.95      0.81       523\n",
            "           1       0.37      0.07      0.12       218\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.54      0.51      0.47       741\n",
            "weighted avg       0.61      0.69      0.61       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.25      0.04      0.08        45\n",
            "           3       0.16      0.03      0.06       119\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.28      0.26      0.24       741\n",
            "weighted avg       0.54      0.69      0.59       741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CeYS2r3IYgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uppPo3JfqZC",
        "colab_type": "text"
      },
      "source": [
        "# Generating test outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9m0WNL9yeX-",
        "colab_type": "text"
      },
      "source": [
        "## Exploring test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mN33uCYfsuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/HASOC/Data/2020_processed_test/en_test.pickle', 'rb') as f:\n",
        "  eed = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v5loE07f4IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eed.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d261H48rw_4H",
        "colab_type": "text"
      },
      "source": [
        "## Inference function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbHuSEGf4XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(models, lang, test_df, hashtags=True, emojis=True, verbose=False, path=OUTPUT_ROOT):\n",
        "  clf1 = models[lang]['hash+emoji'][0]\n",
        "  clf2 = models[lang]['hash+emoji'][1]\n",
        "  \n",
        "  # Get Segmented Hashtags from dataset\n",
        "  test1_hash = list(test_df['segmented_hash'])\n",
        "  \n",
        "  # Segmented hashtags: List of strings --> Space-separated string\n",
        "  test_hash = []\n",
        "  for lis in test1_hash:\n",
        "    test_hash.append(' '.join(lis))\n",
        "\n",
        "  # Get raw test data from the dataset\n",
        "  test_text = list(test_df['tweet_raw_text'])\n",
        "  test_t1s = list(test_df['task_1'])\n",
        "  test_t2s = list(test_df['task_2'])\n",
        "\n",
        "  # Get embeddings for the text\n",
        "  if verbose:\n",
        "    print(\"Started getting text embeddings\")\n",
        "  test_embeddings = sent_encoder.encode(test_text)\n",
        "  \n",
        "  # Get usable feature representations\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the text embeddings\")\n",
        "  test_t1 = get_task(test_t1s)\n",
        "  test_t2 = get_task(test_t2s, 2)\n",
        "\n",
        "  test_emb = get_features(test_embeddings)\n",
        "\n",
        "  # Ablation: If hashtag\n",
        "  if hashtags:\n",
        "    if verbose:\n",
        "      print(\"Started getting hash embeddings\")\n",
        "    test_hashembeddings = sent_encoder.encode(test_hash)\n",
        "    test_emb =  np.concatenate((test_emb , test_hashembeddings), axis = 1)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the hash embeddings\")\n",
        "  \n",
        "  # Ablation: if emoji\n",
        "  if emojis:\n",
        "    if verbose:\n",
        "      print(\"Started getting emoji embeddings\")\n",
        "    test_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(test_df['emoji']))])\n",
        "    test_emb = np.concatenate((test_emb , test_emojiEmbs), axis = 1)\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the emoji embeddings\")\n",
        "\n",
        "  pred_test_t1 = clf1.predict(test_emb)\n",
        "  pred_test_t2 = clf2.predict(test_emb)\n",
        "\n",
        "  # if lang == 'en':\n",
        "  #   for i in range(len(pred_test_t1)):\n",
        "  #     if i % 10 == 0:\n",
        "  #       print(test_text[i], test_t1[i], pred_test_t1[i], test_t2[i], pred_test_t2[i])\n",
        "\n",
        "  print(\"-\"*20, \"Task 1\", \"-\"*20)\n",
        "  print(classification_report(test_t1, pred_test_t1))\n",
        "  print(\"-\"*20, \"Task 2\", \"-\"*20)\n",
        "  print(classification_report(test_t2, pred_test_t2))\n",
        "\n",
        "  writeOutput(test_df, lang, pred_test_t1, pred_test_t2, path=path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDH6mu-inpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inferAllLangs(langs=['en', 'ge', 'hi'], path=OUTPUT_ROOT):\n",
        "  for i in langs:\n",
        "    if i not in ['en', 'ge', 'hi']:\n",
        "      raise NameError(\"Wrong set of languages\")\n",
        "  \n",
        "  for lang in langs:\n",
        "    print(\"Inference for language: \", lang)\n",
        "    train_df, test_df, df = loadData(lang, test=True)\n",
        "    inference(models, lang, df, path=path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdvz7T42jA3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0897c4a2-280c-4966-b1c4-7f9af88c25ef"
      },
      "source": [
        "inferAllLangs(path=OUTPUT_ROOT+'/base/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inference for language:  en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.85      0.81       391\n",
            "           1       0.85      0.77      0.81       423\n",
            "\n",
            "    accuracy                           0.81       814\n",
            "   macro avg       0.81      0.81      0.81       814\n",
            "weighted avg       0.81      0.81      0.81       814\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       414\n",
            "           1       0.22      0.08      0.12        25\n",
            "           2       0.71      0.75      0.73       293\n",
            "           3       0.45      0.18      0.26        82\n",
            "\n",
            "    accuracy                           0.74       814\n",
            "   macro avg       0.54      0.47      0.48       814\n",
            "weighted avg       0.71      0.74      0.71       814\n",
            "\n",
            "Writing Task A\n",
            "Finished writing Task A\n",
            "Writing Task B\n",
            "Finished writing Task B\n",
            "Inference for language:  ge\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85       392\n",
            "           1       0.56      0.51      0.53       134\n",
            "\n",
            "    accuracy                           0.77       526\n",
            "   macro avg       0.70      0.69      0.69       526\n",
            "weighted avg       0.77      0.77      0.77       526\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       378\n",
            "           1       0.22      0.17      0.19        24\n",
            "           2       0.52      0.55      0.53        88\n",
            "           3       0.30      0.08      0.13        36\n",
            "\n",
            "    accuracy                           0.74       526\n",
            "   macro avg       0.47      0.42      0.43       526\n",
            "weighted avg       0.71      0.74      0.72       526\n",
            "\n",
            "Writing Task A\n",
            "Finished writing Task A\n",
            "Writing Task B\n",
            "Finished writing Task B\n",
            "Inference for language:  hi\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.44      0.57       466\n",
            "           1       0.37      0.77      0.50       197\n",
            "\n",
            "    accuracy                           0.54       663\n",
            "   macro avg       0.59      0.60      0.54       663\n",
            "weighted avg       0.68      0.54      0.55       663\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.57      0.67       493\n",
            "           1       0.08      0.02      0.03        56\n",
            "           2       0.07      0.11      0.09        27\n",
            "           3       0.16      0.49      0.25        87\n",
            "\n",
            "    accuracy                           0.49       663\n",
            "   macro avg       0.28      0.30      0.26       663\n",
            "weighted avg       0.63      0.49      0.54       663\n",
            "\n",
            "Writing Task A\n",
            "Finished writing Task A\n",
            "Writing Task B\n",
            "Finished writing Task B\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzLu7ir_f4lW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f22e261d-4636-4eba-e955-12bcd38a8212"
      },
      "source": [
        "models['en'].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['hash+emoji', 'hash', 'emoji', 'vanilla'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V6O8SAw0Itj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# runAllLangs(seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgiHaDJdj2Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqkGALxOj1_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQMjK5dzj16u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g_IIz-ij12Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaIpBROXj1x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnUF9Vybj1t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHvlqdxLj1pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkvzYd8Oj1kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfeVnSpuj1gG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-CzCMbjj1aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcRv74Pnj1Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNLZGUrl0r8f",
        "colab_type": "text"
      },
      "source": [
        "## (Old experiment) Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdtrgDk18sNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_df, test_df, df = loadData('hi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQ1qlfM9CdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clf = trainModelWithFeatures(train_df,test_df,  verbose = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47VtJ99RI2l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d28f7f71-f57d-458f-df45-b268a7e3e5e3"
      },
      "source": [
        "r = performAblations(train_df, test_df,features = [\"hashtags\", \"emojis\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************** ALL: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.82       523\n",
            "           1       0.46      0.12      0.19       218\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.59      0.53      0.50       741\n",
            "weighted avg       0.64      0.70      0.63       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.50      0.02      0.04        45\n",
            "           3       0.32      0.06      0.10       119\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.38      0.26      0.24       741\n",
            "weighted avg       0.59      0.70      0.60       741\n",
            "\n",
            "******************** HASH: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       523\n",
            "           1       0.49      0.08      0.14       218\n",
            "\n",
            "    accuracy                           0.70       741\n",
            "   macro avg       0.60      0.52      0.48       741\n",
            "weighted avg       0.65      0.70      0.62       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.00      0.00      0.00        45\n",
            "           3       0.35      0.07      0.11       119\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.27      0.26      0.23       741\n",
            "weighted avg       0.56      0.69      0.60       741\n",
            "\n",
            "******************** EMOJI: ********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       523\n",
            "           1       0.52      0.11      0.18       218\n",
            "\n",
            "    accuracy                           0.71       741\n",
            "   macro avg       0.62      0.53      0.50       741\n",
            "weighted avg       0.66      0.71      0.63       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.83       523\n",
            "           1       1.00      0.02      0.04        54\n",
            "           2       0.00      0.00      0.00        45\n",
            "           3       0.42      0.11      0.17       119\n",
            "\n",
            "    accuracy                           0.71       741\n",
            "   macro avg       0.54      0.28      0.26       741\n",
            "weighted avg       0.65      0.71      0.62       741\n",
            "\n",
            "******************** VANILLA: ********************\n",
            "-------------------- Task 1 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.81       523\n",
            "           1       0.42      0.11      0.17       218\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.57      0.52      0.49       741\n",
            "weighted avg       0.63      0.69      0.62       741\n",
            "\n",
            "-------------------- Task 2 --------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82       523\n",
            "           1       0.00      0.00      0.00        54\n",
            "           2       0.29      0.04      0.08        45\n",
            "           3       0.27      0.07      0.11       119\n",
            "\n",
            "    accuracy                           0.69       741\n",
            "   macro avg       0.32      0.27      0.25       741\n",
            "weighted avg       0.57      0.69      0.60       741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mDtiufnI7Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8IJkLAPNHCV",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "Using grid-search with the MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvazzcrvQNmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmtcJlrXNO3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_param = {\n",
        "    'activation': ['tanh'],\n",
        "    'hidden_layer_sizes': [(200,), (32, 64, 128, 256, 512, 256, 64, 32, 16, 8, 4, 1),],# (50, 50), (100, 100), (200, 200)],\n",
        "    'solver': ['adam'],\n",
        "    'learning_rate': ['constant'],\n",
        "    'random_state': [1,]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge6FU_CfQM3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search = GridSearchCV(\n",
        "    estimator = MLPClassifier(),\n",
        "    scoring = 'f1_macro',\n",
        "    param_grid = grid_param,\n",
        "    cv = 4,\n",
        "    n_jobs = 1,\n",
        "    verbose = 0\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf33rXLxRbJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "def runAllLangsGrid(grid_search, langs=['en', 'ge', 'hi'], seed=42):\n",
        "  for i in langs:\n",
        "    if i not in ['en', 'ge', 'hi']:\n",
        "      raise NameError(\"Wrong set of languages\")\n",
        "  \n",
        "  for lang in langs:\n",
        "    print(\"\\n\\nFor the language:\", lang, '\\n', '#'*69)\n",
        "    # tokenizer = selectTokenizer(lang=lang)\n",
        "    train_df, test_df, df = loadData(lang, seed=seed)\n",
        "    performGridSearch(df, grid_search, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-afKiUo0T6zg",
        "colab_type": "text"
      },
      "source": [
        "## Running experiment\n",
        "\n",
        "The function prepares the data, then runs the search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSK-ZMaGI8lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performGridSearch(df, grid_search, verbose = False):\n",
        "  \n",
        "  ### Preparing data ###\n",
        "  \n",
        "  # Get Segmented Hashtags from dataset\n",
        "  hash1 = list(df['segmented_hash'])\n",
        "  \n",
        "  # Segmented hashtags: List of strings --> Space-separated string\n",
        "  hash = []\n",
        "  for lis in hash1:\n",
        "    hash.append(' '.join(lis))\n",
        "  \n",
        "  # Get raw data from dataset\n",
        "  text = list(df['tweet_raw_text'])\n",
        "  t1s = list(df['task_1'])\n",
        "  t2s = list(df['task_2'])\n",
        "\n",
        "  # Get embeddings for the text\n",
        "  if verbose:\n",
        "    print(\"Started getting text embeddings\")\n",
        "  embeddings = sent_encoder.encode(text)\n",
        "\n",
        "  # Get usable feature representations\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the text embeddings\")\n",
        "  t1 = get_task(t1s)\n",
        "  t2 = get_task(t2s, 2)\n",
        "\n",
        "  emb = get_features(embeddings)\n",
        "  \n",
        "  # Ablation: If hashtag\n",
        "  if verbose:\n",
        "    print(\"Started getting hash embeddings\")\n",
        "  hashembeddings = sent_encoder.encode(hash)\n",
        "  emb = np.concatenate((emb , hashembeddings), axis = 1)\n",
        "  \n",
        "  if verbose:\n",
        "    print(\"Finished loading up the hash embeddings\")\n",
        "\n",
        "  # Ablation: if emoji\n",
        "  if verbose:\n",
        "    print(\"Started getting emoji embeddings\")\n",
        "  emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(df['emoji']))])\n",
        "  emb = np.concatenate((emb , emojiEmbs), axis = 1)\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the emoji embeddings\")\n",
        "\n",
        "  print(\"-\"*20, \"Task 1\", \"-\"*20)\n",
        "  \n",
        "  grid_search.fit(emb, t1)\n",
        "  print(\"Best parameters: \", grid_search.best_params_)\n",
        "  print(\"Score: \", grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvBW4-cJYjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "298b3ac9-f597-45c8-ac2c-b2012eac5b3a"
      },
      "source": [
        "runAllLangsGrid(grid_search)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "For the language: en \n",
            " #####################################################################\n",
            "Started getting text embeddings\n",
            "Finished loading up the text embeddings\n",
            "Started getting hash embeddings\n",
            "Finished loading up the hash embeddings\n",
            "Started getting emoji embeddings\n",
            "🏽\n",
            "🏽\n",
            "❤\n",
            "⚠\n",
            "⚠\n",
            "⚠\n",
            "⚠\n",
            "🏾\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "✖\n",
            "⚠\n",
            "🏽\n",
            "♀\n",
            "❤\n",
            "🏽\n",
            "🏽\n",
            "♀\n",
            "🏾\n",
            "🏻\n",
            "♂\n",
            "❤\n",
            "🏼\n",
            "♀\n",
            "🏻\n",
            "♀\n",
            "🏻\n",
            "♀\n",
            "🏼\n",
            "🏼\n",
            "🏼\n",
            "🏼\n",
            "☺\n",
            "🏽\n",
            "🏽\n",
            "♂\n",
            "⚠\n",
            "⚠\n",
            "❝\n",
            "❞\n",
            "♡\n",
            "♡\n",
            "♡\n",
            "➡\n",
            "❤\n",
            "🏽\n",
            "♀\n",
            "🏽\n",
            "♀\n",
            "🏽\n",
            "🏽\n",
            "♀\n",
            "🏽\n",
            "🏽\n",
            "🏽\n",
            "🏽\n",
            "🏽\n",
            "🏽\n",
            "🏻\n",
            "♂\n",
            "🏽\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "❤\n",
            "🏼\n",
            "🏻\n",
            "♂\n",
            "🏼\n",
            "❤\n",
            "❤\n",
            "🏻\n",
            "🏻\n",
            "🏻\n",
            "🏾\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "❤\n",
            "✌\n",
            "🏼\n",
            "☀\n",
            "🏾\n",
            "♂\n",
            "✌\n",
            "🏽\n",
            "🏽\n",
            "✔\n",
            "♀\n",
            "🏻\n",
            "♀\n",
            "♛\n",
            "🏾\n",
            "🏽\n",
            "♀\n",
            "☆\n",
            "☽\n",
            "☆\n",
            "❖\n",
            "❖\n",
            "❖\n",
            "🏽\n",
            "♂\n",
            "❤\n",
            "🏽\n",
            "🏽\n",
            "♂\n",
            "❤\n",
            "❤\n",
            "♥\n",
            "❤\n",
            "♥\n",
            "❤\n",
            "♥\n",
            "❤\n",
            "❤\n",
            "❤\n",
            "❤\n",
            "🏻\n",
            "🏽\n",
            "♀\n",
            "🏽\n",
            "🏼\n",
            "🏼\n",
            "🏼\n",
            "🏻\n",
            "🏼\n",
            "🏼\n",
            "🏼\n",
            "🏾\n",
            "❤\n",
            "❤\n",
            "❤\n",
            "🏻\n",
            "🏽\n",
            "❝\n",
            "❞\n",
            "🏻\n",
            "❤\n",
            "🏽\n",
            "♂\n",
            "🏾\n",
            "♀\n",
            "🏾\n",
            "🏻\n",
            "♂\n",
            "🏻\n",
            "♂\n",
            "🏻\n",
            "♂\n",
            "🏻\n",
            "♂\n",
            "🏻\n",
            "♂\n",
            "🏾\n",
            "♂\n",
            "♀\n",
            "✌\n",
            "🏽\n",
            "🏼\n",
            "🏾\n",
            "🏾\n",
            "⚘\n",
            "⚠\n",
            "☺\n",
            "❤\n",
            "♥\n",
            "🏾\n",
            "♀\n",
            "❄\n",
            "⚠\n",
            "⚠\n",
            "☺\n",
            "✾\n",
            "❤\n",
            "🏼\n",
            "✌\n",
            "🏽\n",
            "✌\n",
            "🏽\n",
            "✌\n",
            "🏽\n",
            "♡\n",
            "🏽\n",
            "♀\n",
            "✌\n",
            "🏻\n",
            "⚠\n",
            "⚠\n",
            "❤\n",
            "🏽\n",
            "🏾\n",
            "♂\n",
            "☝\n",
            "☝\n",
            "✔\n",
            "✔\n",
            "✔\n",
            "🏽\n",
            "♂\n",
            "Finished loading up the emoji embeddings\n",
            "-------------------- Task 1 --------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters:  {'activation': 'tanh', 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'random_state': 1, 'solver': 'adam'}\n",
            "Score:  0.823046330738116\n",
            "\n",
            "\n",
            "For the language: ge \n",
            " #####################################################################\n",
            "Started getting text embeddings\n",
            "Finished loading up the text embeddings\n",
            "Started getting hash embeddings\n",
            "Finished loading up the hash embeddings\n",
            "Started getting emoji embeddings\n",
            "♂\n",
            "❤\n",
            "❤\n",
            "❤\n",
            "❤\n",
            "🏼\n",
            "♀\n",
            "♀\n",
            "➜\n",
            "♂\n",
            "❤\n",
            "☝\n",
            "☝\n",
            "🏻\n",
            "♂\n",
            "❤\n",
            "☝\n",
            "✌\n",
            "🏼\n",
            "❤\n",
            "🏻\n",
            "🛸\n",
            "🏽\n",
            "🏼\n",
            "🏼\n",
            "♀\n",
            "♀\n",
            "❤\n",
            "♀\n",
            "♂\n",
            "☝\n",
            "♂\n",
            "❤\n",
            "🏼\n",
            "🏼\n",
            "🏼\n",
            "❤\n",
            "✜\n",
            "☝\n",
            "🏼\n",
            "❤\n",
            "♂\n",
            "🏻\n",
            "🏿\n",
            "♀\n",
            "♀\n",
            "🏼\n",
            "♂\n",
            "♂\n",
            "❤\n",
            "Finished loading up the emoji embeddings\n",
            "-------------------- Task 1 --------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters:  {'activation': 'tanh', 'hidden_layer_sizes': (200,), 'learning_rate': 'constant', 'random_state': 1, 'solver': 'adam'}\n",
            "Score:  0.7083482765344838\n",
            "\n",
            "\n",
            "For the language: hi \n",
            " #####################################################################\n",
            "Started getting text embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e103bb90c783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunAllLangsGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-1003d2fccc2c>\u001b[0m in \u001b[0;36mrunAllLangsGrid\u001b[0;34m(grid_search, langs, seed)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# tokenizer = selectTokenizer(lang=lang)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mperformGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-cb1df7038653>\u001b[0m in \u001b[0;36mperformGridSearch\u001b[0;34m(df, grid_search, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Started getting text embeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Get usable feature representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Batches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36msmart_batching_collate_text_only\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0msentence_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_lists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mget_sentence_features\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sentence_embedding_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mget_sentence_features\u001b[0;34m(self, tokens, pad_seq_length)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[1;32m     70\u001b[0m         \u001b[0mpad_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#Add space for special tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   2456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_inputs_with_special_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_token_type_ids_from_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m             \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_xlm_roberta.py\u001b[0m in \u001b[0;36mcreate_token_type_ids_from_sequences\u001b[0;34m(self, token_ids_0, token_ids_1)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_ids_1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_ids_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_ids_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_ids_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVs6Hx7Jcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr78Lk7-08Hc",
        "colab_type": "text"
      },
      "source": [
        "# Pure BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzI760g1lQd",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "Loading the dataset into a dataframe, then transforming the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAcmEjoxrx4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = '/content/drive/My Drive/HASOC/Data/2020_train_sets/hasoc_2020_de_train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxX_2glrxqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "3a51569e-347d-4e65-99c4-8e85dccc84be"
      },
      "source": [
        "df = pd.read_csv(DATASET_PATH)\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,452\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>1128229574318407680</td>\n",
              "      <td>@BoserEr @SebastianHampel @DrDavidBerger Was i...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1033</th>\n",
              "      <td>1133029984573054976</td>\n",
              "      <td>RT @PlatonsTochter: Baden-Württemberg: Ehemali...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1889</th>\n",
              "      <td>1133427357140836352</td>\n",
              "      <td>Kostenlose dicke deutsche fisten. Geile nachba...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_3091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>1133715547777052672</td>\n",
              "      <td>@panemetc62 @ZDF @ZDFneo bei Dokus ist da ZDF ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1131616638342782976</td>\n",
              "      <td>Merkel Doktorarbeit: Ein Fake? | MMnews https:...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2133</th>\n",
              "      <td>1132000001926848512</td>\n",
              "      <td>@Ruebenhorst Diese Islamisten erscheinen irgen...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>HATE</td>\n",
              "      <td>hasoc_2020_de_884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>1131515152958918656</td>\n",
              "      <td>RT @D4ncingMonkey: #Amthor Leben und  Tod des ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>1132701889357914112</td>\n",
              "      <td>@EhrenmannErich der deutsche kocht sein chilli...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>1130044562884444160</td>\n",
              "      <td>@vickersHV10 @den_tyske Was ist los mit uns #E...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>1131518185474285572</td>\n",
              "      <td>@milchmitzucker sorry aber sie ist auch einfac...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                  ID\n",
              "200   1128229574318407680  ...  hasoc_2020_de_2811\n",
              "1033  1133029984573054976  ...   hasoc_2020_de_710\n",
              "1889  1133427357140836352  ...  hasoc_2020_de_3091\n",
              "1307  1133715547777052672  ...   hasoc_2020_de_531\n",
              "143   1131616638342782976  ...  hasoc_2020_de_2579\n",
              "2133  1132000001926848512  ...   hasoc_2020_de_884\n",
              "305   1131515152958918656  ...  hasoc_2020_de_1896\n",
              "1478  1132701889357914112  ...  hasoc_2020_de_1894\n",
              "1095  1130044562884444160  ...  hasoc_2020_de_1596\n",
              "1111  1131518185474285572  ...  hasoc_2020_de_1847\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo60AHM91IeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b9ec8a5-1e38-425f-8f7c-5f3c64dc693e"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "df['task1'] = LE.fit_transform(df['task1'])\n",
        "df['task2'] = LE.fit_transform(df['task2'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1133388798925189122</td>\n",
              "      <td>Deutsche rothaarige porno reife deutsche fraue...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1131117000279961600</td>\n",
              "      <td>Lehrstück auch, wie in der linken Jammerfemini...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1127134592517980161</td>\n",
              "      <td>RT @NDRinfo: Die deutsche Klimaaktivistin Luis...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_1042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1128897106171842560</td>\n",
              "      <td>@ruhrbahn jeden Morgen eine neue „Fahrzeugstör...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1123576753199484928</td>\n",
              "      <td>@Junge_Freiheit Die Inkas hatten sich schon dä...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...                  ID\n",
              "0  1133388798925189122  ...  hasoc_2020_de_2684\n",
              "1  1131117000279961600  ...  hasoc_2020_de_2440\n",
              "2  1127134592517980161  ...  hasoc_2020_de_1042\n",
              "3  1128897106171842560  ...   hasoc_2020_de_774\n",
              "4  1123576753199484928  ...   hasoc_2020_de_559\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrWazNo1LoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a0e804b-4b8f-40ee-9a76-6b695c3ace84"
      },
      "source": [
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "df.text.apply(count_words).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ULzJBy1Paa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCg277B18qw",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the Dataset\n",
        "\n",
        "And then extracting the posts and tasks from that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tEuNZX1NuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(ged['tweet_raw_text'], get_task(ged['task_1']), test_size=0.2)\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['task1'], test_size=0.2, stratify=df['task1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmPE59dv1QvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = train_x.values\n",
        "# categories = train_y.values\n",
        "posts = train_x\n",
        "categories = train_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu-_UGz81Szr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2VP_v-3D9r",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Data\n",
        "\n",
        "Into BERT-type preprocessed things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6GFCCa1Tse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "3f4844a265fb46b2ac7bc3495203ed4b",
            "6f7dfb4629c240b69132e4d5aa7c332d",
            "09abbce550634a45ae3b891e030a12f8",
            "d9bcd80d126d4ac2a031324d79b8a1fb",
            "27edd6a1538c46f0aef7c69899acbfbe",
            "af9f8a23eeee4f6cb9e9cbee8081a627",
            "0f50cda79879470a834193c725c928e2",
            "8c22825422fd4fa8acf4a8f3ddae1e0a"
          ]
        },
        "outputId": "d30a9a4f-135d-4f56-f7d7-0166c028f9ff"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f4844a265fb46b2ac7bc3495203ed4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=247333.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNv-M4V3NhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b1e93a03-796e-4fa9-bb3f-43e908a8c63b"
      },
      "source": [
        "print('Original: ', posts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Lass uns einfach mal Dopamin vergeuden\n",
            "Token IDs: tensor([  102,  4734,   704,  1533,   774, 17825,  6233,  5272,   204,   166,\n",
            "          103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Wc-M043Nrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6c97b576-f028-4085-be1d-6efe437c46e5"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.875 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,660 training samples\n",
            "  238 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrb2Ypi3NpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcBb8t383Nnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36b8eeea93fa4d74ace74bf9eb501cae",
            "9f39e5acab674eb191a1ad690312c6bb",
            "110e6e1655e941b28c92de002ea7a947",
            "41c181fc244543f29affc0e1611b9f15",
            "80bc1b33433f4472b34e917c1cf00c47",
            "76d0acb3ba3647a081a6915c51f1204b",
            "5cc684216fcc4265ae0d62b4a9e94b51",
            "ea55906d911f473d9b27f1dac6f46ac3",
            "8b6eece69dfc44d78b830223fd4f1fe3",
            "94b44bdb8dd342b0bc2b15d112c368f2",
            "3bd978faf6604530b16f52ac1386cc96",
            "ad755932caec4926b6d7623eca8ba814",
            "29a19cbabb0c4e8e86ee941e327104cc",
            "6efc8f6cbd084b7b8267c33131b14818",
            "f0eb60a3ff694e46910544ed880512f9",
            "adcf12e5ffc149bea974f804368f8d7d"
          ]
        },
        "outputId": "000c00b3-26e2-427b-9c4c-6cbbc44d3fa3"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-german-dbmdz-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36b8eeea93fa4d74ace74bf9eb501cae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b6eece69dfc44d78b830223fd4f1fe3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442256365.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-dbmdz-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DC_gcsJ3NlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "dca3793c-4248-4feb-a8d6-b3d4efc889a8"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (31102, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (4, 768)\n",
            "classifier.bias                                                 (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiLVh19n9JFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DD-3nVZ9JDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVGWrc19JBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HovaG5-9I-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdSKj6Jo9I5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "4d4e34b8-e530-45af-f0e9-9d0ea0126f4c"
      },
      "source": [
        "seed_val = 42\n",
        "torch.cuda.empty_cache()\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epoch took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epoch took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:24.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epoch took: 0:00:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:36 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmNsEOq9Unz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "5e9a6b40-5aeb-43b1-8954-c82edda8a256"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:31</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:31</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:31</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.55         0.39           0.86       0:00:31         0:00:01\n",
              "2               0.33         0.35           0.86       0:00:31         0:00:01\n",
              "3               0.23         0.38           0.86       0:00:31         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzoDddQ9Uj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9e49f1d4-3c8d-433b-97bc-5c0c16aef24b"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQPpBsf9Ug_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = valid_x.values\n",
        "# categories = valid_y.values\n",
        "posts = valid_x\n",
        "categories = valid_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UmpeSGX9Udu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cd8b1e53-a63a-4526-9cc0-32c5f2ec8d71"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbqr33a9UZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "57d1f078-1372-4ea5-9291-1612c07d9f56"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 475 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H6pRi5K9fag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a350f1cf-00a7-4159-8668-25a1feaf7c3f"
      },
      "source": [
        "print(predictions[0],true_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.6323337   3.12274    -2.5567174  -2.9750652 ]\n",
            " [ 4.073063    0.55542827 -2.7315142  -2.840895  ]\n",
            " [-0.58148086  3.386612   -1.9880607  -2.290066  ]\n",
            " [-0.0607793   3.573624   -2.3927078  -2.639462  ]\n",
            " [ 4.159212   -0.33992413 -2.0751953  -2.034514  ]\n",
            " [-0.27654496  3.2491677  -2.220152   -2.4454396 ]\n",
            " [ 3.7280843   0.2307884  -2.5400493  -2.4072416 ]\n",
            " [-0.62693834  3.4375453  -2.0344937  -2.5686939 ]\n",
            " [ 2.6987808   1.9011959  -2.739314   -3.0364413 ]\n",
            " [ 3.247344    1.3262775  -2.8440442  -2.8480377 ]\n",
            " [ 3.5067365  -0.5013843  -1.812414   -1.8513571 ]\n",
            " [ 4.1196136   0.8659061  -2.718529   -2.7948933 ]\n",
            " [ 2.2716424   1.6258057  -2.880927   -2.9757748 ]\n",
            " [ 3.7171805  -0.1532326  -2.4594858  -2.371483  ]\n",
            " [ 2.258548    1.7691505  -2.7650666  -2.7793112 ]\n",
            " [ 4.1161647   0.20726839 -2.4591339  -2.6009326 ]] [1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-g-1py9g2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3cdc0f69-3893-4501-8c01-9a6047be70cc"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "predicts = []\n",
        "accurate = 0\n",
        "total_len = 0\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "    # in to a list of 0s and 1s.\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    predicts.append(pred_labels_i)\n",
        "    # Calculate and store the coef for this batch.  \n",
        "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "\n",
        "    matthews_set.append(matthews)\n",
        "    for j in range(len(true_labels[i])):\n",
        "        if true_labels[i][j] == pred_labels_i[j]:\n",
        "            accurate+=1\n",
        "        total_len+=1\n",
        "print(\"Accuracy:\",accurate/total_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Accuracy: 0.8610526315789474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6oFj1N9h_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "1b1e1fdc-3997-452f-d4a5-6d5eff8baec4"
      },
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fh7Aa1n9jUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cde5609d-8545-49a6-fc3b-5b2e99b50856"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBWPnpv9kgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "953645e9-95d8-42af-b6a3-9cc680b189e0"
      },
      "source": [
        "accurate = 0\n",
        "for (i,j) in zip(flat_predictions, flat_true_labels):\n",
        "    if i==j:\n",
        "        accurate += 1\n",
        "accurate/len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8610526315789474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHaUWhL9lpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21656757-ac6b-42e2-ecfa-14d27d806aa2"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8284785748675976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7yuX5QviNxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}