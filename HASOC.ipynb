{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC BE",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/HASOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymx75g3TKBPu",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AusydJSf1JWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eea9a966-1380-450f-a705-6fa26ee0fbe2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkgSSbTKFnl",
        "colab_type": "text"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5k6sJxMId20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers\n",
        "!pip install seaborn\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U sentence-transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mJWYRNKH7l",
        "colab_type": "text"
      },
      "source": [
        "# Get imports\n",
        "\n",
        "- **General:** random, pickle, re, time, datetime\n",
        "- **General DS:** pandas, numpy, sklearn, matplotlib, seaborn, nltk\n",
        "- **Deep Learning:** torch, transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0yrIDfJZaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e7f504a0-086b-481a-c493-22bdf095d5d7"
      },
      "source": [
        "import random\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk36oE5Lrg9W",
        "colab_type": "text"
      },
      "source": [
        "# GPU device Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gcXgxjBfAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3d9168b9-82cf-46ec-fc41-46d43a2a3d4f"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKl5AjVg2GGu",
        "colab_type": "text"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtF92-5O1kHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_ROOT = '/content/drive/My Drive/2020_processed_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnNe1bM1vaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(DATASET_ROOT+'hi.pickle', 'rb') as f:\n",
        "  ged = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MXmbq82tfXr",
        "colab_type": "text"
      },
      "source": [
        "Checking it once for content description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLKtbO3yBD-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35be0578-b771-49b3-b6c5-356d1fc8fafd"
      },
      "source": [
        "ged.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_id', 'task_1', 'task_2', 'hasoc_id', 'full_tweet', 'tweet_raw_text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJlOlcu0QWM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae9d2bb-c45c-4f05-fce9-d4f06d69febc"
      },
      "source": [
        "ged['task_1'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOT', 'NOT', 'NOT', 'NOT', 'HOF', 'HOF', 'NOT', 'NOT', 'HOF', 'NOT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSohluLctjzO",
        "colab_type": "text"
      },
      "source": [
        "## Split data into train-test-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXL1bHONOQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train1_hash = ged['segmented_hash'][:2000]\n",
        "# test1_hash = ged['segmented_hash'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYE1Uvx2O35x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_hash = []\n",
        "# for lis in train1_hash:\n",
        "#   train_hash.append(' '.join(lis))\n",
        "# test_hash = []\n",
        "# for lis in test1_hash:\n",
        "#   test_hash.append(' '.join(lis))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyLubZmQuGzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text, test_text, train_t1s, test_t1s = model_selection.train_test_split(\n",
        "#     ged['tweet_raw_text'],\n",
        "#     ged['task_1'],\n",
        "#     test_size = 0.2,\n",
        "#     # random_state = 42\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoKUgiqgtag5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_text = ged['tweet_raw_text'][:2000]\n",
        "# train_t1s = ged['task_1'][:2000]\n",
        "\n",
        "# test_text = ged['tweet_raw_text'][2000:]\n",
        "# test_t1s = ged['task_1'][2000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwhRamhzzZRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame.from_dict(ged)\n",
        "# df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub6jEswMzlcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNTWBGA0tnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1_hash = list(train_df['segmented_hash'])\n",
        "test1_hash = list(test_df['segmented_hash'])\n",
        "train_hash = []\n",
        "for lis in train1_hash:\n",
        "  train_hash.append(' '.join(lis))\n",
        "test_hash = []\n",
        "for lis in test1_hash:\n",
        "  test_hash.append(' '.join(lis))\n",
        "train_text = list(train_df['tweet_raw_text'])\n",
        "train_t1s = list(train_df['task_1'])\n",
        "\n",
        "test_text = list(test_df['tweet_raw_text'])\n",
        "test_t1s = list(test_df['task_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_XcLvgGqafu",
        "colab_type": "text"
      },
      "source": [
        "# get Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU8BMAterqu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(embeddings):\n",
        "  # emb = []\n",
        "  # for e in embeddings:\n",
        "  #   emb.append({'feat': e})\n",
        "  emb = embeddings\n",
        "  return emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Jmwjber44S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_task(tasklist):\n",
        "  newtasks = []\n",
        "  for x in tasklist:\n",
        "    if x == 'NOT':\n",
        "      # newtasks.append(['0'])\n",
        "      newtasks.append(0)\n",
        "    else:\n",
        "      # newtasks.append(['1'])\n",
        "      newtasks.append(1)\n",
        "  return newtasks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXhZ-jlRdzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "907c9890-df6b-4560-95fe-7ba3ce83378f"
      },
      "source": [
        "import gensim.models as gsm\n",
        "e2v = gsm.KeyedVectors.load_word2vec_format('emoji2vec.bin', binary=True)\n",
        "# happy_vector = e2v['😂']    # Produces an embedding vector of length 300\n",
        "\n",
        "# Download the bin file from here https://github.com/uclnlp/emoji2vec/blob/master/pre-trained/emoji2vec.bin\n",
        "\n",
        "def getEmojiEmbeddings(emojiList,dim=300,verbose = False):\n",
        "  \"\"\" Generates an emoji vector by averaging the emoji representation for each emoji. If no emoji returns an empty list of dimension dim\"\"\"\n",
        "  if dim < 300:\n",
        "    raise IndexError(\"Dim has to be greater than 300\")\n",
        "  result = np.zeros(dim)\n",
        "  if (len(emojiList) == 0):\n",
        "    return result\n",
        "  else:\n",
        "    embs = None\n",
        "    for i in emojiList:\n",
        "      if verbose:\n",
        "        if i not in e2v.vocab:\n",
        "          print(i)\n",
        "    embs = np.mean([e2v[i] for i in emojiList if i in e2v.vocab], axis=0)\n",
        "  if np.any(np.isnan(embs)):\n",
        "    return result\n",
        "  result[:300] = embs\n",
        "  return result \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K9SOt3i1ihL",
        "colab_type": "text"
      },
      "source": [
        "# Ablation Studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXrjmeWh9q7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ffee83bd-db83-429f-87a3-d459d981fc29"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-dbmdz-uncased', do_lower_case=True)\n",
        "sent_encoder = SentenceTransformer('xlm-r-100langs-bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31CYez461hZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "a = []\n",
        "b = []\n",
        "def trainModelWithFeatures(train_df,test_df, hashtags=True, emojis=True, verbose = False):\n",
        "  \"\"\" Function to train a model on a specific configuration of features \"\"\"\n",
        "  global a\n",
        "  global b\n",
        "  train1_hash = list(train_df['segmented_hash'])\n",
        "  test1_hash = list(test_df['segmented_hash'])\n",
        "  train_hash = []\n",
        "  for lis in train1_hash:\n",
        "    train_hash.append(' '.join(lis))\n",
        "  test_hash = []\n",
        "  for lis in test1_hash:\n",
        "    test_hash.append(' '.join(lis))\n",
        "  train_text = list(train_df['tweet_raw_text'])\n",
        "  train_t1s = list(train_df['task_1'])\n",
        "\n",
        "  test_text = list(test_df['tweet_raw_text'])\n",
        "  test_t1s = list(test_df['task_1'])\n",
        "  if verbose:\n",
        "    print(\"Started getting text embeddings\")\n",
        "  train_embeddings = sent_encoder.encode(train_text)\n",
        "  test_embeddings = sent_encoder.encode(test_text)\n",
        "  if verbose:\n",
        "    print(\"Finished loading up the text embeddings\")\n",
        "  train_t1 = get_task(train_t1s)\n",
        "  test_t1 = get_task(test_t1s)\n",
        "  train_emb = get_features(train_embeddings)\n",
        "  test_emb = get_features(test_embeddings)\n",
        "  if hashtags:\n",
        "    if verbose:\n",
        "      print(\"Started getting hash embeddings\")\n",
        "    train_hashembeddings = sent_encoder.encode(train_hash)\n",
        "    test_hashembeddings = sent_encoder.encode(test_hash)\n",
        "    train_emb = np.concatenate((train_emb , train_hashembeddings), axis = 1)\n",
        "    test_emb =  np.concatenate((test_emb , test_hashembeddings), axis = 1)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the hash embeddings\")\n",
        "  if emojis:\n",
        "    if verbose:\n",
        "      print(\"Started getting emoji embeddings\")\n",
        "    train_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(train_df['emoji']))])\n",
        "    test_emojiEmbs = np.asarray([getEmojiEmbeddings(i,verbose=verbose) for i in (list(test_df['emoji']))])\n",
        "    train_emb = np.concatenate((train_emb , train_emojiEmbs), axis = 1)\n",
        "    test_emb = np.concatenate((test_emb , test_emojiEmbs), axis = 1)\n",
        "    if verbose:\n",
        "      print(\"Finished loading up the emoji embeddings\")\n",
        "  a = train_emb\n",
        "  b = test_emb\n",
        "  clf = MLPClassifier(random_state=1, max_iter=300).fit(train_emb, train_t1)\n",
        "  if verbose:\n",
        "    print(\"Finsihed training classifier\")\n",
        "  pred_test_t1 = clf.predict(test_emb)\n",
        "  print(classification_report(test_t1, pred_test_t1))\n",
        "  return clf \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqkF55RX303E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def loadData(lang):\n",
        "  if lang not in ['hi','en','ge']:\n",
        "      raise NameError(\"Language not found\")\n",
        "  fileName = lang + '.pickle'\n",
        "  with open(DATASET_ROOT+fileName, 'rb') as f:\n",
        "    ged = pickle.load(f)\n",
        "  df = pd.DataFrame.from_dict(ged)\n",
        "  train_df, test_df = model_selection.train_test_split(df, random_state = 42, test_size = 0.25)\n",
        "  return train_df, test_df, df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdtrgDk18sNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, test_df, df = loadData('hi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQ1qlfM9CdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "8cb7f042-39be-435b-ab4c-49b3baabdcf7"
      },
      "source": [
        "clf = trainModelWithFeatures(train_df,test_df,  verbose = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-221-be21239b3ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModelWithFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-210-3bed7862c9bc>\u001b[0m in \u001b[0;36mtrainModelWithFeatures\u001b[0;34m(train_df, test_df, hashtags, emojis, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Started getting text embeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mtrain_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mtest_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, is_pretokenized, device, num_workers)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AEBfX0BHk7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performAblations(train_df, test_df,features = [\"hashtags\", \"emojis\"], verbose = False):\n",
        "  for i in features:\n",
        "    if i not in [\"hashtags\", \"emojis\"]:\n",
        "      raise NameError(\"Wrong set of features. \")\n",
        " # TODO Make it more extensible \n",
        "  results = {}\n",
        "  print(\"all\")\n",
        "  results[\"hash+emoji\"] = trainModelWithFeatures(train_df,test_df,  verbose = verbose)\n",
        "  print(\"hash\")\n",
        "  results[\"hash\"] = trainModelWithFeatures(train_df,test_df,emojis=False, verbose = verbose)\n",
        "  print(\"emoji\")\n",
        "  results[\"emoji\"] = trainModelWithFeatures(train_df,test_df,hashtags=False, verbose = verbose)\n",
        "  print(\"vanilla\")\n",
        "  results[\"vanilla\"] = trainModelWithFeatures(train_df,test_df,hashtags=False,emojis=False, verbose = verbose)\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47VtJ99RI2l9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "0eae4ef3-7ed9-4bf5-aaf3-03139254053a"
      },
      "source": [
        "r = performAblations(train_df, test_df,features = [\"hashtags\", \"emojis\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       523\n",
            "           1       0.56      0.51      0.53       218\n",
            "\n",
            "    accuracy                           0.74       741\n",
            "   macro avg       0.68      0.67      0.68       741\n",
            "weighted avg       0.73      0.74      0.73       741\n",
            "\n",
            "hash\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       523\n",
            "           1       0.55      0.52      0.53       218\n",
            "\n",
            "    accuracy                           0.73       741\n",
            "   macro avg       0.68      0.67      0.67       741\n",
            "weighted avg       0.73      0.73      0.73       741\n",
            "\n",
            "emoji\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       523\n",
            "           1       0.56      0.56      0.56       218\n",
            "\n",
            "    accuracy                           0.74       741\n",
            "   macro avg       0.69      0.69      0.69       741\n",
            "weighted avg       0.74      0.74      0.74       741\n",
            "\n",
            "vanilla\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.83       523\n",
            "           1       0.61      0.42      0.50       218\n",
            "\n",
            "    accuracy                           0.75       741\n",
            "   macro avg       0.70      0.66      0.67       741\n",
            "weighted avg       0.74      0.75      0.74       741\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mDtiufnI7Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42694126-1c5d-428b-cfa6-ed54bd0f6dfd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSK-ZMaGI8lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXvBW4-cJYjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVs6Hx7Jcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr78Lk7-08Hc",
        "colab_type": "text"
      },
      "source": [
        "# Pure BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzI760g1lQd",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "Loading the dataset into a dataframe, then transforming the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAcmEjoxrx4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = '/content/drive/My Drive/HASOC/Data/2020_train_sets/hasoc_2020_de_train.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxX_2glrxqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "bbb41d5a-2855-49ab-973a-7608702146b0"
      },
      "source": [
        "df = pd.read_csv(DATASET_PATH)\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 2,452\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2114</th>\n",
              "      <td>1124994968999858176</td>\n",
              "      <td>@dabiggapicta @twitpatli @operationlibero Stim...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>1133100503418703874</td>\n",
              "      <td>@iParaadox Das ist einfach anders</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1165</th>\n",
              "      <td>1131791712786030592</td>\n",
              "      <td>RT @DerZeroy: ich hab schon tweets gemacht da ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>OFFN</td>\n",
              "      <td>hasoc_2020_de_114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>1125436117518626822</td>\n",
              "      <td>@tagesschau Dankeschön❤️🌙😽</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_2238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1626</th>\n",
              "      <td>1134494044162277377</td>\n",
              "      <td>RT @ohnenahme: @MalteKaufmann @Nobby1949Z Ich ...</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_1105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1134169870571098112</td>\n",
              "      <td>RT @hl_h2o: Komm,mein Herz,geh und leg dich wi...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_1212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>1125967141575057410</td>\n",
              "      <td>So ist es, und war es schon immer. Die Menschh...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1124469888272216065</td>\n",
              "      <td>@bineuerboss @shoutoutxobella Würde Arsch geben</td>\n",
              "      <td>HOF</td>\n",
              "      <td>PRFN</td>\n",
              "      <td>hasoc_2020_de_996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>1131202803140124672</td>\n",
              "      <td>in 🇱🇻 ballern jetzt einfach alle alle pointen ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>1128626259007660032</td>\n",
              "      <td>Daniel+Kermit &amp;gt; Red+Andy</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NONE</td>\n",
              "      <td>hasoc_2020_de_381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                  ID\n",
              "2114  1124994968999858176  ...  hasoc_2020_de_1027\n",
              "700   1133100503418703874  ...  hasoc_2020_de_1592\n",
              "1165  1131791712786030592  ...   hasoc_2020_de_114\n",
              "2416  1125436117518626822  ...  hasoc_2020_de_2238\n",
              "1626  1134494044162277377  ...  hasoc_2020_de_1105\n",
              "321   1134169870571098112  ...  hasoc_2020_de_1212\n",
              "1258  1125967141575057410  ...   hasoc_2020_de_200\n",
              "495   1124469888272216065  ...   hasoc_2020_de_996\n",
              "507   1131202803140124672  ...   hasoc_2020_de_758\n",
              "610   1128626259007660032  ...   hasoc_2020_de_381\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo60AHM91IeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cd153475-9f25-4bc7-b057-5815f04aea0d"
      },
      "source": [
        "LE = LabelEncoder()\n",
        "df['task1'] = LE.fit_transform(df['task1'])\n",
        "df['task2'] = LE.fit_transform(df['task2'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1133388798925189122</td>\n",
              "      <td>Deutsche rothaarige porno reife deutsche fraue...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1131117000279961600</td>\n",
              "      <td>Lehrstück auch, wie in der linken Jammerfemini...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_2440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1127134592517980161</td>\n",
              "      <td>RT @NDRinfo: Die deutsche Klimaaktivistin Luis...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_1042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1128897106171842560</td>\n",
              "      <td>@ruhrbahn jeden Morgen eine neue „Fahrzeugstör...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1123576753199484928</td>\n",
              "      <td>@Junge_Freiheit Die Inkas hatten sich schon dä...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hasoc_2020_de_559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  ...                  ID\n",
              "0  1133388798925189122  ...  hasoc_2020_de_2684\n",
              "1  1131117000279961600  ...  hasoc_2020_de_2440\n",
              "2  1127134592517980161  ...  hasoc_2020_de_1042\n",
              "3  1128897106171842560  ...   hasoc_2020_de_774\n",
              "4  1123576753199484928  ...   hasoc_2020_de_559\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHrWazNo1LoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52fc5127-6ec5-4fd7-e545-c029e27df164"
      },
      "source": [
        "def count_words(text):\n",
        "    return len(text.split())\n",
        "df.text.apply(count_words).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ULzJBy1Paa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nCg277B18qw",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the Dataset\n",
        "\n",
        "And then extracting the posts and tasks from that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tEuNZX1NuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(ged['tweet_raw_text'], get_task(ged['task_1']), test_size=0.2)\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['task1'], test_size=0.2, stratify=df['task1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmPE59dv1QvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = train_x.values\n",
        "# categories = train_y.values\n",
        "posts = train_x\n",
        "categories = train_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu-_UGz81Szr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH2VP_v-3D9r",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Data\n",
        "\n",
        "Into BERT-type preprocessed things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6GFCCa1Tse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e07c910a-31c2-4d91-f3d8-fbdbb402af93"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJNv-M4V3NhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "90ed3f31-e861-4175-b602-6bdee15eca69"
      },
      "source": [
        "print('Original: ', posts[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  : Die hat die Bekleidung der Schler im linken Bild als Uniformierung gewertet. Die Bekleidung der Nazis rechts h\n",
            "Token IDs: tensor([  102,   847,   125,   292,   125, 23474,   127,  2673, 30940,   197,\n",
            "         5782,  1282,   250, 22326,   603, 26678,   552,   125, 23474,   127,\n",
            "        22900,  1557,   134,   103,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Wc-M043Nrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "326626af-eb32-4104-f1fd-d9912ff35c9b"
      },
      "source": [
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_size = int(0.875 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,660 training samples\n",
            "  238 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrb2Ypi3NpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcBb8t383Nnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99e82e6f-bc7b-42e5-ec7b-7fe2f126a321"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-german-dbmdz-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-dbmdz-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DC_gcsJ3NlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "d52ccf9d-4a46-4821-8d74-ddb793449337"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (31102, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (4, 768)\n",
            "classifier.bias                                                 (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiLVh19n9JFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DD-3nVZ9JDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVGWrc19JBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HovaG5-9I-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdSKj6Jo9I5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "8f09bdaf-f642-4239-a01a-b1c51fe66bfa"
      },
      "source": [
        "seed_val = 42\n",
        "torch.cuda.empty_cache()\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:21.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epoch took: 0:00:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.41\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    104.    Elapsed: 0:00:10.\n",
            "  Batch    80  of    104.    Elapsed: 0:00:20.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epoch took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:23 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmNsEOq9Unz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "911e9461-e3bf-491e-faba-5c9c65eaeee5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:00:27</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0:00:26</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:00:26</td>\n",
              "      <td>0:00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.53         0.40           0.85       0:00:27         0:00:01\n",
              "2               0.36         0.41           0.86       0:00:26         0:00:01\n",
              "3               0.29         0.43           0.84       0:00:26         0:00:01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzoDddQ9Uj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "92549eb5-7d30-49eb-a26f-e8b0b1a3446b"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUQPpBsf9Ug_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts = valid_x.values\n",
        "# categories = valid_y.values\n",
        "posts = valid_x\n",
        "categories = valid_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UmpeSGX9Udu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9ba02b0c-edfa-4a1a-8dfa-8c382c50827e"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in posts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(categories)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbqr33a9UZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7ae78fb0-67dd-44b0-ea2a-54003b567a4f"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 475 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H6pRi5K9fag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b6cc7328-de91-4cd9-a263-8efa4dcd6381"
      },
      "source": [
        "print(predictions[0],true_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.815918    0.67652035 -2.2650628  -2.2906172 ]\n",
            " [ 3.8203065   0.5583332  -2.6725311  -2.4873564 ]\n",
            " [ 3.9499502   0.24259631 -2.4285192  -2.5219963 ]\n",
            " [ 3.8023715   0.8992263  -2.5455017  -2.6608763 ]\n",
            " [ 3.5275538   0.95858186 -2.3949318  -2.4766378 ]\n",
            " [ 3.887617    0.8140077  -2.6724727  -2.5248737 ]\n",
            " [ 0.16910587  3.6695373  -2.1501563  -1.9946499 ]\n",
            " [ 3.9468524   0.59644496 -2.5063562  -2.649984  ]\n",
            " [ 3.4229798   1.6607033  -2.573406   -2.9573843 ]\n",
            " [ 3.6360824   0.6973718  -2.5745804  -2.4552243 ]\n",
            " [ 3.3757284   1.1719614  -2.5285096  -2.8608246 ]\n",
            " [ 2.4881876   2.7517326  -2.7661166  -2.5374627 ]\n",
            " [ 3.873526    1.1388052  -2.6257365  -2.922611  ]\n",
            " [ 1.1770823   3.7499785  -2.6348324  -2.4921196 ]\n",
            " [ 3.671365    0.7367661  -2.4249887  -2.6031053 ]\n",
            " [ 3.5447338   1.9936495  -2.782876   -2.8870366 ]] [0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-g-1py9g2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "53621db4-bdf2-4176-b510-932c27bee754"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "predicts = []\n",
        "accurate = 0\n",
        "total_len = 0\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "    # in to a list of 0s and 1s.\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    predicts.append(pred_labels_i)\n",
        "    # Calculate and store the coef for this batch.  \n",
        "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "\n",
        "    matthews_set.append(matthews)\n",
        "    for j in range(len(true_labels[i])):\n",
        "        if true_labels[i][j] == pred_labels_i[j]:\n",
        "            accurate+=1\n",
        "        total_len+=1\n",
        "print(\"Accuracy:\",accurate/total_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Accuracy: 0.8273684210526315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6oFj1N9h_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "d89de99c-7c20-4bf2-edd3-b5bd7622a180"
      },
      "source": [
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fh7Aa1n9jUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd6dbb7d-5b21-4d60-9157-be161ba58689"
      },
      "source": [
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBWPnpv9kgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d8e71b5-2556-4fa4-e327-5d8eee8ca3a2"
      },
      "source": [
        "accurate = 0\n",
        "for (i,j) in zip(flat_predictions, flat_true_labels):\n",
        "    if i==j:\n",
        "        accurate += 1\n",
        "accurate/len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8273684210526315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKHaUWhL9lpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5ea681-9c14-4857-f434-b070142f2bfb"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(flat_true_labels, flat_predictions, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.775094696969697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    }
  ]
}