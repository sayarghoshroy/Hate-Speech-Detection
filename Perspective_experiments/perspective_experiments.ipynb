{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perspective_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZnIYmeSUCYZWeAbAfDENGvIFnWsbBUBf",
      "authorship_tag": "ABX9TyMJx7ElrEfaxB60oQ71q8dG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/perspective_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IyDVzQvqG56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing Effectiveness of Perspective API features"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5EB6Nfu5jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQHl0mFguj5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d7b86f5-65c0-4e83-be7b-bb8ff7d84af9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fevc0sOduF8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading datasets\n",
        "\n",
        "en_load = '/content/drive/My Drive/HASOC_raw_data/perspective_train/en.pickle'\n",
        "en_pers = {}\n",
        "\n",
        "ge_load = '/content/drive/My Drive/HASOC_raw_data/perspective_train/ge.pickle'\n",
        "ge_pers = {}\n",
        "\n",
        "en_data_load = '/content/drive/My Drive/2020_processed_data/en.pickle'\n",
        "en_data = {}\n",
        "\n",
        "ge_data_load = '/content/drive/My Drive/2020_processed_data/ge.pickle'\n",
        "ge_data = {}\n",
        "\n",
        "with open(en_load, 'rb') as f:\n",
        "  en_pers = pickle.load(f)\n",
        "\n",
        "with open(ge_load, 'rb') as f:\n",
        "  ge_pers = pickle.load(f)\n",
        "\n",
        "with open(en_data_load, 'rb') as f:\n",
        "  en_data = pickle.load(f)\n",
        "\n",
        "with open(ge_data_load, 'rb') as f:\n",
        "  ge_data = pickle.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfRQxw4NvDf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d2a8a22b-b330-4215-ecf9-49fc1ff89f37"
      },
      "source": [
        "# Visualizing Data\n",
        "for key in ge_pers.keys():\n",
        "  print(str(key))\n",
        "  # Uncomment to visualize actual values\n",
        "  # print(str(key) + \": \" + str(ge_pers[key]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOXICITY_WHOLE\n",
            "TOXICITY_RAW\n",
            "SEVERE_TOXICITY_WHOLE\n",
            "SEVERE_TOXICITY_RAW\n",
            "IDENTITY_ATTACK_WHOLE\n",
            "IDENTITY_ATTACK_RAW\n",
            "INSULT_WHOLE\n",
            "INSULT_RAW\n",
            "PROFANITY_WHOLE\n",
            "PROFANITY_RAW\n",
            "THREAT_WHOLE\n",
            "THREAT_RAW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3OJ5bqlw974",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6c7bda27-7176-46ad-e0f3-fa2c7ee4393e"
      },
      "source": [
        "# Testing Load Correctness\n",
        "ge_data.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_id', 'task_1', 'task_2', 'hasoc_id', 'full_tweet', 'tweet_raw_text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi0FO1y7vMle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ce4baaaa-6c5b-4a85-f71f-368829d82a91"
      },
      "source": [
        "x = []\n",
        "y_a = []\n",
        "y_b = []\n",
        "\n",
        "none_cnt = 0\n",
        "prfn_cnt = 0\n",
        "hate_cnt = 0\n",
        "offn_cnt = 0\n",
        "\n",
        "not_cnt = 0\n",
        "hof_cnt = 0\n",
        "\n",
        "# Uncomment to Run for English\n",
        "language = \"EN\"\n",
        "\n",
        "# Uncomment to Run for German\n",
        "# language = \"GE\"\n",
        "\n",
        "if language == \"EN\":\n",
        "    data_size = len(en_data['task_1'])\n",
        "\n",
        "    for idx in range(data_size):\n",
        "      y_a.append(en_data['task_1'][idx])\n",
        "      y_b.append(en_data['task_2'][idx])\n",
        "\n",
        "    x_matrix = []\n",
        "    for key in en_pers.keys():\n",
        "      if key == \"RAW_SPAN\" or key == \"WHOLE_SPAN\":\n",
        "        continue\n",
        "      x_matrix.append(en_pers[key])\n",
        "\n",
        "    x_matrix = np.asmatrix(x_matrix).T\n",
        "    y_a = np.asmatrix(y_a).T\n",
        "    y_b = np.asmatrix(y_b).T\n",
        "    # View Dimensions\n",
        "    print(\"x Dimensions: \" + str(np.shape(x_matrix)))\n",
        "    print(\"y Dimensions: \" + str(np.shape(y_a)))\n",
        "\n",
        "elif language == \"GE\":\n",
        "    data_size = len(ge_data['task_1'])\n",
        "\n",
        "    for idx in range(data_size):\n",
        "      checker = ge_data['task_1'][idx]\n",
        "      if checker == 'NOT':\n",
        "        not_cnt += 1\n",
        "      if checker == 'HOF':\n",
        "        hof_cnt += 1\n",
        "      y_a.append(ge_data['task_1'][idx])\n",
        "\n",
        "      checker = ge_data['task_2'][idx]\n",
        "      if checker == 'NONE':\n",
        "        none_cnt += 1\n",
        "      if checker == 'OFFN':\n",
        "        offn_cnt += 1\n",
        "      if checker == 'HATE':\n",
        "        hate_cnt += 1\n",
        "      if checker == 'PRFN':\n",
        "        prfn_cnt += 1\n",
        "      y_b.append(ge_data['task_2'][idx])\n",
        "\n",
        "    x_matrix = []\n",
        "    for key in ge_pers.keys():\n",
        "      if key == \"RAW_SPAN\" or key == \"WHOLE_SPAN\":\n",
        "        continue\n",
        "      x_matrix.append(ge_pers[key])\n",
        "\n",
        "    x_matrix = np.asmatrix(x_matrix).T\n",
        "    y_a = np.asmatrix(y_a).T\n",
        "    y_b = np.asmatrix(y_b).T\n",
        "    # View Dimensions\n",
        "    print(\"x Dimensions: \" + str(np.shape(x_matrix)))\n",
        "    print(\"y Dimensions: \" + str(np.shape(y_a)))\n",
        "    print(\"y Dimensions: \" + str(np.shape(y_b)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Dimensions: (3708, 18)\n",
            "y Dimensions: (3708, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIWnfEN2X8GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9922340a-3738-431c-cbdf-798968ffb2df"
      },
      "source": [
        "print(\"not_cnt: \" + str(not_cnt))\n",
        "print(\"hof_cnt: \" + str(hof_cnt))\n",
        "\n",
        "print(\"none_cnt: \" + str(none_cnt))\n",
        "print(\"hate_cnt: \" + str(hate_cnt))\n",
        "print(\"prfn_cnt: \" + str(prfn_cnt))\n",
        "print(\"offn_cnt: \" + str(offn_cnt))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not_cnt: 0\n",
            "hof_cnt: 0\n",
            "none_cnt: 0\n",
            "hate_cnt: 0\n",
            "prfn_cnt: 0\n",
            "offn_cnt: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKao8Dv2l-j3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd1dc96f-ea93-42e3-a4cb-37e74a1e021d"
      },
      "source": [
        "print(y_b.T)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['PRFN' 'PRFN' 'NONE' ... 'NONE' 'PRFN' 'NONE']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhdL7xcIxdaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, test_X, train_Y_a, test_Y_a, train_Y_b, test_Y_b = model_selection.train_test_split(x_matrix, y_a, y_b, random_state = 42, test_size = 0.2)\n",
        "train_Y_a = np.ravel(train_Y_a)\n",
        "test_Y_a = np.ravel(test_Y_a)\n",
        "train_Y_b = np.ravel(train_Y_b)\n",
        "test_Y_b = np.ravel(test_Y_b)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLRL6p1_z5E3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ae5313c8-8df8-4d6f-a430-02c440b24f57"
      },
      "source": [
        "# Viewing Data Shapes\n",
        "print(\"Train X: \" + str(np.shape(train_X)))\n",
        "print(\"Train Y: \" + str(np.shape(train_Y_a)))\n",
        "print(\"Test X: \" + str(np.shape(test_X)))\n",
        "print(\"Test Y: \" + str(np.shape(test_Y_a)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train X: (2966, 18)\n",
            "Train Y: (2966,)\n",
            "Test X: (742, 18)\n",
            "Test Y: (742,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_nK-4TfCnDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mean = np.mean(train_X, axis = 0)\n",
        "train_var = np.var(train_X, axis = 0)\n",
        "# Data Normalization\n",
        "# Note that we are only observing our training set\n",
        "train_X = (train_X -  train_mean) / np.sqrt(train_var)\n",
        "test_X = (test_X - train_mean) / np.sqrt(train_var)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCM2faHbz7qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, y_a, y_b, active = 'relu', sol = 'adam', learn = 'adaptive'):\n",
        "    cl_a = MLPClassifier(alpha = 0,\n",
        "                      # learning_rate_init = 1e-2 * 5,\n",
        "                      learning_rate = learn,\n",
        "                      hidden_layer_sizes = (32, 64, 128, 256, 512, 256, 64, 32, 16, 8, 4, 1),\n",
        "                      random_state = 2020,\n",
        "                      activation = active,\n",
        "                      max_iter = int(1e4),\n",
        "                      solver = sol,\n",
        "                      batch_size = 800,\n",
        "                      momentum = 0.9)\n",
        "    \n",
        "    cl_b = MLPClassifier(alpha = 0,\n",
        "                      # learning_rate_init = 1e-2 * 5,\n",
        "                      learning_rate = learn,\n",
        "                      hidden_layer_sizes = (32, 64, 128, 256, 512, 256, 64, 32, 16),\n",
        "                      random_state = 2020,\n",
        "                      activation = active,\n",
        "                      max_iter = int(1e4),\n",
        "                      solver = sol,\n",
        "                      batch_size = 800,\n",
        "                      momentum = 0.9)\n",
        "    cl_a.fit(X, y_a)\n",
        "    cl_b.fit(X, y_b)\n",
        "    return [cl_a, cl_b]\n",
        "\n",
        "def get_test_res(cl_a, cl_b):\n",
        "    pred_y_test_a = cl_a.predict(test_X)\n",
        "    pred_y_test_b = cl_b.predict(test_X)\n",
        "    target_names = ['NONE', 'PRFN', 'HATE', 'OFFN']\n",
        "\n",
        "    total = 0\n",
        "    matches = 0\n",
        "    size = np.shape(pred_y_test_a)[0]\n",
        "    for idx in range(size):\n",
        "      if pred_y_test_a[idx] == test_Y_a[idx]:\n",
        "          matches += 1\n",
        "      if pred_y_test_a[idx] == 'NOT':\n",
        "          pred_y_test_b[idx] = 'NONE'\n",
        "      total += 1\n",
        "    print(\"Accuracy = \" + str(matches / total * 100) + \"%\")\n",
        "    print(\"\")\n",
        "    # Uncomment to View Full Reports\n",
        "    print(classification_report(test_Y_b, pred_y_test_b, target_names = target_names))\n",
        "    print(\"\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dB_CvsL0wX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "063a9379-0019-4e1c-901a-1d67bd640594"
      },
      "source": [
        "# activations = ['identity', 'tanh', 'logistic', 'relu']\n",
        "activations = ['tanh', 'identity']\n",
        "solvers = ['adam', 'lbfgs', 'sgd']\n",
        "# learning_rates = ['adaptive', 'constant', 'invscaling']\n",
        "learning_rates = ['adaptive']\n",
        "\n",
        "# Going ahead with the better performing schemes\n",
        "\n",
        "# On German, identity activation + sgd solver gives overflow problems\n",
        "for active in activations:\n",
        "    model_number = 1\n",
        "    print(\"### \" + str(active) + \" Activation\")\n",
        "    for sol in solvers:\n",
        "        if active == 'tanh' and sol == 'lbfgs':\n",
        "          continue\n",
        "        if language == \"GE\" and active == \"identity\" and sol == \"sgd\":\n",
        "          continue\n",
        "        if language == \"GE\" and active == \"relu\" and sol == \"lbfgs\":\n",
        "          continue\n",
        "        print(\"#### \" + str(sol) + \" Solver\")\n",
        "        for learn in learning_rates:\n",
        "            model_a, model_b = train(train_X, train_Y_a, train_Y_b, active, sol, learn)\n",
        "            print(str(model_number) + \". \", end = \"\")\n",
        "            get_test_res(model_a, model_b)\n",
        "            model_number += 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### tanh Activation\n",
            "#### adam Solver\n",
            "1. Accuracy = 89.08355795148249%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE       0.14      0.06      0.08        36\n",
            "        PRFN       0.82      0.92      0.86       349\n",
            "        HATE       0.28      0.25      0.26        65\n",
            "        OFFN       0.85      0.81      0.83       292\n",
            "\n",
            "    accuracy                           0.77       742\n",
            "   macro avg       0.52      0.51      0.51       742\n",
            "weighted avg       0.75      0.77      0.76       742\n",
            "\n",
            "\n",
            "#### sgd Solver\n",
            "2. Accuracy = 89.75741239892183%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE       0.00      0.00      0.00        36\n",
            "        PRFN       0.87      0.93      0.90       349\n",
            "        HATE       0.32      0.09      0.14        65\n",
            "        OFFN       0.78      0.93      0.85       292\n",
            "\n",
            "    accuracy                           0.81       742\n",
            "   macro avg       0.49      0.49      0.47       742\n",
            "weighted avg       0.74      0.81      0.77       742\n",
            "\n",
            "\n",
            "### identity Activation\n",
            "#### adam Solver\n",
            "1. Accuracy = 89.35309973045821%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE       0.29      0.06      0.09        36\n",
            "        PRFN       0.88      0.93      0.90       349\n",
            "        HATE       0.38      0.15      0.22        65\n",
            "        OFFN       0.80      0.93      0.86       292\n",
            "\n",
            "    accuracy                           0.82       742\n",
            "   macro avg       0.59      0.52      0.52       742\n",
            "weighted avg       0.77      0.82      0.79       742\n",
            "\n",
            "\n",
            "#### lbfgs Solver\n",
            "2. Accuracy = 89.8921832884097%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE       0.33      0.03      0.05        36\n",
            "        PRFN       0.87      0.92      0.90       349\n",
            "        HATE       0.28      0.08      0.12        65\n",
            "        OFFN       0.78      0.94      0.85       292\n",
            "\n",
            "    accuracy                           0.81       742\n",
            "   macro avg       0.57      0.49      0.48       742\n",
            "weighted avg       0.76      0.81      0.77       742\n",
            "\n",
            "\n",
            "#### sgd Solver\n",
            "3. Accuracy = 89.4878706199461%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE       0.67      0.06      0.10        36\n",
            "        PRFN       0.87      0.92      0.90       349\n",
            "        HATE       0.33      0.09      0.14        65\n",
            "        OFFN       0.78      0.94      0.85       292\n",
            "\n",
            "    accuracy                           0.81       742\n",
            "   macro avg       0.66      0.50      0.50       742\n",
            "weighted avg       0.78      0.81      0.77       742\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2a8ZAbHn5KE",
        "colab_type": "text"
      },
      "source": [
        "# ***A Massive Results Dump...***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI_7wPWya1bh",
        "colab_type": "text"
      },
      "source": [
        "### Random Seed Used: 42\n",
        "#### For all experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ITZV5skMTTp",
        "colab_type": "text"
      },
      "source": [
        "#Results for English: Un-normalized, Last HL 1\n",
        "\n",
        "## identity Activation\n",
        "### lbfgs solver\n",
        "1. Learn Rate = constant : Accuracy = 90.02695417789758%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 90.02695417789758%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 90.02695417789758%\n",
        "\n",
        "### sgd Solver\n",
        "4. Learn Rate = constant : Accuracy = 89.75741239892183%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 88.27493261455525%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 89.35309973045821%\n",
        "\n",
        "### adam Solver\n",
        "7. Learn Rate = constant : Accuracy = 82.61455525606469%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 82.61455525606469%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 82.61455525606469%\n",
        "\n",
        "## logistic Activation\n",
        "### lbfgs Solver\n",
        "1. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### sgd Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 52.96495956873315%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### adam Solver\n",
        "7. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "## relu Activation\n",
        "### sgd Solver\n",
        "1. Learn Rate = constant : Accuracy = 89.35309973045821%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 84.50134770889488%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 89.08355795148249%\n",
        "\n",
        "### adam Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### lbfgs solver\n",
        "7. Learn Rate = constant : Accuracy = 88.94878706199461%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 88.94878706199461%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 88.94878706199461%\n",
        "\n",
        "## tanh Activation\n",
        "### sgd Solver\n",
        "1. Learn Rate = constant : Accuracy = 89.8921832884097%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 89.4878706199461%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 87.87061994609164%\n",
        "\n",
        "### adam Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSXci318VmcB",
        "colab_type": "text"
      },
      "source": [
        "# Results for German: : Un-normalized, Last HL 1\n",
        "\n",
        "### tanh Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 81.89473684210526%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 84.42105263157896%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### logistic Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### lbfgs Solver\n",
        "7.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "8.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "9.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### relu Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### lbfgs Solver\n",
        "7.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "8.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "9.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "#### lbfgs Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 82.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 82.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 82.94736842105263%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qZssj1X7Kx_",
        "colab_type": "text"
      },
      "source": [
        "# German Post Normalization With Task 1 Info\n",
        "\n",
        "### tanh Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 81.89473684210526%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.75      0.11      0.19        28\n",
        "        PRFN       0.81      0.97      0.88       337\n",
        "        HATE       0.44      0.22      0.29        32\n",
        "        OFFN       0.73      0.49      0.58        78\n",
        "\n",
        "    accuracy                           0.79       475\n",
        "   macro avg       0.68      0.45      0.49       475\n",
        "weighted avg       0.77      0.79      0.75       475\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "2. Accuracy = 85.47368421052632%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.47      0.29      0.36        28\n",
        "        PRFN       0.87      0.92      0.89       337\n",
        "        HATE       0.57      0.12      0.21        32\n",
        "        OFFN       0.62      0.77      0.69        78\n",
        "\n",
        "    accuracy                           0.80       475\n",
        "   macro avg       0.63      0.52      0.54       475\n",
        "weighted avg       0.79      0.80      0.78       475\n",
        "\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 84.0%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.50      0.07      0.12        28\n",
        "        PRFN       0.84      0.93      0.89       337\n",
        "        HATE       1.00      0.03      0.06        32\n",
        "        OFFN       0.62      0.78      0.69        78\n",
        "\n",
        "    accuracy                           0.80       475\n",
        "   macro avg       0.74      0.45      0.44       475\n",
        "weighted avg       0.80      0.80      0.75       475\n",
        "\n",
        "\n",
        "#### lbfgs Solver\n",
        "2. Accuracy = 83.15789473684211%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.40      0.07      0.12        28\n",
        "        PRFN       0.85      0.92      0.88       337\n",
        "        HATE       0.75      0.09      0.17        32\n",
        "        OFFN       0.60      0.77      0.67        78\n",
        "\n",
        "    accuracy                           0.79       475\n",
        "   macro avg       0.65      0.46      0.46       475\n",
        "weighted avg       0.77      0.79      0.75       475\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRClGsP3ciiS",
        "colab_type": "text"
      },
      "source": [
        "# English Post normalization with task 1 info\n",
        "\n",
        "### tanh Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 89.08355795148249%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.14      0.06      0.08        36\n",
        "        PRFN       0.82      0.92      0.86       349\n",
        "        HATE       0.28      0.25      0.26        65\n",
        "        OFFN       0.85      0.81      0.83       292\n",
        "        \n",
        "    accuracy                           0.77       742\n",
        "   macro avg       0.52      0.51      0.51       742\n",
        "weighted avg       0.75      0.77      0.76       742\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "2. Accuracy = 89.75741239892183%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.00      0.00      0.00        36\n",
        "        PRFN       0.87      0.93      0.90       349\n",
        "        HATE       0.32      0.09      0.14        65\n",
        "        OFFN       0.78      0.93      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.49      0.49      0.47       742\n",
        "weighted avg       0.74      0.81      0.77       742\n",
        "\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 89.35309973045821%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.29      0.06      0.09        36\n",
        "        PRFN       0.88      0.93      0.90       349\n",
        "        HATE       0.38      0.15      0.22        65\n",
        "        OFFN       0.80      0.93      0.86       292\n",
        "\n",
        "    accuracy                           0.82       742\n",
        "   macro avg       0.59      0.52      0.52       742\n",
        "weighted avg       0.77      0.82      0.79       742\n",
        "\n",
        "\n",
        "#### lbfgs Solver\n",
        "2. Accuracy = 89.8921832884097%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.33      0.03      0.05        36\n",
        "        PRFN       0.87      0.92      0.90       349\n",
        "        HATE       0.28      0.08      0.12        65\n",
        "        OFFN       0.78      0.94      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.57      0.49      0.48       742\n",
        "weighted avg       0.76      0.81      0.77       742\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "3. Accuracy = 89.4878706199461%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.67      0.06      0.10        36\n",
        "        PRFN       0.87      0.92      0.90       349\n",
        "        HATE       0.33      0.09      0.14        65\n",
        "        OFFN       0.78      0.94      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.66      0.50      0.50       742\n",
        "weighted avg       0.78      0.81      0.77       742\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q308nIjg1mbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}