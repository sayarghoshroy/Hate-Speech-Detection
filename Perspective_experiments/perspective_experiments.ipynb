{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perspective_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZnIYmeSUCYZWeAbAfDENGvIFnWsbBUBf",
      "authorship_tag": "ABX9TyPLoAPx68TXACpvBDI8rbRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/perspective_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IyDVzQvqG56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing Effectiveness of Perspective API features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5EB6Nfu5jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQHl0mFguj5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "918efd0b-9625-45ee-97f8-ee67e642cb4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fevc0sOduF8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading datasets\n",
        "\n",
        "en_load = '/content/drive/My Drive/HASOC_raw_data/perspective_train/en.pickle'\n",
        "en_pers = {}\n",
        "\n",
        "ge_load = '/content/drive/My Drive/HASOC_raw_data/perspective_train/ge.pickle'\n",
        "ge_pers = {}\n",
        "\n",
        "en_data_load = '/content/drive/My Drive/2020_processed_data/en.pickle'\n",
        "en_data = {}\n",
        "\n",
        "ge_data_load = '/content/drive/My Drive/2020_processed_data/ge.pickle'\n",
        "ge_data = {}\n",
        "\n",
        "# Test Data\n",
        "en_load_test = '/content/drive/My Drive/perspective_test/en.pickle'\n",
        "en_pers_test = {}\n",
        "\n",
        "ge_load_test = '/content/drive/My Drive/perspective_test/ge.pickle'\n",
        "ge_pers_test = {}\n",
        "\n",
        "en_data_load_test = '/content/drive/My Drive/2020_processed_test/en_test.pickle'\n",
        "en_data_test = {}\n",
        "\n",
        "ge_data_load_test = '/content/drive/My Drive/2020_processed_test/ge_test.pickle'\n",
        "ge_data_test = {}\n",
        "\n",
        "with open(en_load, 'rb') as f:\n",
        "  en_pers = pickle.load(f)\n",
        "\n",
        "with open(ge_load, 'rb') as f:\n",
        "  ge_pers = pickle.load(f)\n",
        "\n",
        "with open(en_data_load, 'rb') as f:\n",
        "  en_data = pickle.load(f)\n",
        "\n",
        "with open(ge_data_load, 'rb') as f:\n",
        "  ge_data = pickle.load(f)\n",
        "\n",
        "# For Testing\n",
        "\n",
        "with open(en_load_test, 'rb') as f:\n",
        "  en_pers_test = pickle.load(f)\n",
        "\n",
        "with open(ge_load_test, 'rb') as f:\n",
        "  ge_pers_test = pickle.load(f)\n",
        "\n",
        "with open(en_data_load_test, 'rb') as f:\n",
        "  en_data_test = pickle.load(f)\n",
        "\n",
        "with open(ge_data_load_test, 'rb') as f:\n",
        "  ge_data_test = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfRQxw4NvDf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d190e2e7-35a8-4cdb-ba38-303541f425c3"
      },
      "source": [
        "# Visualizing Data\n",
        "for key in ge_pers.keys():\n",
        "  print(str(key))\n",
        "  # Uncomment to visualize actual values\n",
        "  # print(str(key) + \": \" + str(ge_pers[key]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOXICITY_WHOLE\n",
            "TOXICITY_RAW\n",
            "SEVERE_TOXICITY_WHOLE\n",
            "SEVERE_TOXICITY_RAW\n",
            "IDENTITY_ATTACK_WHOLE\n",
            "IDENTITY_ATTACK_RAW\n",
            "INSULT_WHOLE\n",
            "INSULT_RAW\n",
            "PROFANITY_WHOLE\n",
            "PROFANITY_RAW\n",
            "THREAT_WHOLE\n",
            "THREAT_RAW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP3NRv6uswgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "3517c705-468a-43e3-cec7-1a1c206b0849"
      },
      "source": [
        "# Visualizing Data\n",
        "for key in en_pers.keys():\n",
        "  print(str(key))\n",
        "  # Uncomment to visualize actual values\n",
        "  # print(str(key) + \": \" + str(ge_pers[key]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOXICITY_WHOLE\n",
            "TOXICITY_RAW\n",
            "SEVERE_TOXICITY_WHOLE\n",
            "SEVERE_TOXICITY_RAW\n",
            "TOXICITY_FAST_WHOLE\n",
            "TOXICITY_FAST_RAW\n",
            "IDENTITY_ATTACK_WHOLE\n",
            "IDENTITY_ATTACK_RAW\n",
            "INSULT_WHOLE\n",
            "INSULT_RAW\n",
            "PROFANITY_WHOLE\n",
            "PROFANITY_RAW\n",
            "THREAT_WHOLE\n",
            "THREAT_RAW\n",
            "SEXUALLY_EXPLICIT_WHOLE\n",
            "SEXUALLY_EXPLICIT_RAW\n",
            "OBSCENE_WHOLE\n",
            "OBSCENE_RAW\n",
            "RAW_SPAN\n",
            "WHOLE_SPAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3OJ5bqlw974",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f5b47ebc-f314-42a0-dd9a-e4b167e369d0"
      },
      "source": [
        "# Testing Load Correctness\n",
        "ge_data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_id', 'task_1', 'task_2', 'hasoc_id', 'full_tweet', 'tweet_raw_text', 'hashtags', 'smiley', 'emoji', 'url', 'mentions', 'numerals', 'reserved_word', 'emotext', 'segmented_hash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi0FO1y7vMle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "643f8af2-5016-4807-b8bc-6951c47a5d7c"
      },
      "source": [
        "ignore_set = [\"RAW_SPAN\", \"WHOLE_SPAN\"] # , \"SEXUALLY_EXPLICIT_WHOLE\", \"SEXUALLY_EXPLICIT_RAW\", \"OBSCENE_WHOLE\", \"OBSCENE_RAW\", \"TOXICITY_FAST_WHOLE\", \"TOXICITY_FAST_RAW\"]\n",
        "\n",
        "y_a = []\n",
        "y_b = []\n",
        "\n",
        "y_a_test = []\n",
        "y_b_test = []\n",
        "\n",
        "none_cnt = 0\n",
        "prfn_cnt = 0\n",
        "hate_cnt = 0\n",
        "offn_cnt = 0\n",
        "\n",
        "not_cnt = 0\n",
        "hof_cnt = 0\n",
        "\n",
        "# Uncomment to Run for English\n",
        "# language = \"EN\"\n",
        "# Uncomment to Run for German\n",
        "language = \"GE\"\n",
        "\n",
        "data_size = len(en_data['task_1'])\n",
        "\n",
        "if language == 'EN':\n",
        "  for idx in range(data_size):\n",
        "    y_a.append(en_data['task_1'][idx])\n",
        "    y_b.append(en_data['task_2'][idx])\n",
        "\n",
        "x_matrix_en = []\n",
        "for key in en_pers.keys():\n",
        "  if key in ignore_set:\n",
        "    continue\n",
        "  x_matrix_en.append(en_pers[key])\n",
        "\n",
        "data_size = len(ge_data['task_1'])\n",
        "\n",
        "if language == 'GE':\n",
        "  for idx in range(data_size):\n",
        "    checker = ge_data['task_1'][idx]\n",
        "    if checker == 'NOT':\n",
        "      not_cnt += 1\n",
        "    if checker == 'HOF':\n",
        "      hof_cnt += 1\n",
        "    y_a.append(ge_data['task_1'][idx])\n",
        "\n",
        "    checker = ge_data['task_2'][idx]\n",
        "    if checker == 'NONE':\n",
        "      none_cnt += 1\n",
        "    if checker == 'OFFN':\n",
        "      offn_cnt += 1\n",
        "    if checker == 'HATE':\n",
        "      hate_cnt += 1\n",
        "    if checker == 'PRFN':\n",
        "      prfn_cnt += 1\n",
        "    y_b.append(ge_data['task_2'][idx])\n",
        "\n",
        "x_matrix_ge = []\n",
        "for key in ge_pers.keys():\n",
        "  x_matrix_ge.append(ge_pers[key])\n",
        "\n",
        "x_matrix_en = np.asmatrix(x_matrix_en).T\n",
        "x_matrix_ge = np.asmatrix(x_matrix_ge).T\n",
        "print(np.shape(x_matrix_en))\n",
        "print(np.shape(x_matrix_ge))\n",
        "\n",
        "# x_matrix = np.concatenate((x_matrix_en, x_matrix_ge), axis = 0)\n",
        "# np.random.shuffle(x_matrix)\n",
        "\n",
        "if language == 'EN':\n",
        "  x_matrix = x_matrix_en\n",
        "if language == 'GE':\n",
        "  x_matrix = x_matrix_ge\n",
        "\n",
        "y_a = np.asmatrix(y_a).T\n",
        "y_b = np.asmatrix(y_b).T\n",
        "# View Dimensions\n",
        "print(\"x Dimensions: \" + str(np.shape(x_matrix)))\n",
        "print(\"y_a Dimensions: \" + str(np.shape(y_a)))\n",
        "print(\"y_b Dimensions: \" + str(np.shape(y_b)))\n",
        "\n",
        "if language == \"EN\":\n",
        "    # Load test data\n",
        "    data_size_test = len(en_data_test['task_1'])\n",
        "\n",
        "    for idx in range(data_size_test):\n",
        "      y_a_test.append(en_data_test['task_1'][idx])\n",
        "      y_b_test.append(en_data_test['task_2'][idx])\n",
        "\n",
        "    x_matrix_test = []\n",
        "    for key in en_pers_test.keys():\n",
        "      if key in ignore_set: \n",
        "        continue\n",
        "      x_matrix_test.append(en_pers_test[key])\n",
        "\n",
        "    x_matrix_test = np.asmatrix(x_matrix_test).T\n",
        "    y_a_test = np.asmatrix(y_a_test).T\n",
        "    y_b_test = np.asmatrix(y_b_test).T\n",
        "\n",
        "    # View Dimensions\n",
        "    print(\"x Test Dimensions: \" + str(np.shape(x_matrix_test)))\n",
        "    print(\"y_a Test Dimensions: \" + str(np.shape(y_a_test)))\n",
        "    print(\"y_b Test Dimensions: \" + str(np.shape(y_b_test)))\n",
        "\n",
        "elif language == \"GE\":\n",
        "    # Load test data\n",
        "    data_size_test = len(ge_data_test['task_1'])\n",
        "\n",
        "    for idx in range(data_size_test):\n",
        "      y_a_test.append(ge_data_test['task_1'][idx])\n",
        "      y_b_test.append(ge_data_test['task_2'][idx])\n",
        "\n",
        "    x_matrix_test = []\n",
        "    for key in ge_pers_test.keys():\n",
        "      x_matrix_test.append(ge_pers_test[key])\n",
        "\n",
        "    x_matrix_test = np.asmatrix(x_matrix_test).T\n",
        "    y_a_test = np.asmatrix(y_a_test).T\n",
        "    y_b_test = np.asmatrix(y_b_test).T\n",
        "    \n",
        "    # View Dimensions\n",
        "    print(\"x Test Dimensions: \" + str(np.shape(x_matrix_test)))\n",
        "    print(\"y Test Dimensions: \" + str(np.shape(y_a_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3708, 18)\n",
            "(2373, 12)\n",
            "x Dimensions: (2373, 12)\n",
            "y_a Dimensions: (2373, 1)\n",
            "y_b Dimensions: (2373, 1)\n",
            "x Test Dimensions: (526, 12)\n",
            "y Test Dimensions: (526, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIWnfEN2X8GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d721ea97-b9e2-4c50-a637-269f4a3c2eb9"
      },
      "source": [
        "# Stats for German:\n",
        "print(\"not_cnt: \" + str(not_cnt))\n",
        "print(\"hof_cnt: \" + str(hof_cnt))\n",
        "\n",
        "print(\"none_cnt: \" + str(none_cnt))\n",
        "print(\"hate_cnt: \" + str(hate_cnt))\n",
        "print(\"prfn_cnt: \" + str(prfn_cnt))\n",
        "print(\"offn_cnt: \" + str(offn_cnt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not_cnt: 1700\n",
            "hof_cnt: 673\n",
            "none_cnt: 1700\n",
            "hate_cnt: 146\n",
            "prfn_cnt: 387\n",
            "offn_cnt: 140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKao8Dv2l-j3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "444645b9-4054-4cca-c758-80f5a0b6b97b"
      },
      "source": [
        "print(y_b.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['NONE' 'NONE' 'NONE' ... 'NONE' 'PRFN' 'NONE']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhdL7xcIxdaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For validation Experiments:\n",
        "# train_X, test_X, train_Y_a, test_Y_a, train_Y_b, test_Y_b = model_selection.train_test_split(x_matrix, y_a, y_b, random_state = 42, test_size = 0.2)\n",
        "\n",
        "# On the Actual Testing Data\n",
        "train_X = x_matrix\n",
        "test_X = x_matrix_test\n",
        "train_Y_a = y_a\n",
        "test_Y_a = y_a_test\n",
        "train_Y_b = y_b\n",
        "test_Y_b = y_b_test\n",
        "\n",
        "# Formatting\n",
        "train_Y_a = np.ravel(train_Y_a)\n",
        "test_Y_a = np.ravel(test_Y_a)\n",
        "train_Y_b = np.ravel(train_Y_b)\n",
        "test_Y_b = np.ravel(test_Y_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLRL6p1_z5E3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "50e2f3db-92a3-4c14-e871-00f98e2f9022"
      },
      "source": [
        "# Viewing Data Shapes\n",
        "print(\"Train X: \" + str(np.shape(train_X)))\n",
        "print(\"Train Y: \" + str(np.shape(train_Y_a)))\n",
        "print(\"Test X: \" + str(np.shape(test_X)))\n",
        "print(\"Test Y: \" + str(np.shape(test_Y_a)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train X: (2373, 12)\n",
            "Train Y: (2373,)\n",
            "Test X: (526, 12)\n",
            "Test Y: (526,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_nK-4TfCnDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_mean = np.mean(train_X, axis = 0)\n",
        "train_var = np.var(train_X, axis = 0)\n",
        "# Data Normalization\n",
        "# Note that we are only observing our training set\n",
        "train_X = (train_X -  train_mean) / np.sqrt(train_var)\n",
        "test_X = (test_X - train_mean) / np.sqrt(train_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCM2faHbz7qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, y_a, y_b, active = 'relu', sol = 'adam', learn = 'adaptive'):\n",
        "    cl_a = MLPClassifier(alpha = 0,\n",
        "                      # learning_rate_init = 1e-2 * 5,\n",
        "                      learning_rate = learn,\n",
        "                      hidden_layer_sizes = (32, 64, 128, 256, 512, 256, 64, 32, 16, 8, 4, 1),\n",
        "                      random_state = 2020,\n",
        "                      activation = active,\n",
        "                      max_iter = int(1e6),\n",
        "                      solver = sol,\n",
        "                      batch_size = 200,\n",
        "                      momentum = 0.9,\n",
        "                      early_stopping = True)\n",
        "    \n",
        "    cl_b = MLPClassifier(alpha = 0,\n",
        "                      # learning_rate_init = 1e-2 * 5,\n",
        "                      learning_rate = learn,\n",
        "                      hidden_layer_sizes = (32, 64, 128, 256, 512, 256, 64, 32, 16),\n",
        "                      random_state = 2020,\n",
        "                      activation = active,\n",
        "                      max_iter = int(1e6),\n",
        "                      solver = sol,\n",
        "                      batch_size = 200,\n",
        "                      momentum = 0.9,\n",
        "                      early_stopping = True)\n",
        "    cl_a.fit(X, y_a)\n",
        "    cl_b.fit(X, y_b)\n",
        "    return [cl_a, cl_b]\n",
        "\n",
        "def get_test_res(cl_a, cl_b):\n",
        "    pred_y_test_a = cl_a.predict(test_X)\n",
        "    pred_y_test_b = cl_b.predict(test_X)\n",
        "    target_names = ['NONE', 'PRFN', 'HATE', 'OFFN']\n",
        "    target_binary = ['NOT', 'HOF']\n",
        "\n",
        "    total = 0\n",
        "    matches = 0\n",
        "    size = np.shape(pred_y_test_a)[0]\n",
        "    for idx in range(size):\n",
        "      if pred_y_test_a[idx] == test_Y_a[idx]:\n",
        "          matches += 1\n",
        "      if pred_y_test_a[idx] == 'NOT':\n",
        "          pred_y_test_b[idx] = 'NONE'\n",
        "      total += 1\n",
        "    print(\"Accuracy = \" + str(matches / total * 100) + \"%\")\n",
        "    print(\"\")\n",
        "\n",
        "    print(classification_report(test_Y_a, pred_y_test_a, target_names = target_binary, digits = 5))\n",
        "    print(\"\")\n",
        "\n",
        "    # Uncomment to View Full Reports\n",
        "    print(classification_report(test_Y_b, pred_y_test_b, target_names = target_names, digits = 5))\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dB_CvsL0wX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76b4bae9-50bc-44c3-a62e-ed97fb3868b2"
      },
      "source": [
        "# activations = ['identity', 'tanh', 'logistic', 'relu']\n",
        "activations = ['tanh', 'identity']\n",
        "solvers = ['adam', 'lbfgs', 'sgd']\n",
        "# learning_rates = ['adaptive', 'constant', 'invscaling']\n",
        "learning_rates = ['adaptive']\n",
        "\n",
        "# Going ahead with the better performing schemes\n",
        "\n",
        "# On German, identity activation + sgd solver gives overflow problems\n",
        "for active in activations:\n",
        "    model_number = 1\n",
        "    print(\"### \" + str(active) + \" Activation\")\n",
        "    for sol in solvers:\n",
        "        if active == 'tanh' and sol == 'lbfgs':\n",
        "          continue\n",
        "        if language == \"GE\" and active == \"identity\" and sol == \"sgd\":\n",
        "          continue\n",
        "        if language == \"GE\" and active == \"relu\" and sol == \"lbfgs\":\n",
        "          continue\n",
        "        print(\"#### \" + str(sol) + \" Solver\")\n",
        "        for learn in learning_rates:\n",
        "            model_a, model_b = train(train_X, train_Y_a, train_Y_b, active, sol, learn)\n",
        "            print(str(model_number) + \". \", end = \"\")\n",
        "            get_test_res(model_a, model_b)\n",
        "            model_number += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### tanh Activation\n",
            "#### adam Solver\n",
            "1. Accuracy = 84.60076045627376%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NOT    0.71200   0.66418   0.68726       134\n",
            "         HOF    0.88778   0.90816   0.89786       392\n",
            "\n",
            "    accuracy                        0.84601       526\n",
            "   macro avg    0.79989   0.78617   0.79256       526\n",
            "weighted avg    0.84300   0.84601   0.84421       526\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE    0.33333   0.04167   0.07407        24\n",
            "        PRFN    0.86019   0.96032   0.90750       378\n",
            "        HATE    0.14286   0.02778   0.04651        36\n",
            "        OFFN    0.67021   0.71591   0.69231        88\n",
            "\n",
            "    accuracy                        0.81369       526\n",
            "   macro avg    0.50165   0.43642   0.43010       526\n",
            "weighted avg    0.75527   0.81369   0.77454       526\n",
            "\n",
            "\n",
            "#### sgd Solver\n",
            "2. Accuracy = 81.36882129277566%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NOT    0.61538   0.71642   0.66207       134\n",
            "         HOF    0.89730   0.84694   0.87139       392\n",
            "\n",
            "    accuracy                        0.81369       526\n",
            "   macro avg    0.75634   0.78168   0.76673       526\n",
            "weighted avg    0.82548   0.81369   0.81807       526\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE    0.00000   0.00000   0.00000        24\n",
            "        PRFN    0.79050   0.96825   0.87039       378\n",
            "        HATE    0.00000   0.00000   0.00000        36\n",
            "        OFFN    0.52381   0.37500   0.43709        88\n",
            "\n",
            "    accuracy                        0.75856       526\n",
            "   macro avg    0.32858   0.33581   0.32687       526\n",
            "weighted avg    0.65571   0.75856   0.69862       526\n",
            "\n",
            "\n",
            "### identity Activation\n",
            "#### adam Solver\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1. Accuracy = 80.6083650190114%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NOT    0.60667   0.67910   0.64085       134\n",
            "         HOF    0.88564   0.84949   0.86719       392\n",
            "\n",
            "    accuracy                        0.80608       526\n",
            "   macro avg    0.74615   0.76430   0.75402       526\n",
            "weighted avg    0.81457   0.80608   0.80953       526\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE    0.33333   0.04167   0.07407        24\n",
            "        PRFN    0.84597   0.94444   0.89250       378\n",
            "        HATE    0.33333   0.02778   0.05128        36\n",
            "        OFFN    0.62245   0.69318   0.65591        88\n",
            "\n",
            "    accuracy                        0.79848       526\n",
            "   macro avg    0.53377   0.42677   0.41844       526\n",
            "weighted avg    0.75010   0.79848   0.75800       526\n",
            "\n",
            "\n",
            "#### lbfgs Solver\n",
            "2. Accuracy = 69.20152091254754%\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NOT    0.00000   0.00000   0.00000       134\n",
            "         HOF    0.73092   0.92857   0.81798       392\n",
            "\n",
            "    accuracy                        0.69202       526\n",
            "   macro avg    0.36546   0.46429   0.40899       526\n",
            "weighted avg    0.54472   0.69202   0.60960       526\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NONE    0.00000   0.00000   0.00000        24\n",
            "        PRFN    0.71863   1.00000   0.83628       378\n",
            "        HATE    0.00000   0.00000   0.00000        36\n",
            "        OFFN    0.00000   0.00000   0.00000        88\n",
            "\n",
            "    accuracy                        0.71863       526\n",
            "   macro avg    0.17966   0.25000   0.20907       526\n",
            "weighted avg    0.51643   0.71863   0.60098       526\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2a8ZAbHn5KE",
        "colab_type": "text"
      },
      "source": [
        "# ***A Massive Results Dump...***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI_7wPWya1bh",
        "colab_type": "text"
      },
      "source": [
        "### Random Seed Used: 42\n",
        "#### For all experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ITZV5skMTTp",
        "colab_type": "text"
      },
      "source": [
        "#Results for English: Un-normalized, Last HL 1\n",
        "\n",
        "## identity Activation\n",
        "### lbfgs solver\n",
        "1. Learn Rate = constant : Accuracy = 90.02695417789758%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 90.02695417789758%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 90.02695417789758%\n",
        "\n",
        "### sgd Solver\n",
        "4. Learn Rate = constant : Accuracy = 89.75741239892183%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 88.27493261455525%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 89.35309973045821%\n",
        "\n",
        "### adam Solver\n",
        "7. Learn Rate = constant : Accuracy = 82.61455525606469%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 82.61455525606469%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 82.61455525606469%\n",
        "\n",
        "## logistic Activation\n",
        "### lbfgs Solver\n",
        "1. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### sgd Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 52.96495956873315%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### adam Solver\n",
        "7. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "## relu Activation\n",
        "### sgd Solver\n",
        "1. Learn Rate = constant : Accuracy = 89.35309973045821%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 84.50134770889488%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 89.08355795148249%\n",
        "\n",
        "### adam Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%\n",
        "\n",
        "### lbfgs solver\n",
        "7. Learn Rate = constant : Accuracy = 88.94878706199461%\n",
        "\n",
        "8. Learn Rate = invscaling : Accuracy = 88.94878706199461%\n",
        "\n",
        "9. Learn Rate = adaptive : Accuracy = 88.94878706199461%\n",
        "\n",
        "## tanh Activation\n",
        "### sgd Solver\n",
        "1. Learn Rate = constant : Accuracy = 89.8921832884097%\n",
        "\n",
        "2. Learn Rate = invscaling : Accuracy = 89.4878706199461%\n",
        "\n",
        "3. Learn Rate = adaptive : Accuracy = 87.87061994609164%\n",
        "\n",
        "### adam Solver\n",
        "4. Learn Rate = constant : Accuracy = 47.03504043126684%\n",
        "\n",
        "5. Learn Rate = invscaling : Accuracy = 47.03504043126684%\n",
        "\n",
        "6. Learn Rate = adaptive : Accuracy = 47.03504043126684%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSXci318VmcB",
        "colab_type": "text"
      },
      "source": [
        "# Results for German: : Un-normalized, Last HL 1\n",
        "\n",
        "### tanh Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 81.89473684210526%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 84.42105263157896%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### logistic Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### lbfgs Solver\n",
        "7.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "8.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "9.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### relu Activation\n",
        "#### sgd Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### adam Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "#### lbfgs Solver\n",
        "7.  Learn Rate = constant : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "8.  Learn Rate = invscaling : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "9.  Learn Rate = adaptive : \n",
        "Accuracy = 70.94736842105263%\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1.  Learn Rate = constant : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "2.  Learn Rate = invscaling : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "3.  Learn Rate = adaptive : \n",
        "Accuracy = 84.0%\n",
        "\n",
        "#### lbfgs Solver\n",
        "4.  Learn Rate = constant : \n",
        "Accuracy = 82.94736842105263%\n",
        "\n",
        "5.  Learn Rate = invscaling : \n",
        "Accuracy = 82.94736842105263%\n",
        "\n",
        "6.  Learn Rate = adaptive : \n",
        "Accuracy = 82.94736842105263%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qZssj1X7Kx_",
        "colab_type": "text"
      },
      "source": [
        "# German Post Normalization With Task 1 Info\n",
        "\n",
        "### tanh Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 81.89473684210526%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.75      0.11      0.19        28\n",
        "        PRFN       0.81      0.97      0.88       337\n",
        "        HATE       0.44      0.22      0.29        32\n",
        "        OFFN       0.73      0.49      0.58        78\n",
        "\n",
        "    accuracy                           0.79       475\n",
        "   macro avg       0.68      0.45      0.49       475\n",
        "weighted avg       0.77      0.79      0.75       475\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "2. Accuracy = 85.47368421052632%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.47      0.29      0.36        28\n",
        "        PRFN       0.87      0.92      0.89       337\n",
        "        HATE       0.57      0.12      0.21        32\n",
        "        OFFN       0.62      0.77      0.69        78\n",
        "\n",
        "    accuracy                           0.80       475\n",
        "   macro avg       0.63      0.52      0.54       475\n",
        "weighted avg       0.79      0.80      0.78       475\n",
        "\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 84.0%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.50      0.07      0.12        28\n",
        "        PRFN       0.84      0.93      0.89       337\n",
        "        HATE       1.00      0.03      0.06        32\n",
        "        OFFN       0.62      0.78      0.69        78\n",
        "\n",
        "    accuracy                           0.80       475\n",
        "   macro avg       0.74      0.45      0.44       475\n",
        "weighted avg       0.80      0.80      0.75       475\n",
        "\n",
        "\n",
        "#### lbfgs Solver\n",
        "2. Accuracy = 83.15789473684211%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.40      0.07      0.12        28\n",
        "        PRFN       0.85      0.92      0.88       337\n",
        "        HATE       0.75      0.09      0.17        32\n",
        "        OFFN       0.60      0.77      0.67        78\n",
        "\n",
        "    accuracy                           0.79       475\n",
        "   macro avg       0.65      0.46      0.46       475\n",
        "weighted avg       0.77      0.79      0.75       475\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRClGsP3ciiS",
        "colab_type": "text"
      },
      "source": [
        "# English Post normalization with task 1 info\n",
        "\n",
        "### tanh Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 89.08355795148249%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.14      0.06      0.08        36\n",
        "        PRFN       0.82      0.92      0.86       349\n",
        "        HATE       0.28      0.25      0.26        65\n",
        "        OFFN       0.85      0.81      0.83       292\n",
        "        \n",
        "    accuracy                           0.77       742\n",
        "   macro avg       0.52      0.51      0.51       742\n",
        "weighted avg       0.75      0.77      0.76       742\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "2. Accuracy = 89.75741239892183%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.00      0.00      0.00        36\n",
        "        PRFN       0.87      0.93      0.90       349\n",
        "        HATE       0.32      0.09      0.14        65\n",
        "        OFFN       0.78      0.93      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.49      0.49      0.47       742\n",
        "weighted avg       0.74      0.81      0.77       742\n",
        "\n",
        "\n",
        "### identity Activation\n",
        "#### adam Solver\n",
        "1. Accuracy = 89.35309973045821%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.29      0.06      0.09        36\n",
        "        PRFN       0.88      0.93      0.90       349\n",
        "        HATE       0.38      0.15      0.22        65\n",
        "        OFFN       0.80      0.93      0.86       292\n",
        "\n",
        "    accuracy                           0.82       742\n",
        "   macro avg       0.59      0.52      0.52       742\n",
        "weighted avg       0.77      0.82      0.79       742\n",
        "\n",
        "\n",
        "#### lbfgs Solver\n",
        "2. Accuracy = 89.8921832884097%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.33      0.03      0.05        36\n",
        "        PRFN       0.87      0.92      0.90       349\n",
        "        HATE       0.28      0.08      0.12        65\n",
        "        OFFN       0.78      0.94      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.57      0.49      0.48       742\n",
        "weighted avg       0.76      0.81      0.77       742\n",
        "\n",
        "\n",
        "#### sgd Solver\n",
        "3. Accuracy = 89.4878706199461%\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "        NONE       0.67      0.06      0.10        36\n",
        "        PRFN       0.87      0.92      0.90       349\n",
        "        HATE       0.33      0.09      0.14        65\n",
        "        OFFN       0.78      0.94      0.85       292\n",
        "\n",
        "    accuracy                           0.81       742\n",
        "   macro avg       0.66      0.50      0.50       742\n",
        "weighted avg       0.78      0.81      0.77       742\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q308nIjg1mbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}