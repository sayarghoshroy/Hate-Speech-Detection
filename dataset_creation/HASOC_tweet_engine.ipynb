{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HASOC_tweet_engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/br/WG+K4Mmq0IsQ1JONW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Hate-Speech-Detection/blob/master/HASOC_tweet_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS9buWpIKyMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZP09fuRPyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b0986e24-3bd8-4e98-edd2-8a6b5245f4ba"
      },
      "source": [
        "# Uncomment if you're running it for the first time\n",
        "# !pip install ekphrasis\n",
        "from ekphrasis.classes.segmenter import Segmenter\n",
        "# to leverage word statistics from Twitter\n",
        "seg_tw = Segmenter(corpus = \"twitter\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjJB1JBRTqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment if you're running it for the first time\n",
        "# !pip install tweet-preprocessor\n",
        "import preprocessor as tweet_proc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFe2tWP4eulw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment if you're running it for the first time\n",
        "# !pip install emot\n",
        "from emot.emo_unicode import UNICODE_EMO, EMOTICONS"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG87-Z2wq3nL",
        "colab_type": "text"
      },
      "source": [
        "#### *Raw Datasets are hosted [here](https://drive.google.com/drive/folders/1TuHRQQ41lK9oXJhlhsRiMjMnczuKn_kF?usp=sharing).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cth_6-5zMJlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f2aca46-0712-4a0d-98da-db369509987d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoVIASaVZGJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_list(proc_obj):\n",
        "  if proc_obj == None:\n",
        "    return []\n",
        "  \n",
        "  store = []\n",
        "  for unit in proc_obj:\n",
        "    store.append(unit.match)\n",
        "  \n",
        "  return store"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG_SKbAKfDtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emotext(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\", \"\").replace(\":\", \"\").split()))\n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBZ63rc-LeKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c65756f8-f906-4387-cf81-6af6d67a90a0"
      },
      "source": [
        "# For English\n",
        "file_name = \"/content/drive/My Drive/HASOC_raw_data/2019_data/english_dataset/english_dataset/english_dataset.tsv\"\n",
        "\n",
        "# For Hindi\n",
        "# file_name = \"/content/drive/My Drive/HASOC_raw_data/2019_data/hindi_dataset/hindi_dataset/hindi_dataset.tsv\"\n",
        "\n",
        "# For German\n",
        "# file_name = \"/content/drive/My Drive/HASOC_raw_data/2019_data/german_dataset/german_dataset/german_dataset.tsv\"\n",
        "\n",
        "# Set `german` as True while using the German dataset\n",
        "# It will notify dataset creater that there is no task 3\n",
        "german = False\n",
        "\n",
        "datapoints_count = 0\n",
        "see_index = True\n",
        "\n",
        "tweets = []\n",
        "raw_tweet_texts = []\n",
        "\n",
        "hashtags = []\n",
        "smileys = []\n",
        "emojis = []\n",
        "urls = []\n",
        "mentions = []\n",
        "numbers = []\n",
        "reserveds = []\n",
        "\n",
        "task_1_labels = []\n",
        "task_2_labels = []\n",
        "task_3_labels = []\n",
        "\n",
        "with open(file_name) as file:\n",
        "    file_reader = csv.reader(file, delimiter = \"\\t\")\n",
        "    for line in file_reader:\n",
        "      if see_index == True:\n",
        "        see_index = False\n",
        "        continue\n",
        "      \n",
        "      datapoints_count += 1\n",
        "\n",
        "      task_1_labels.append(line[2])\n",
        "      task_2_labels.append(line[3])\n",
        "      if german != True:\n",
        "        task_3_labels.append(line[4])\n",
        "      \n",
        "      tweets.append(line[1])\n",
        "      raw_tweet_texts.append(tweet_proc.clean(line[1]))\n",
        "\n",
        "      parse_obj = tweet_proc.parse(line[1])\n",
        "\n",
        "      hashtags.append(make_list(parse_obj.hashtags))\n",
        "      smileys.append(make_list(parse_obj.smileys))\n",
        "      emojis.append(make_list(parse_obj.emojis))\n",
        "      urls.append(make_list(parse_obj.urls))\n",
        "      mentions.append(make_list(parse_obj.mentions))\n",
        "      numbers.append(make_list(parse_obj.numbers))\n",
        "      reserveds.append(make_list(parse_obj.reserved))\n",
        "\n",
        "print(\"Number of Datapoints: \" + str(datapoints_count))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Datapoints: 5852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pILm-0QOMeEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "9b636dfd-220f-458e-e6c9-a275f2267978"
      },
      "source": [
        "# Viewing Created Dataset\n",
        "\n",
        "print(\"Tweets:\")\n",
        "print(tweets[0: 5])\n",
        "\n",
        "print(\"Raw Texts:\")\n",
        "print(raw_tweet_texts[0: 5])\n",
        "\n",
        "print(\"Hashtags:\")\n",
        "print(hashtags[0: 5])\n",
        "\n",
        "print(\"Smileys:\")\n",
        "print(smileys[0: 5])\n",
        "\n",
        "print(\"Emojis:\")\n",
        "print(emojis[0: 5])\n",
        "\n",
        "print(\"Urls:\")\n",
        "print(urls[0: 5])\n",
        "\n",
        "print(\"Mentions:\")\n",
        "print(mentions[0: 5])\n",
        "\n",
        "print(\"Numbers:\")\n",
        "print(numbers[0: 5])\n",
        "\n",
        "print(\"Reserved Words:\")\n",
        "print(reserveds[0: 5])\n",
        "\n",
        "print(\"Task Labels:\")\n",
        "print(task_1_labels[0: 5])\n",
        "print(task_2_labels[0: 5])\n",
        "if german != True:\n",
        "  print(task_3_labels[0: 5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets:\n",
            "[\"#DhoniKeepsTheGlove | WATCH: Sports Minister Kiren Rijiju issues statement backing MS Dhoni over 'Balidaan Badge', tells BCCI to take up the matter with ICC and keep government in the know as nation's pride is involved    https://t.co/zuo5335Rjr\", '@politico No. We should remember very clearly that #Individual1 just admitted to treason . #TrumpIsATraitor  #McCainsAHero #JohnMcCainDay', '@cricketworldcup Guess who would be the winner of this #CWC19?     Team who gets maximum points from the abandoned matches ðŸ˜„ #ShameOnICC #WIvsENG @ICC', \"Corbyn is too politically intellectual for #BorisJohnsonShouldNotBePM   Can't wait   #GeneralElectionNow https://t.co/pt8KmjfxJj\", 'All the best to #TeamIndia for another swimming competition on Sunday against #Pakistan.     #INDvPAK #ShameOnICC  #CWC19 #CWC19Rains â˜”â˜” https://t.co/MG2cIE0zib']\n",
            "Raw Texts:\n",
            "[\"| WATCH: Sports Minister Kiren Rijiju issues statement backing MS Dhoni over 'Balidaan Badge', tells BCCI to take up the matter with ICC and keep government in the know as nation's pride is involved\", 'No. We should remember very clearly that just admitted to treason .', 'Guess who would be the winner of this ? Team who gets maximum points from the abandoned matches', \"Corbyn is too politically intellectual for Can't wait\", 'All the best to for another swimming competition on Sunday against .']\n",
            "Hashtags:\n",
            "[['#DhoniKeepsTheGlove'], ['#Individual1', '#TrumpIsATraitor', '#McCainsAHero', '#JohnMcCainDay'], ['#CWC19', '#ShameOnICC', '#WIvsENG'], ['#BorisJohnsonShouldNotBePM', '#GeneralElectionNow'], ['#TeamIndia', '#Pakistan', '#INDvPAK', '#ShameOnICC', '#CWC19', '#CWC19Rains']]\n",
            "Smileys:\n",
            "[[], [], [], [], []]\n",
            "Emojis:\n",
            "[[], [], ['ðŸ˜„'], [], ['â˜”', 'â˜”']]\n",
            "Urls:\n",
            "[['https://t.co/zuo5335Rjr'], [], [], ['https://t.co/pt8KmjfxJj'], ['https://t.co/MG2cIE0zib']]\n",
            "Mentions:\n",
            "[[], ['@politico'], ['@cricketworldcup', '@ICC'], [], []]\n",
            "Numbers:\n",
            "[[], [], [], [], []]\n",
            "Reserved Words:\n",
            "[[], [], [], [], []]\n",
            "Task Labels:\n",
            "['NOT', 'HOF', 'NOT', 'NOT', 'NOT']\n",
            "['NONE', 'HATE', 'NONE', 'NONE', 'NONE']\n",
            "['NONE', 'TIN', 'NONE', 'NONE', 'NONE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBzrxDQYfaFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "76683c60-98f8-49b6-8cef-945cb037a49a"
      },
      "source": [
        "# Generating Emoji Texts\n",
        "emoji_texts = []\n",
        "\n",
        "for emo_list in emojis:\n",
        "  texts = []\n",
        "  for emoji in emo_list:\n",
        "    text = emotext(emoji)\n",
        "    texts.append(text)\n",
        "  emoji_texts.append(texts)\n",
        "\n",
        "print(\"Emoji Descriptions:\")\n",
        "print(emoji_texts[0: 5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emoji Descriptions:\n",
            "[[], [], ['smiling_face_with_open_mouth_&_smiling_eyes'], [], ['umbrella_with_rain_drops', 'umbrella_with_rain_drops']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8zou30vmf1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "902daae6-a7d4-4595-acca-e702a26166be"
      },
      "source": [
        "# Segmenting Hashtags\n",
        "segmented_hashtags = []\n",
        "\n",
        "for hashset in hashtags:\n",
        "  segmented_set = []\n",
        "  for tag in hashset:\n",
        "    word = tag[1: ]\n",
        "    # removing the hash symbol\n",
        "    segmented_set.append(seg_tw.segment(word))\n",
        "  segmented_hashtags.append(segmented_set)\n",
        "\n",
        "print(\"Segmented Hashtags:\")\n",
        "print(segmented_hashtags[0: 5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Segmented Hashtags:\n",
            "[['dhoni keeps the glove'], ['individual 1', 'trump is a traitor', 'mc cains a hero', 'john mc cain day'], ['cwc 19', 'shame on icc', 'w ivs eng'], ['boris johnson should not be pm', 'general election now'], ['team india', 'pakistan', 'in dv pak', 'shame on icc', 'cwc 19', 'cwc 19 rains']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLyTfvlmomYM",
        "colab_type": "text"
      },
      "source": [
        "#### **Comments**\n",
        "\n",
        "#### *English*\n",
        "\n",
        "- Everything Works Fine\n",
        "- In hashtag segmentation, things like \"WIvsIND\" get are misrepresented\n",
        "\n",
        "#### *Hindi*\n",
        "\n",
        "- Raw text field does not capture anything\n",
        "- Hashtags, Mentions, and URLs are captured nicely\n",
        "\n",
        "#### *German*\n",
        "\n",
        "- No data for task 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLnLj7h4OZDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}